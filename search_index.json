[["index.html", "Estatística por uma quase estatística 1 Sobre", " Estatística por uma quase estatística Andressa Gonelli 1 Sobre Este livro é um compilado de anotações dos meus estudos de estatística e R, onde busco registrar da forma mais simples e intuitiva toda informação que encontro (por vezes de forma quase ininteligível) nas mais diversas fontes de conhecimento. Minha pretensão é somente estruturar e linkar a teoria estatística com a programação em R (e futuramente python) para facilitar a consulta e associação de conteúdos. Minha intenção ao tornar esse conteúdo público foi somente ajudar pessoas que ,assim como eu, buscam se desenvolver na área de ciência de dados/ estatística e estão tendo dificuldade em encontrar conteúdos organizados e de fácil entendimento (para público não técnico). "],["estatística.html", "2 Estatística 2.1 Definição 2.2 Tipos de estatística 2.3 População 2.4 Amostragem 2.5 Amostra 2.6 Censo 2.7 Observação 2.8 Variáveis 2.9 Tipos de estatística", " 2 Estatística 2.1 Definição (Estudo)Conjunto de métodos e processos quantitativos que serve para estudar e medir fenômenos coletivos. Estatística e a ciência parte da matemática aplicada que fornece métodos para coletar, descrever, analisar, apresentar e interpretar dados, para utilização dos mesmos na tomada de decisões. (Fato Numérico) Dado de resumo de um conjunto de dados 2.2 Tipos de estatística 2.2.1 Descritiva Utiliza métodos para coleta, organização, apresentação e análise e síntese de dados obtidos em uma população ou amostra. Os dados são apresentados por meio de gráficos, tabelas, medidas para descrever o fenômeno. Trabalha com dados históricos oferecendo insights sobre acontecimentos do passado. 2.2.2 Inferencial Processo de estimar informações sobre uma população a partir dos resultados observados em uma amostra. Oferece conclusões, previsões, análise e interpretações de fenômenos com certo grau de confiabilidade. Ex: Pesquisa de mercado, opinião pública. 2.3 População Conjunto de indivíduos, objetos ou informações que apresentam pelo menos uma característica em comum, cujo comportamento nos interessa analisar Para que haja uma definição clara dos elementos que formam a população é necessária a especificação de trê elementos: uma característica comum localização temporal localização geográfica 2.3.1 Tipos População Finita Número limitado de elementos Universo estatístico Todos os elementos de um grupo População Infinita Teoricamente infinitos elementos. Na prática número muito grande de elementos 2.4 Amostragem Usa a coleta, organização, apresentação e análise dos dados como meio de estudar os parâmetros de uma população. 2.5 Amostra Parte de uma população, selecionada a partir de métodos específicos 2.6 Censo Exame completo de toda população, quanto maior a amostra mais preciso e confiável o resultado. Técnica que seleciona e avalia todos os elementos da população quando se realiza uma pesquisa Prós Maior acurácia/ confiança dos dados Contras Alto custo de tempo e dinheiro 2.7 Observação Ocorrência de um item de dados específico que é gravado sobre uma unidade de dados Tabela diferenciando a observação da variável 2.8 Variáveis Característica de interesse que e medidas em cada elemento da amostra ou população 2.8.1 Variáveis nominais Categoria não mensurável, rótulo ou nomes para identificar determinado atributo de um elemento Ex: Cor dos olhos, marca de carro, sexo, etc. 2.8.2 Variáveis ordinais Categorias divididas em números, onde as propriedades inerentes aos dados nominais trazem a ideia de ordem, classificação(significativas). Ex:Idade, grau de instrução, classe social, etc. 2.8.3 Variáveis intervalares Se os dados trazem a ideia de ordenação expressa por meio de um intervalo (como nota do ENEM) Ex:Idade, grau de instrução, classe social, etc. 2.8.4 Variáveis proporcionais Se os dados trazem as propriedades de dados de intervalo,porém sua proporção é dos valores é significativa Ex: distância, altura ,peso 2.9 Tipos de estatística 2.9.1 Estatística descritiva Coleta, organização, classificação, apresentação, interpretação e análise de dados, por meio de: Gráficos, tabelas, medidas para descrever o fenômeno 2.9.2 Estatística Indutiva ou Inferêncial A partir de uma amostra são desenvolvidas: Conclusões, previsões, análises, interpretações (Teoria de probabilidade ) Ex: Pesquisa de mercado, opinião pública "],["dados.html", "3 Dados 3.1 Classificação 3.2 Fontes de dados", " 3 Dados 3.1 Classificação 3.1.1 Qualitativos Apresentam uma qualidade ou atributo do indivíduo pesquisado, usam a escala de medição nominal/categórica ou ordinal e podem ser numéricos ou não. Nominal /Categórica Cor dos olhos Ordinal Grau de instrução 3.1.2 Quantitativa Resultado da observação é número que indica quantificação ou quantidade numerica. As variáveis podem ser intervalares ou proporcionais. 3.1.2.1 Variável contínua Assume qualquer valor na reta real Ex:Peso, altura, etc; - - 1,2; 1,23; 1,234;  3.1.2.2 Variável discreta Assume somente os valores inteiros na reta real Número de alunos, de mensagens, de filhos, etc. 3.1.2.3 De seção Transversal São dados coletado no mesmo intervalo de tempo, ou aproximado. 3.1.2.4 De série histórica São dados coletados ao longo de diversos períodos. ## Apresentação de dados Tabelas Série estatística Tipos de agrupamento na tabela Série temporal Série geográfica Série Histórica Série Específica ou categórica De acordo com categoria ou especificidade Série Mista Agrupamento duplo 3.2 Fontes de dados Dados primários Características Coletado pelo autor da análise Modo de coleta conhecido Prós Confiabilidade Qualidade Controle de informações Acertabilidade nos resultados Dados atualizados Contras Alto custo Demanda de tempo maior Equipe grande Dados secundários Características Coletados por terceiros Prós Baixo custo Rapidez Existência de diversas fontes Diversidade de informações para quantificação de questões Contras Falta de controle Dados inadequados Diversidade na classificação dos dados Dados desatualizados Fontes não confiáveis Dificuldade de reproduzir um estudo obtendo os mesmos resultados "],["medida-de-posição.html", "4 Medida de posição 4.1 Média 4.2 Mediana 4.3 Moda 4.4 Valor máximo e valor mínimo 4.5 Quartil 4.6 Percentil", " 4 Medida de posição As medidas de tendência central são valores representativos da distribuição em torno da qual as outras medidas se distribuem. Duas medidas são as mais utilizadas: a média aritmética e a mediana. 4.1 Média \\[\\begin{equation} \\bar{x}= \\frac{\\sum x_{i}}{n} \\tag{4.1} \\end{equation}\\] $ x_{i} = $ $ n = $ A média aritmética de um conjunto de n valores, como o próprio nome indica, é obtida somando-se todas as medidas e dividindo-se a soma por n.  Tentativa de sintetizar o comportamento do conjunto originário. Representamos cada valor individual por uma letra (x, y, z, etc.) seguida por um sub-índice, ou seja, representamos os n valores da amostra por x1, x2, x3, , xn, onde x1 é a primeira observação, x2 é a segunda e assim por diante. 4.1.1 Média Ajustada Quando se tem valores extremos, é a média ajustada. Ela é obtida excluindo-se uma porcentagem dos valores menores e maiores de um conjunto e calculando-se então a média dos valores restantes. Por exemplo, a média ajustada de 5% é obtida eliminando-se os 5% dos valores de dados menores e o 5% dos valores de dados maiores e calculando-se depois a média dos valores restantes. 4.1.2 Média Aritmética ponderada Onde cada valor tem um peso diferente \\[\\small \\bar{x}= \\frac{\\sum w_{i}x_{i}}{\\sum w_{i}} \\] \\(\\small x_{i} = \\textrm{o valor da observação de i} \\\\ w_{i}= \\textrm{o valor da observação de i}\\) 4.1.2.1 Para dados agrupados sem intervalos de classes População: \\[\\small \\mu= \\frac{\\sum X_{i}f_{i}}{N} \\] \\(\\small X_{i} = \\textrm{o valor da classe} \\\\ f_{i} = \\textrm{o número de elementos classificados na classe}\\) Amostra: \\[\\small \\bar{x}= \\frac{\\sum w_{i}x_{i}}{n} \\] \\(\\small x_{i}= \\textrm{o valor da classe} \\\\ w_{i}= \\textrm{o número de elementos classificados na classe}\\) Exemplo: Notas dos alunos - \\(\\small x_i\\) Número de alunos \\(\\small x_if_i\\) 1 1 1 2 3 6 3 5 15 4 1 4 Total () n = 10 26 4.1.2.2 Para dados agrupados com intervalos de classes População: \\[\\small x_i \\mu= \\frac{\\sum X_{i}f_{i}}{N} \\textrm{, onde } X_{i} = \\frac{l_{i}+l{s}}{2} \\] \\(\\small x_{i} = \\textrm{o valor da classe} \\\\ f_{i} = \\textrm{o número de elementos classificados na classe}\\) Amostra: \\[\\small \\bar{x}= \\frac{\\sum x_{i}f_{i}}{N} \\textrm{, onde } x_{i} = \\frac{l_{i}+l{s}}{2} \\] Exemplo: Classes - Renda Familiar \\(\\small x_i\\) \\(\\small f_i\\) - N° de famílias \\(\\small x_if_i\\) [2,4[ 3 5 15 [4,6[ 5 10 50 [6,8[ 7 14 98 [8,10[ 9 8 72 [10,12[ 11 3 33 Total () n = 40 268 \\(\\small x_{i} = \\textrm{ponto médio da classe}\\) R Exemplo: A lista abaixo possui as notas de 10 alunos de um curso de graduação no exame final. Calcule a média. notas = c(6.4, 7.3, 9.8, 7.3, 7.9, 8.2, 9.1, 5.6, 8.5, 6.8) mean(notas) ## [1] 7.69 4.2 Mediana A mediana é uma medida alternativa à média aritmética para representar o centro da distribuição, muito usada em estatística descritiva. A mediana de um conjunto de medidas (x1, x2, x3, , xn) é um valor M tal que pelo menos 50% das medidas são menores ou iguais a M e pelo menos 50% das medidas são maiores ou iguais a M. Em outras palavras, 50% das medidas ficam abaixo da mediana e 50% acima. Se o número de elementos for ímpar, a mediana é o elemento do meio: n / 2 Se o número de elementos for par, a mediana ainda é o elemento do meio, mas calculado assim: \\[ \\frac{(n + 1)} {2} \\] 4.2.1 R Exemplo: Os dados da lista abaixo são tempos de vida (em dias) de 8 lâmpadas. Calcule a média e a mediana. tempos = c(400, 350, 510, 550, 690, 720, 750, 2000) mean(tempos) ## [1] 746.25 median(tempos) ## [1] 620 4.2.2 Mediana em dados agrupados \\[md = LI_i + (\\frac{0,5n - F_{i-1}}{f_i})\\times h\\] \\(i: \\textrm{Classe mediana (é o intervalo de classe onde a coluna dos} F_i \\textrm{ na TDF superou o 50\\% dos dados } \\\\ LI_i: \\textrm{Limite inferior da classe mediana} \\\\ F_{i-1}: \\textrm{é a frequência acumulada absoluta da classe anterior a classe mediana} \\\\ f_i: \\textrm{é a frequência absoluta da classe mediana} \\\\ h: \\textrm{comprimento do intervalo de classe}\\) 4.3 Moda A moda de uma distribuição é o valor que ocorre mais frequentemente, ou o valor que corresponde ao intervalo de classe com a maior frequência. A moda, da mesma forma que a mediana, não é afetada por valores extremos. Uma distribuição de frequência que apresenta apenas uma moda é chamada de unimodal. Se a distribuição apresenta dois pontos de alta concentração ela é chamada de bimodal. Distribuições bimodais ou multimodais podem indicar que na realidade a distribuição de frequência se refere a duas populações cujas medidas foram misturadas. Por exemplo, suponha que um lote de caixas de leite longa vida é amostrado e em cada caixa da amostra é medido o volume envasado. Se o lote é formado pela produção de duas máquinas de envase que estão calibradas em valores diferentes, é possível que o histograma apresente duas modas, uma para cada valor de calibração. tamanhos = c(38, 38, 36, 37, 36, 36, 40, 39, 36, 35, 36) mean(tamanhos) ## [1] 37 median(tamanhos) ## [1] 36 moda = function(dados) { vetor = table(as.vector(dados)) names(vetor)[vetor == max(vetor)]} moda(tamanhos) ## [1] &quot;36&quot; 4.3.1 Moda em dados agrupados 4.3.1.1 Czuber \\[mo = LI_i + (\\frac{d_1}{d_1+d_2})\\times h\\] \\(i: \\textrm{Classe modal (é aquela classe que tem maior frequência absoluta)}(f_i) \\\\ LI_i: \\textrm{é o limite inferior da classe modal} \\\\ d_1: f_i - f_{i-1} \\\\ d_2: f_i - f_{i+1} \\\\ h: \\textrm{amplitude da classe modal}\\) 4.3.1.2 King \\[mo = LI_i + c \\times(\\frac{f_{post}}{f_{ant}+f_{post}})\\] \\(i: \\textrm{Classe modal (é aquela classe que tem maior frequência absoluta)}(f_i) \\\\ LI_i: \\textrm{é o limite inferior da classe modal} \\\\ f_{ant}: \\textrm{frequência da classe anterior à classe modal} \\\\ f_{post}: \\textrm{frequência da classe posterior à classe modal} \\\\ c: \\textrm{comprimento do intervalo de classe}\\) 4.4 Valor máximo e valor mínimo Representam os valores máximos e mínimos da distribuição de dados Exemplo: Quais são os valores máximo e mínimo dos tamanhos de sapatos do item anterior. tamanhos = c(38, 38, 36, 37, 36, 36, 40, 39, 36, 35, 36) max(tamanhos) ## [1] 40 min(tamanhos) ## [1] 35 4.5 Quartil Chamados de quartis da distribuição ou simplesmente quartil, dividem a distribuição em quartas partes Q1- 25% dos dados antes dele Q2 - 50% (mediana) Q3 - 75% Q4 - 100% 4.5.1 R Exemplo: O horário de funcionamento de um banco já está se esgotando, para adiantar o atendimento dos clientes o gerente decide para de chamar individualmente e passa a chamar em grupos de 1/4 da quantidade total de clientes na fila. A partir dos números das fichas dos clientes, determine os grupos das 4 chamadas. num_fichas = c(54, 55, 56, 57, 58, 59, 60, 61, 62, 63) quantile(num_fichas) ## 0% 25% 50% 75% 100% ## 54.00 56.25 58.50 60.75 63.00 4.6 Percentil Dividem a distribuição de dados em 100 parte iguais. Curva normal com as faixas de percentil destacadas Ex Percentil 10 = décimo percentil = 10% dos dados antes dele 4.6.1 R Exemplo: Considerando os dados do exemplos anterior, calcule o percentil 10, 80 e 98. num_fichas = c(54, 55, 56, 57, 58, 59, 60, 61, 62, 63) quantile(num_fichas, c(.10, .80,.98)) ## 10% 80% 98% ## 54.90 61.20 62.82 "],["medidas-de-variabilidade.html", "5 Medidas de variabilidade 5.1 Amplitude 5.2 Amplitude Interquartil 5.3 Variância 5.4 Desvio Padrão 5.5 Coeficiente de variação", " 5 Medidas de variabilidade 5.1 Amplitude A amplitude é uma medida de variabilidade (a mais simples) sendo resultante da diferença entre o maior e menor valor de um conjunto de dados. 5.1.1 R Exemplo: Bob quer aprender a voar com asa delta, e ele quer saber qual a amplitude máxima que um voo pode ter. A partir dos dados de outros praticantes de voo livre, determine qual a amplitude. dados = c(28, 31, 45, 58, 22, 33, 42, 68, 24,37) range(dados) ## [1] 22 68 diff(range(dados)) ## [1] 46 5.2 Amplitude Interquartil AIQ, ou amplitude Interquartil, é uma medida de variabilidade que supera valores extremos, sendo este a diferença entre o terceiro e o primeiro quartil, ou seja, a diferença entre 50% dos dados intermediários. \\[AIQ = Q3 - Q1\\] 5.3 Variância A variância é uma medida de variabilidade que utiliza todos os dados, baseando-se na diferença dos dados em relação à média. Essa diferença se chama, desvio em torno da média. Portanto, a variância descreve quão espalhados os dados estão dentro de um conjunto. Medindo a amplitude (variabilidade) dos dados em relação à média. Não é tão claro de ler o valor em relação ao dados, visto que o valor se encontra ao quadrado da grandeza utilizada na medição dos dados. \\[ \\sigma = \\frac{\\sum(x_{i}-\\bar{x})^2}{N}\\] Essa fórmula aplica-se para variância populacional - para variância da amostra deve-se usar n - 1, devido a diminuição dos graus de liberdade \\[ S^2 = \\frac{\\sum(x_{i}-\\bar{x})^2}{n-1}\\] 5.3.1 R Maq1 = c(181.9, 180.8, 181.9, 180.2, 181.4) Maq2 = c(180.1, 181.8, 181.5, 181.2, 182.4) Maq3 = c(182.1, 183.7, 182.1, 180.2, 181.9) var(Maq1) ## [1] 0.543 var(Maq2) ## [1] 0.725 var(Maq3) ## [1] 1.54 5.3.2 Variância para dados agrupados Amostra: \\[ S^2 = \\frac{\\sum f_{i}(M_{i}-\\bar{x})^2}{n-1}\\] \\(M_{i} = \\textrm{ponto médio da classe}\\) \\(f_{i} = \\textrm{frequência da classe}\\) População: \\[ S^2 = \\frac{\\sum f_{i}(M_{i}-\\mu )^2}{n-1}\\] \\(M_{i} = \\textrm{ponto médio da classe}\\) \\(f_{i} = \\textrm{frequência da classe}\\) \\(\\mu = \\textrm{média da população}\\) Tempo de conclusão Ponto médio da Classe (Mi) Frequência (fi) (fiMi) 10 -14 12 4 48 15 - 19 17 8 136 20 - 24 22 5 110 25 - 29 27 2 54 30 - 34 32 1 32 Total 20 380 \\[\\bar{x}=\\frac{\\sum f{i}M{i}}{n}\\] \\[\\bar{x}=\\frac{380}{20}=19\\] Tempo de conclusão Ponto médio da Classe (Mi) Frequência (fi) Desvio (Mi- x) Desvio Quadrático (Mi- x)2 fi(Mi- x)2 10 -14 12 4 -7 49 196 15 - 19 17 8 -2 4 92 20 - 24 22 5 3 9 45 25 - 29 27 2 8 64 128 30 - 34 32 1 13 169 169 Total 20 570 = \\[ S^2 = \\frac{\\sum f_{i}(M_{i}-\\bar{x})^2}{n-1}\\] \\[ S^2 = \\frac{570}{20-1} = 30\\] 5.4 Desvio Padrão O desvio padrão indica o grau da variação de um conjunto de dados, podendo este ser amostral ou populacional. Ele e a raiz quadrada positiva da variância. O desvio padrão é mais intuitivo de compreender, por estar na mesma escala da grandeza em análise. Desvio Padrão da amostra \\[\\sqrt{s^2}\\] Desvio Padrão da população \\[\\sqrt{\\sigma^2}\\] ### R Exemplo: Um engenheiro precisa decidir entre três modelos de máquinas de corte de alta precisão, para isso ele usa como critério o desvio padrão. A máquina que tiver menor desvio será a escolhida por ele. A partir dos dados de medida de corte das 3 máquinas, determine qual deve ser a escolhida pelo engenheiro. Máquina 1 (mm) = (181.9, 180.8, 181.9, 180.2, 181.4). Máquina 2 (mm) = (180.1, 181.8, 181.5, 181.2, 182.4). Máquina 3 (mm) = (182.1, 183.7, 182.1, 180.2, 181.9). Maq1 = c(181.9, 180.8, 181.9, 180.2, 181.4) Maq2 = c(180.1, 181.8, 181.5, 181.2, 182.4) Maq3 = c(182.1, 183.7, 182.1, 180.2, 181.9) mean(Maq1) ## [1] 181.24 mean(Maq2) ## [1] 181.4 mean(Maq3) ## [1] 182 sd(Maq1) ## [1] 0.7368853 sd(Maq2) ## [1] 0.8514693 sd(Maq3) ## [1] 1.240967 5.5 Coeficiente de variação O coeficiente de variação indica a quantidade de variação de um conjunto de dados em relação a média. O valor é dado por uma relação direta do quociente entre o desvio com a média da amostra. \\[Coeficiente = (\\frac{\\textrm{Desvio Padrão}}{Média}× 100) \\% \\] \\[Coeficiente = (\\frac{\\sigma}{\\mu}× 100) \\% \\] O coeficiente de variação (CV), mede o desvio padrão em termos de percentual da média. Um CV alto, indica alta variabilidade dos dados, ou seja, menos consistência dos dados. Um CV menor, indica mais consistência dentro do conjunto de dados. Quando comparamos a consistência entre 2 conjuntos de dados em relação a suas médias, é melhor feito quando utilizamos coeficiente de variação. 5.5.1 R Exemplo: Imagine que um investidor está decidindo se compra ações da Nike ou Adidas na bolsa de valores. O valor médio da ação de cada empresa e o desvio padrão, são dados a seguir. Qual deve ser a escolha do investidor? Nike =&gt; Valor médio da ação = $55.62 / desvio padrão = $5.10 Adidas =&gt; Valor médio da ação = $24.86 / desvio padrão = $3.60 \\[Coeficiente = (\\frac{\\textrm{Desvio Padrão}}{Média}× 100) \\% \\] CV_Nike = (5.10/55.62) * 100 CV_Adidas = (3.60/24.86) * 100 print(CV_Nike) ## [1] 9.169364 print(CV_Adidas) ## [1] 14.48109 "],["métodos-tabulares-e-métodos-gráficos.html", "6 Métodos tabulares e métodos gráficos 6.1 Tabelas 6.2 Tabelas de contingência 6.3 Definição de Classes 6.4 Frequência Absoluta 6.5 Frequência Relativa 6.6 Frequência acumulada 6.7 Frequência acumulada relativa 6.8 Polígono de frequências 6.9 Histograma 6.10 Gráfico Ogiva de Galton - Frequência Acumulada 6.11 Apresentação Ramo-e-folha 6.12 Coeficiente de Assimetria 6.13 Coeficiente de curtose 6.14 BoxPlot 6.15 Tabulação Cruzada 6.16 Diagrama de Dispersão 6.17 Métodos tabulares e gráficos de sintetizar os dados 6.18 Análise exploratória de dados", " 6 Métodos tabulares e métodos gráficos 6.1 Tabelas Uma tabela resume os dados por meio de linhas e colunas podendo conter, além de linhas e colunas: - Fonte - Chamadas, localizadas no rodapé - Notas - Esclarecimentos acerca dos dados ou apuração - Feitos em algarismos arábicos escritos entre parênteses, e colocados à direita da coluna Ao preencher células/casas deve-se atentar: - utilizar um traço horizontal (_) quando o valor é zero - utilizar três pontos () quando não há dados - utilizar ponto de interrogação (?) quando há dúvida sobre a exatidão do valor - zero (0) quando o valor é muito pequeno para ser expresso pela unidade utilizada 6.2 Tabelas de contingência As tabelas de contingência são utilizadas quando os dados precisam ser classificados de acordo com dois fatores. Dessa forma as tabelas tem duas entradas, cada uma relativa a um fator. Regiões Meses Total Janeiro Fevereiro Março Norte 27 503 23 374 24 198 75 075 Nordeste 72 377 62 618 66 158 201 153 Sudeste 100 531 91 077 96 073 287 681 Sul 35 068 31 331 33 716 100 115 Centro-Oeste 21 439 19 487 21 072 61 998 Fonte: IBGE, 2021 6.3 Definição de Classes Determinar o número de classes não sobrepostas Em geral, usa-se entre 5 - 20 classes. Pode ser adotada fórmula: \\(\\small k - 1+3,3.log(n\\)) n: número total de dados k: número aproximado de classes Determinar a amplitude de cada classe Amplitude = (Maior valor - Menor valor)/ Número de classes Determinar o limite da classe 6.4 Frequência Absoluta Por frequência absoluta, entende-se o número de observações correspondente a cada classe. 6.5 Frequência Relativa A frequência relativa, por sua vez, diz respeito ao quociente entre a frequência absoluta da classe correspondente e a soma das frequências absolutas. \\[FR= \\frac{\\textrm{Frequência da classe} }{ \\textrm{Quantidade total de observações na amostra}}\\] 6.6 Frequência acumulada Soma das frequências das classes anteriores a classe atual analisada. Cores Freq. Abs. Freq. Rel. Freq Rel. (%) Freq. Rel. Ac. Branco 70 0,35 35 35 Preto 50 0,25 25 60 Amarelo 40 0,20 20 80 Azul 20 0,1 10 90 Cinza 15 0,075 7,5 97,5 Roxo 5 0,025 2,5 100 Total 200 1 100 100 6.7 Frequência acumulada relativa Soma das frequências em relação ao total de amostras \\[FAR= \\frac{\\textrm{Frequências acumuladas} }{ \\textrm{Quantidade total de observações na amostra}}\\] 6.8 Polígono de frequências O polígono de frequência é construído utilizando-se dos pontos médios de cada classe para marcar os pontos nas abscissas. Os pontos das ordenadas são traçados pela frequência de cada classe. Exemplo de gráfico polígono de frequência 6.9 Histograma Um histograma é um modelo de gráfico que representa uma distribuição de frequências através de um agrupamento de classes, de forma que se pode contabilizar as ocorrências dos dados em cada classe. Útil para visualizar a distribuição de medidas dispersão simetria dos dados tendências centrais. A soma das áreas de todos os retângulos do histograma deve ser igual a 1. Como fazer um histograma manualmente? Ordenar os valores Encontrar a amplitude total: A = xmax  xmin. Assim, os intervalos devem cobrir uma faixa de, no mínimo, o valor da amplitude. Estimar o número de classes: 2k  n. Sendo que n é igual a raiz quadrada do número total de observações. Estimar o tamanho de cada intervalo de classe: C = A/k Contar o número de observações que caem em cada intervalo de classe (subintervalo), frequência. Determinar a frequência relativa do intervalo: Frequência relativa = frequência/total de observações. Construir o gráfico. Exemplo: Os seguintes dados representam o número de acidentes diários em um complexo industrial (colocados em ordem crescente), durante o período de 50 dias. Represente o histograma desses dados. dados = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29, 30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37,37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45,45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65) hist(dados, main = &quot;Número de Acidentes Diários&quot;, xlab = &quot;Acidentes&quot;, ylab = &quot;Frequência&quot;) hist(dados, main = &quot;Número de Acidentes Diários&quot;, xlab = &quot;Acidentes&quot;, ylab = &quot;Frequência&quot;, breaks = 6) hist(dados, main = &quot;Número de Acidentes Diários&quot;, xlab = &quot;Acidentes&quot;, ylab = &quot;Frequência&quot;, breaks = 5) 6.10 Gráfico Ogiva de Galton - Frequência Acumulada O gráfico de uma distribuição cumulativa se chama ogiva, onde os dados se encontram no eixo horizontal e as frequências cumulativas, relativas cumulativas ou frequências percentuais cumulativas no eixo vertical. No eixo horizontal são utilizados os pontos extremos de cada classe. 6.11 Apresentação Ramo-e-folha A apresentação de ramo-e-folha pode ser usada para mostrar simultaneamente tanto a ordem de classificação como a forma de dados. Para desenvolver uma apresentação de ramo-e-folha organiza-se primeiramente os dígitos à esquerda de cada valor de dados à esquerda de uma linha vertical. À direita da linha vertical, registrando o último dígito de cada valor de dados. As folhas podem valer 1, 10, 100 para tornar a apresentação mais legível. 6.12 Coeficiente de Assimetria O coeficiente de assimetria é o que permite dizer se uma determinada distribuição é assimétrica ou não. A assimetria da amostra pode ser calculada por: \\[Assimetria =\\frac{n}{(n -1)(n -2)} \\sum \\frac{(x_{i} - \\bar{x})}{s}^3\\] Inclinação à direita: assimetria positiva Média &gt; Mediana Inclinação à esquerda: assimetria negativa Média &lt; Mediana 6.12.1 R Exemplo: Os seguintes dados representam o número de acidentes diários em um complexo industrial (colocados em ordem crescente), durante o período de 50 dias. Represente o histograma desses dados. dados = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29, 30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37, 37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45, 45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65) hist(dados, main = &quot;Número de Acidentes Diários&quot;, xlab = &quot;Acidentes&quot;, ylab = &quot;Frequência&quot;) mean(dados) ## [1] 38.32 sd(dados) ## [1] 11.58366 median(dados) ## [1] 37 library(moments) SK = skewness(dados) print(SK) ## [1] 0.2549279 Sk  0: dados simétricos. Tanto a cauda do lado direito quanto a do lado esquerdo da função densidade de probabilidade são iguais. Sk &lt; 0: assimetria negativa. A cauda do lado esquerdo da função densidade de probabilidade é maior que a do lado direito. Sk &gt; 0: assimetria positiva. A cauda do lado direito da função densidade de probabilidade é maior que a do lado esquerdo. O coeficiente de assimetria é 0.2549279. Como o coeficiente de assimetria é maior que 0, diz-se que a curva apresenta assimetria positiva e a cauda do lado direito da função densidade de probabilidade é maior que no lado esquerdo. Ao observar também o Histograma, percebe-se que há maior densidade de dados do lado direito. Outro exemplo set.seed(1234) x = rnorm(1000) hist(x) skewness(x) ## [1] -0.005202026 6.13 Coeficiente de curtose O coeficiente de curtose é uma medida que caracteriza o achatamento da curva da função de distribuição. 6.13.1 R Exemplo: Os seguintes dados representam o número de acidentes diários em um complexo industrial (colocados em ordem crescente), durante o período de 50 dias. Represente o histograma desses dados. dados = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29,30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37,37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45, 45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65) hist(dados, main = &quot;Número de Acidentes Diários&quot;, xlab = &quot;Acidentes&quot;, ylab = &quot;Frequência&quot;) mean(dados) ## [1] 38.32 sd(dados) ## [1] 11.58366 median(dados) ## [1] 37 library(moments) CK = kurtosis(dados) print(CK) ## [1] 2.37652 CK  0: Distribuição normal. Chamada de Curtose Mesocúrtica. CK &lt; 0: Cauda mais leve que a normal. Para um coeficiente de Curtose negativo, tem-se uma Curtose Platicúrtica. CK &gt; 0: Cauda mais pesada que a normal. Para um coeficiente de Curtose positivo, tem-se uma Curtose Leptocúrtica. O coeficiente de curtose é igual a 2.37652. Logo, como o valor de CK é maior que 0, a curva é Leptocúrtica. Outro exemplo n.sample &lt;- rnorm(n = 10000, mean = 55, sd = 4.5) #Skewness e Kurtosis library(moments) skewness(n.sample) ## [1] 0.001526792 kurtosis(n.sample) ## [1] 2.958097 #Histograma library(ggplot2) datasim &lt;- data.frame(n.sample) ggplot(datasim, aes(x = n.sample), binwidth = 2) + geom_histogram(aes(y = ..density..), fill = &#39;red&#39;, alpha = 0.5) + geom_density(colour = &#39;blue&#39;) + xlab(expression(bold(&#39;Dados&#39;))) + ylab(expression(bold(&#39;Densidade&#39;))) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 6.14 BoxPlot Box-plot, ou diagrama de caixa, é possível obter informações sobre vários aspectos dos dados simultaneamente como, outliers, dispersão, tendências centrais, erros padrão e simetria. Utilizado para avaliar a distribuição empírica dos dados, é formado pelo primeiro e terceiro quartis, juntamente com a mediana. dados = c(18, 20, 20, 21, 22, 24, 25, 25, 26, 27, 29, 29,30, 30, 31, 31, 32, 33, 34, 35, 36, 36, 37, 37,37, 37, 38, 38, 38, 40, 41, 43, 44, 44, 45, 45,45, 46, 47, 48, 49, 50, 51, 53, 54, 54, 56, 58, 62, 65) mean(dados) ## [1] 38.32 sd(dados) ## [1] 11.58366 median(dados) ## [1] 37 range(dados) ## [1] 18 65 quantile(dados) ## 0% 25% 50% 75% 100% ## 18.00 30.00 37.00 45.75 65.00 boxplot(dados, main = &quot;Número de Acidentes Diários&quot;) 6.15 Tabulação Cruzada A tabulação cruzada (Cross table) é um sumário tabular de dados para duas variáveis. Muito útil para se analisar a relação entre duas variáveis Por exemplo, a tabela abaixo (incompleta) pode ser sumarizada de forma a tornar mais fácil a leitura: Restaurant Quality Rating Meal Price ($) 1 Good 18 2 Very Good 22 3 Good 28 4 Excellent 38 5 Very Good 33 6 Good 28 7 Very Good 19 8 Very Good 11 9 Very Good 23 10 Good 13 Avaliação Frequência Relativa Frequência Percentual Bom 0,28 28% Ótimo 0,50 50% Excelente 0,22 22% Total 1 100% Preço Frequência Relativa Frequência Percentual $10-19 0,26 26% $20-29 0,39 39% $30-39 0,25 25% $40-49 0,09 9% Total 1 100 Tabela Cruzada - Avaliação X Preço Avaliação $10-19 $20-29 $30-39 $40-49 Total Bom 42 40 2 0 84 Ótimo 34 64 46 6 150 Excelente 2 14 28 22 66 Total 78 118 76 28 300 Tabela Cruzada - Avaliação X Preço - Porcentagens por linha Avaliação $10-19 $20-29 $30-39 $40-49 Total Bom 50% 47,6% 2,4% 0% 100% Ótimo 22,7% 42,7% 30,6% 4% 100% Excelente 3% 21,2% 42,4% 33,4% 100% 6.15.1 Paradoxo de Simpson Quando duas ou mais tabulações cruzadas são combinadas ou agregadas, chamamos a tabulação resultante de tabulação cruzada resumida ou tabulação cruzada agregada. Em tais tabulações pode ocorrer um fenômeno chamado Paradoxo de Simpson, no qual, a conclusão baseada na tabulação cruzada agregada é completamente inversa a conclusão baseada nos dados não-agregados. Juiz Veredito Luckett Kendall Confirmado 129 (86%) 110 (88%) Revertido 21 (14%) 15 (12%) Total(%) 150 (100%) 125 (100%) Conclusão: Juiz Kendall teve menos veredictos convertidos que o juiz Luckett, logo faz um melhor trabalho. Porém, ao observar os dados menos resumidos. Juiz Luckett Juiz Kendall Veredito Apelação Comum Confirmado 29 (91%) Convertido 3 (9%) Total 32 (100%) Conclusão: Juiz Luckett tem percentualmente, mais confirmacao e menos conversões, em ambas as classes, que o juiz kendall. Logo, Luckett faz uma trabalho melhor. 6.16 Diagrama de Dispersão Um diagrama de dispersão é uma apresentação gráfica da relação existente entre duas variáveis e uma linha de tendência é uma linha que fornece uma aproximação da relação. Graficos de dispersão e as diferentes interpretações em relação a correção entre as variáveis 6.17 Métodos tabulares e gráficos de sintetizar os dados 6.18 Análise exploratória de dados Regra dos cinco itens Menor valor Primeiro Quartil (Q1) Mediana(Q2) Terceiro Quartil(Q3) Maior Valor Todos estes pontos podem ser encontrados num BoxPlot O limite inferior é dado por Q3+ 1,5 AIQ O limite superior é dado por Q1- 1,5 AIQ "],["medidas-de-associação-entre-duas-variáveis.html", "7 Medidas de associação entre duas variáveis 7.1 Covariância 7.2 Coeficiente de correlação", " 7 Medidas de associação entre duas variáveis 7.1 Covariância \\[ \\frac{S_{xy}=(x_{i} - \\bar{x} )(y_{i} - \\bar{y} )}{n - 1} \\] \\[\\frac{ \\sigma_{xy}=\\sum (x_{i} - \\bar{x} )(y_{i} - \\bar{y} )} {N}\\] A covariância entre duas variáveis (X, Y) é uma medida de variabilidade conjunta dessas duas variáveis aleatórias, ou seja, a correlação linear entre duas variáveis, sendo X a variável independente (ou explanatória) e Y a variável dependente (ou resposta). - Quando a covariâncias entre essas variáveis é positiva os dados apresentam tendência positiva na dispersão. - Quando o valor da covariância é negativo, o comportamento é análogo, no entanto, os dados apresentam tendências negativas. A covariância é uma medida de como as alterações em uma variável estão associadas a mudanças em uma segunda variável. Especificamente, a covariância mede o grau em que duas variáveis estão linearmente associadas. No entanto, também é frequentemente usado informalmente como uma medida geral de como duas variáveis são monotonicamente relacionadas. 7.1.1 R #cov(x,y) 7.2 Coeficiente de correlação Também chamado de correlação momento-produto de Pearson Para amostra: \\[\\small r_{xy} =\\frac{S_{xy}} {S_{x}S_{y}}\\] \\(\\small r_{xy}=\\textrm{ coeficiente de correlação da amostra}\\) \\(\\small S_{xy}= \\textrm{covariância da amostra}\\) \\(\\small S_x = \\textrm{desvio padrão da amostra de x}\\) \\(\\small S_y = \\textrm{desvio padrão da amostra de y}\\) Para população: \\[ \\small \\rho_{xy} = \\frac{\\sigma_{xy}} {\\sigma_{x} \\sigma_{y}}\\] \\(\\small \\rho_{xy}= \\textrm{coeficiente de correlação da população}\\) \\(\\small \\sigma_{xy}= \\textrm{covariância da população}\\) \\(\\small \\sigma_x = \\textrm{desvio padrão da população para x}\\) \\(\\small \\sigma_y = \\textrm{desvio padrão da população para y}\\) A correlação é uma versão em escala de covariância que assume valores em [1,1] com uma correlação de ± 1 indicando associação linear perfeita e 0 indicando nenhuma relação linear. - Diferença - Esse escalonamento torna a correlação invariante às mudanças na escala das variáveis originais A constante de escala é o produto dos desvios padrão das duas variáveis. Portanto, o Coeficiente de Correlação p mede o grau de correlação entre duas variáveis, a qualidade da relação entre as variáveis. - p entre 90% e 100%: alta ou ótima correlação - p entre 80% e 90%: boa correlação - p entre 60% e 80%: média correlação - p entre 40% e 60% baixa correlação - p entre 0 40%: péssima correlação Para p = 1, tem-se uma correlação perfeita entre as duas variáveis. Isso significa que y aumenta com x Para p = 0, as duas variáveis não dependem linearmente uma da outra, não há associação entre as duas variáveis (x e y) Para p = - 1, há uma correlação perfeita entre as variáveis, no entanto, essa correlação é negativa. Isso significa que toda vez que x aumenta, y diminui 7.2.1 R Exemplo: Analisar a covariância e correlação entre as variáveis milhas/galão e peso do veículo no dataset mtcars. my_data &lt;- mtcars my_data ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 library(&quot;ggpubr&quot;) ggscatter(my_data, x = &quot;mpg&quot;, y = &quot;wt&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, cor.coef = TRUE, cor.method = &quot;pearson&quot;, xlab = &quot;Autonomia&quot;, ylab = &quot;Peso do Veículo&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; # Definindo x e y x = my_data$mpg y = my_data$wt # Covariância cov(x, y) ## [1] -5.116685 # Correlação cor(x, y) ## [1] -0.8676594 "],["amostragem-1.html", "8 Amostragem 8.1 Probabilística 8.2 Não probabilística 8.3 Estimação por ponto 8.4 Estimação por intervalo 8.5 Teorema do Limite Central", " 8 Amostragem .highlightRed { background-color:#ffcdd2; } .highlightBlue { background-color:#bbdefb; } .highlightGreen { background-color:#a2fca2; } .highlightAmber { background-color:#ffecb3; } A amostragem é a técnica, processo ou pesquisa que podem ser realizadas para obter uma amostra. A qual utiliza-se coleta, organização, apresentação e análise dos dados como meio de estudar os parâmetros de uma população. Faz-se uso da amostragem devido ao fato de nem sempre ser possível ou desejável testar toda a população para se obter os parâmetros e conclusões desejadas. A amostragem é uma estimativa, e portanto tal, se torna mais assertiva pelo uso de técnicas de amostragem e pela regulação dos níveis de confiança. Prós Economia de tempo e dinheiro Pode-se obter uma acurácia/ precisão muito próxima do uso da população A margem de erro pode ser calculada Contras Não pode ser feito de qualquer jeito É preciso conhecimento e aplicação de técnicas Pontos de atenção O encaixe da técnica x dados x objetivos precisa ser bem avaliada Caso contrário irá produzir anomalias que irão inutilizar os dados 8.1 Probabilística Características Objetiva Escolha aleatória Sorteio não viciado Probabilidade conhecida dos elementos serem escolhidos todos têm alguma chance de serem escolhidos Distribuição amostral pode ser identificada Erro amostral pode ser calculado - amostragem pode ser avaliada 8.1.1 Aleatória simples 8.1.1.1 População Finita Trata-se de uma coleta dentro de uma população finita onde todos os elementos têm a mesma probabilidade de serem selecionados. Comumente é utilizada de sem substituição ( após um elemento ser selecionado ele sai da lista. Para tanto, é feita a coleta na população até que se obtenha o tamanho da amostra desejado, por meio de um método de sorteio não viciado, onde pode-se realizar a amostragem com ou sem substituição. 8.1.1.2 População Infinita São consideradas populações infinitas: Populações não contadas / listadas Populações muito grandes Populações contínuas (cliente em um restaurante) Nesses casos, para que a amostragem seja feita de forma correta, deve-se satisfazer as seguintes condições: Cada elemento selecionado vem dessa população Cada elemento é selecionado de forma independente O número de amostras aleatórias simples de tamanho n que podem ser obtidas de uma população infinita tamanho N é dado por: \\[\\frac{N!}{n!(N - n!)}\\] 8.1.1.3 População Amostrada A amostra coletada não se dá exatamente da população de interesse (população alvo) mas de uma população mais acessível, conveniente. Ex. Busca-se conhecer os hábitos noturno de mulheres divorciadas com mais de 40 anos. Para tanto se extrai uma amostra em uma grande cidade para estudo. População alvo: mulheres divorciadas com mais de 40 anos do país População amostrada: mulheres divorciadas com mais de 40 anos da cidade amostrada Pode-se então obter conclusões válidas apenas para os elementos da grande cidade (população amostrada), mas se pode usar o julgamento do pesquisados para extrapolar os resultados para a população alvo (com cautela e reservas). 8.1.2 Sistemática A amostragem sistemática é útil quando se trata de grandes populações, onde seria um trabalho muito dispendioso utilizar o método da amostragem aleatória simples. A partir da definição do tamanho da amostra desejado, o índice é definido a partir da fórmula: \\[i = \\frac{N}{n}\\] \\(i = índice\\) \\(n = \\textrm{ tamanho da amostra desejada}\\) \\(N =\\textrm{tamanho da população}\\) A partir do índice, pode-se escolher duas abordagens: Selecionar aleatoriamente um dos primeiros i elementos da lista da população E selecionar na lista, a partir do elemento anteriormente escolhido, o i° elemento, seguidas vezes, até completar a amostra desejada Por exemplo, a cada 100 biscoitos que passam na linha de produção, um é selecionado para teste. A desvantagem é que a população precisa ser listada e estando ordenada, precisa-se ter cuidado para não haver algum tipo de periodicidade nos dados. E precisa ser o mais homogênea possível, para não haver enviesamento. 8.1.3 Estratificada Na amostragem aleatória estratificada os dados são divididos em estratos (grupos), de forma sistemática, de forma que cada elemento pertença a somente um estrato. Um estrato pode ser formado a partir de : idade, departamento, local, tipo de indústria, etc. Os melhores resultados são obtidos quando os elementos de um estrato são os mais similares possíveis. Pois quanto maior a homogeneidade do grupo, menor o enviesamento da amostra. Após ser formado os estratos, uma amostra aleatória simples é extraída de cada um deles. Há fórmulas disponíveis para se combinar os resultados das amostras de estrato individuais em uma estimativa do parâmetro populacional de interesse. 8.1.4 Conglomerados (cluster) Na amostragem por conglomerados os elementos da população são divididos em grupos distintos chamados de conglomerados, onde cada elemento pertence somente a um conglomerado. Os conglomerados devem ser o mais diversos possível, pois devem ser uma pequena amostra representativa da população. Uma das principais aplicações da amostragem por conglomerados é a amostragem por áreas, em que os conglomerados são quarteirões de uma cidade ou outras áreas bem definidas. A amostragem por conglomerados geralmente requer uma amostra maior que a amostragem aleatória simples ou a amostragem aleatória estratificada. 8.1.5 Reamostragem (bootstrap) Características Várias amostras (com reposição) são repetidamente extraídas da população pode-se estimar parâmetros da população como média e proporção 8.2 Não probabilística Características Subjetiva -&gt; decisão do pesquisador Não tem a mesma probabilidade entre si de serem escolhidos Probabilidade dos elementos serem escolhidos é desconhecida Não é possível avaliar a qualidade dos dados amostrais em relação à população Ex Pesquisa social 8.2.1 Conveniência ou acessibilidade A amostragem por conveniência é uma técnica onde a amostra é identificada primeiramente por conveniência. Os elementos são incluídos sem probabilidades previamente especificadas ou conhecidas de serem selecionada. São exemplos: selecionar laranjas de engradados aleatórios (contar e rotular todas as laranjas seria impraticável) grupos de voluntários para pesquisa de consumidores (são voluntários, não aleatórios) captura de animais selvagens para análise de hábitos ( não é aleatório, ou rotulado, é o que estava disponível) A vantagem da amostra por conveniência é a facilidade de coleta e análise dos dados, entretanto, não se pode avaliar a excelência da amostral em termos da sua representatividade em relação à população. 8.2.2 Intencional ou por Julgamento Na amostragem por julgamento, o pesquisador escolhe os elementos que considera serem os mais representativos da população. Por exemplo, selecionar como amostra a opinião de dois ou três senadores, julgando que estes representam a opinião geral de todos os senadores. No caso, a qualidade da amostra depende da qualidade do julgamento da pessoa que faz a escolha. 8.3 Estimação por ponto As médias(\\(\\bar{x}\\)), desvios padrão(\\(s\\)) e proporções (\\(\\bar{p}\\)) entrados em amostras são chamadas estimação por ponto da média(\\(\\mu\\)), desvio padrão(\\(\\sigma\\)) e proporção da população(\\(p\\)). Parâmetro = População Estatística amostral = amostra Quando o valor esperado de um estimador por ponto é igual ao parâmetro populacional, o estimador é considerado sem viés. 8.3.1 Distribuição amostral de \\(\\bar{x}\\) \\(\\bar{x}\\) = média da amostra Qualquer estimação por ponto possui uma margem de erro, como pode ser observado no exemplo abaixo: Parâmetros Populacionais Valor Parâmetros Amostrais Valor  - Salário Médio anual 51.800 \\(\\bar{x}\\) - Salário Médio anual 51.814  - Desvio Padrão do salário 4.000 s -Desvio Padrão do salário 3.348 p - Proporção da população que concluiu o programa de treinamento gerencial 0,60 \\(\\bar{p}\\) - Proporção da população que concluiu o programa de treinamento gerencial 0,63 Para diminuir o erro da estimação de média, podemos realizar diversas coletas de amostras na população e tirar a média de cada uma dessas amostras. Como \\(\\bar{x}\\) também é uma variável aleatória e podemos a partir dela fazer uma distribuição amostral. A tabela de distribuição de frequência abaixo ilustra o processo de coleta de 500 amostras aleatórias numa população de 2500 registros. Salário Anual Médio ($) Frequência Frequência Relativa 49.500,00 - 49.999,99 2 0,004 50.000,00 - 50.499,99 16 0,032 50.500,00 - 50.999,99 52 0,104 51.000,00 - 51.499,99 101 0,202 51.500,00 - 51.999,99 133 0,266 52.000,00 - 52.499,99 110 0,220 52.500,00 - 52.999,99 54 0,108 53.000,00 - 53.499,99 26 0,052 53.500,00 - 53.999,99 6 0,012 Total 500 1 amostra = read.csv(file = &quot;data/EAI.csv&quot;, sep = &quot;,&quot;, as.is = F) str(amostra) ## &#39;data.frame&#39;: 2500 obs. of 2 variables: ## $ Salary : num 55770 50823 48408 49788 52802 ... ## $ Training: Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 1 1 2 1 2 1 2 1 ... media_amostras &lt;- c() proporcao_amostras &lt;- c() for(i in 1:500) { coleta = sample(amostra$Salary,30, replace = T) media_amostras &lt;- append(mean(coleta),media_amostras) coleta = sample(amostra$Training,30, replace = T) proporcao_amostras &lt;-append(prop.table(table(coleta))[&quot;Yes&quot;],proporcao_amostras) } hist(media_amostras, breaks = seq(40000, 60000, 500 ), main = &quot;Histograma de frequência relativa dos valores da média de \\n 500 amostras aleatórias simples com tamanho 30 cada uma&quot;, ylab = &quot;Frequência Relativa&quot;, xlab = &quot;Valores das médias das amostras&quot;) hist(proporcao_amostras, breaks = seq(0.10,0.99,0.08),main = &quot;Histograma de frequência relativa dos valores da proporção de \\n 500 amostras aleatórias simples com tamanho 30 cada uma&quot;, ylab = &quot;Frequência Relativa&quot;, xlab = &quot;Valores médios das proporções das amostras&quot;) A distribuição amostral de x é a distribuição de probabilidade de todos os valores possíveis da amostrais de x 8.3.1.1 Valor esperado É a média de todos os possíveis valores de x que podem ser gerados a partir das amostras aleatórias simples. \\[ E (\\bar{x}) = \\mu \\] 8.3.1.2 Desvio Padrão O desvio padrão de \\(\\bar{x}\\) é chamado de erro padrão da média. Em geral, o termo erro padrão se refere ao desvio padrão de um estimador por ponto. Neste caso será útil para demonstrar quão distante a média amostral se encontra da média da população. 8.3.1.2.1 População Finita \\[\\sigma_{\\bar{x}}=\\sqrt{\\frac{N - n} {N - 1} (\\frac{\\sigma} {\\sqrt{n}})}\\] \\(\\sqrt{\\frac{N-n}{N-1}}\\) = Fator de correção para populações finitas 8.3.1.2.2 População Infinita Utiliza-se esta fórmula para populações infinitas e populações finitas onde o tamanho da amostra for menor ou igual a 5% do tamanho da população, ou seja, \\(\\frac{n}{N} 0,05\\). Isto porque, o fator de correção para populações finitas terá pouca influência sobre o resultado. \\[\\sigma_{\\bar{x}}=\\frac{\\sigma} {\\sqrt{n}}\\] No exemplo acima temos que: \\(\\frac{n}{N} 0,05\\) \\(\\frac{30}{2500} = 0,012 0,05\\) Portanto utilizaremos a fórmula da população infinita. \\[\\sigma_{\\bar{x}}=\\frac{\\sigma} {\\sqrt{n}}\\] \\(\\sigma_{\\bar{x}}=\\frac{4000} {\\sqrt{30}}=730,3\\) 8.3.1.3 Forma da Distribuição Amostral de \\(\\bar{x}\\) Dado o Teorema do Limite Central, podemos afirmar que a amostra de gerentes está normalmente distribuída, pelo fato de n  30. O valor da média da amostra é sempre utilizada para aproximar o valor da média da população. Porém, como se pode saber o quão aproximada essa média se encontra? Se o observarmos a média das 500 amostras, veremos que algumas se distanciam em torno de 2 mil dólares da média da população, no caso, seria aceitável uma amostra que se distancia tanto da média da população? Caso fosse solicitado que a média da amostra estivesse dentro de 500 dólares da média da população, qual a probabilidade disso ocorrer? Sabendo-se que a média populacional é de 51.800, qual a probabilidade da média amostral estar entre 51.300 e 52.300? A probabilidade é dada pela área sob a curva sombreada: A fórmula correspondente seria então: \\[ z = \\frac{x_1 - \\mu} {\\sigma_\\bar{x}} \\] \\(z = \\frac{51.300 - 51.800}{730,3} = - 0,68\\) \\[ z = \\frac{x_2 - \\mu} {\\sigma_\\bar{x}} \\] \\(z = \\frac{52.300 - 51.800}{730,3} = 0,68\\) Consultando a tabela da distribuição normal verificamos a área entre \\(z = 0\\) e \\(z = 0,68\\) é \\(0,2517\\) \\(z = 0\\) e \\(z = -0,68\\) é \\(0,2517\\) Portanto, a probabilidade de o valor da média da amostra estar entre 51.300 - 52.300 é 0,2517 + 0,2517 = 0,5034. E analogamente, a probabilidade da amostra estar fora do intervalo de 51.300 - 52.300 é de 1 - 0,5034 = 0,4966 Portanto, a probabilidade é de aproximadamente 50-50 de produzir uma média amostral dentro dos limites de 500 dólares. Seria uma tamanho de amostra maior a solução para que a probabilidade da média fique contida no intervalo ? Dada uma amostra de n = 100 teremos um erro amostral (desvio padrão): \\[ \\sigma_\\bar{x} = \\frac{\\sigma}{\\sqrt{n}} \\] \\(\\sigma_\\bar{x} = \\frac{4000}{\\sqrt{100}}=400\\) Como podemos observar, o erro padrão diminui, portanto a distribuição muda de forma, se torna mais acentuada: mean=51800; sd=730.3; sd_2 &lt;-400 lcb &lt;- ((mean - (3 * sd)) - 5) ucb &lt;- ((mean + (3 * sd)) + 5) u &lt;- seq(from = lcb, to = ucb) v1 &lt;- dnorm(x = u, mean = mean, sd = sd) v2 &lt;- dnorm(x = u, mean = mean, sd = sd_2) ggplot(data = data.frame(u = c(lcb, ucb)), mapping = aes(x = u)) + stat_function(mapping = aes(colour = &quot;n=30 sd=730.3&quot;), fun = dnorm, args = list(mean = mean, sd = sd)) + stat_function(mapping = aes(colour = &quot;n=100 sd=400&quot;), fun = dnorm, args = list(mean = mean, sd = sd_2)) + scale_colour_manual(values = c(&quot;red&quot;, &quot;blue&quot;)) + labs(x = &quot;salários&quot;, y = &quot;densities&quot;, title = &quot;Comparação entre distribuições com 30 e 100 elementos para \\n amostras aleatórias simples dos salários dos gerentes EAI&quot;) Agora, se formos considerar a probabilidade da média amostral se encontrar em torno de 500 dolares da média populacional teremos: \\[z = \\frac{x_1 - \\mu}{ \\sigma_\\bar{x}}\\] \\(z = \\frac{51.300 - 51.800}{400} = -1,25\\) \\[z = \\frac{x_2 - \\mu}{ \\sigma_\\bar{x}}\\] \\(z = \\frac{52.300 - 51.800}{400} = 1,25\\) Consultando a tabela da distribuição normal verificamos a área entre \\(z = 0\\) e \\(z = 1,25\\) é \\(0,3944\\) \\(z = 0\\) e \\(z = -1,25\\) é \\(0,3944\\) Portanto, a probabilidade de o valor da média da amostra estar entre 51.300 - 52.300 é 0,3944 + 0,3944 = 0,7888. E analogamente, a probabilidade da amostra estar fora do intervalo de 51.300 - 52.300 é de 1 - 0,5034 = 0,2112 Portanto, a probabilidade do intervalo (51.300 - 52.300 ) conter a média populacional aumentou de 0,5034 para 0,7888 Obs: Demonstrações teóricas do teorema do limite central requerem observações independentes, ou seja, amostragem com substituição. lb&lt;-51300 ub&lt;-52300 sd&lt;-400 mean&lt;-51800 pnormGC(c(lb,ub),region=&quot;between&quot;,mean=mean, sd=sd,graph=TRUE) ## [1] 0.7887005 8.3.2 Distribuição amostral de \\(\\bar{p}\\) A proporção amostral \\(\\bar{p}\\) é o estimador por ponto da proporção p da população. E é dado por: \\[\\bar{p} =\\frac{x}{n}\\] \\(x =\\textrm{número de elementos da amostra com a característica de interesse}\\) \\(n = \\textrm{o tamanho da amostra}\\) 8.3.2.1 Valor esperado de \\(\\bar{p}\\) O valor esperado de \\(\\bar{p}\\) , que é a média de todos os valores possíveis de \\(\\bar{p}\\) , é igual a proporção populacional de p \\[E(\\bar{p} ) = p\\] \\(E(\\bar{p} )= \\textrm{o valor esperado de } \\bar{p}\\) \\(p = \\textrm{proporção populacional}\\) 8.3.2.2 Desvio padrão de \\(\\bar{p}\\) O desvio padrão de \\(\\bar{p}\\) é chamado de erro padrão da proporção. Em geral, o termo erro padrão se refere ao desvio padrão de um estimador por ponto. Neste caso será útil para demonstrar quão distante a proporção amostral se encontra da proporção da população. 8.3.2.2.1 População Finita \\[\\sigma_\\bar{p} = \\sqrt{\\frac{N-n}{N-1}} \\sqrt{\\frac{p(1 - p)}{n}}\\] \\(\\sqrt{\\frac{N-n}{N-1}}= \\textrm{Fator de correção para populações finitas}\\) 8.3.2.2.2 População Infinita Utiliza-se esta fórmula para populações infinitas e populações finitas onde o tamanho da amostra for menor ou igual a 5% do tamanho da população, ou seja,\\(\\frac{n}{N}0,05\\) . Isto porque, o fator de correção para populações finitas terá pouca influência sobre o resultado. \\[\\sigma_\\bar{p} = \\sqrt{\\frac{p(1 - p)}{n}}\\] No exemplo acima, temos que: \\(\\frac{n}{N}\\) 0,05 \\(\\frac{30}{2500}= 0,012  0,05\\) Portanto utilizaremos a fórmula da população infinita: \\[\\sigma_\\bar{p} = \\sqrt{\\frac{p(1 - p)}{n}}\\] \\(\\sigma_\\bar{p} = \\sqrt{\\frac{0,60(1 - 0,60)}{100}} = 0,0894\\) Se amostra fosse aumentada para 100: \\[\\sigma_\\bar{p} = \\sqrt{\\frac{p(1 - p)}{n}}\\] \\(\\sigma_\\bar{p} = \\sqrt{\\frac{0,60(1 - 0,60)}{100}} = 0,049\\) 8.3.2.3 Forma da distribuição amostral de \\(\\bar{p}\\) Agora para determinarmos a forma da distribuição de \\(\\bar{p}\\), devemos considerar que esta se trata de uma variável aleatória binomial (ou é característica específica ou não ( sucesso ou fracasso) que indica o número de elementos na população que possuem a variável de interesse. Dado que a proporção é dada por \\(\\bar{p} = \\frac{x}{n}\\) e n é uma constante, a probabilidade \\(\\frac{x}{n}\\) é idêntica a probabilidade binomial de x, o que significa que a distribuição amostral de \\(\\bar{p}\\) também é uma distribuição discreta de probabilidade e que a probabilidade correspondente a cada valor de \\(\\frac{x}{n}\\) é idêntica a probabilidade binomial de x. Sendo satisfeitas as condições: \\(n × p  5\\) \\(n ( 1 - p)  5\\) A distribuição de probabilidade de x pode ser aproximada por meio de uma distribuição normal. E desde que n seja uma constante a distribuição amostral de \\(\\bar{p} = \\frac{x}{n}\\) também pode. Caso fosse desejado saber a probabilidade da proporção amostral se encontrar em 0,05 da média populacional, teríamos: \\(P( 0,55- 0,65)\\) \\[z = \\frac{x_1 - \\mu}{ \\sigma_\\bar{x}}\\] \\(z = \\frac{0,55 - 0,60}{ 0,0894}=-0,56\\) \\[z = \\frac{x_2 - \\mu}{ \\sigma_\\bar{x}}\\] \\(z = \\frac{0,65 - 0,60}{ 0,0894}= 0,56\\) Consultando a tabela da distribuição normal verificamos a área entre \\(z = 0\\) e \\(z = 0,56\\) é \\(0,2123\\) \\(z = 0\\) e \\(z = -0,56\\) é \\(0,2123\\) Portanto, a probabilidade de o valor da proporção da amostra estar entre 0,55- 0,65 é 0,2123 + 0,2123 = 0,4246. lb&lt;-0.55 ub&lt;-0.65 mean&lt;-0.60 sd&lt;-0.0894 pnormGC(c(lb,ub),region=&quot;between&quot;,mean=mean, sd=sd,graph=TRUE) ## [1] 0.4240322 E analogamente, a probabilidade da amostra estar fora do intervalo de 0,55- 0,65 é de 1 - 0,4246 = 0,5754 Se a amostra fosse aumentada para 100: \\[z = \\frac{x_1 - \\mu}{ \\sigma_\\bar{x}}\\] \\(z = \\frac{0,55 - 0,60}{ 0,049}=-1,02\\) \\[z = \\frac{x_2 - \\mu}{ \\sigma_\\bar{x}}\\] \\(z = \\frac{0,65 - 0,60}{ 0,049}= 1,02\\) Consultando a tabela da distribuição normal verificamos a área entre \\(z = 0\\) e \\(z = 1,02\\) é \\(0,3461\\) \\(z = 0\\) e \\(z = -1,02\\) é \\(0,3461\\) Portanto, a probabilidade de o valor da proporção da amostra estar entre 0,55- 0,65 é 0,3461 + 0,3461 = 0,6922. E analogamente, a probabilidade da amostra estar fora do intervalo de 0,55- 0,65 é de 1 - 0,6922 = 0,3078 lb&lt;-0.55 ub&lt;-0.65 mean&lt;-0.60 sd&lt;-0.049 pnormGC(c(lb,ub),region=&quot;between&quot;,mean=mean, sd=sd,graph=TRUE) ## [1] 0.6924651 8.4 Estimação por intervalo Dado que um estimador por ponto é uma estatística da amostra usada para estimar um parâmetro populacional e que não se pode esperar que um estimador produza o valor exato da do parâmetro populacional, uma estimação por intervalo frequentemente é calculada adicionando ou subtraindo-se um valor, denotado de margem de erro, ao estimador por ponto. A forma geral da estimação por ponto é dada por: Estimação por ponto ± Margem de erro A finalidade de uma estimação por intervalo é fornecer informações sobre o quão próximo o estimador por ponto, produzido pela amostra, está do valor do parâmetro populacional. 8.4.1 Média da população : Desvio Padrão ()Conhecido Para desenvolver uma estimação por intervalo da média populacional o desvio padrão da população  ou o s da amostra devem ser conhecidos para se calcular a margem de erro . Sendo o  desconhecido, utiliza-se o s. Tendo-se grandes quantidades de dados históricos, pode-se calcular o  da população antes de se fazer a amostragem, assim como em situações de controle de qualidade nas quais se supõe que um processo esteja operando corretamente. Exemplo: Dado um histórico de compras normalmente distribuído, de desvio padrão de 20 dólares, uma amostra de 100 clientes é retirada e obtendo-se uma média ${x}= 82 $ dólares por compra. Sabemos, que a estimação por ponto possui um erro padrão (desvio padrão da estimação por ponto) de: \\[\\sigma_x=\\frac{\\sigma}{\\sqrt{n}}\\] \\(\\sigma_x=\\frac{20}{\\sqrt{100}} =2\\) Consultando a tabela de score z sabemos que numa distribuição normal, 95% dos valores estarão contidos em um desvio padrão de ±1,96 desvio padrão da média. Sabendo então que o desvio padrão da amostra é 2: \\(1,96 × \\sigma\\) \\(1,96 × 2 = 3,92\\) Podemos então concluir que 95% de todos os valores da média da amostra (\\(\\bar{x}\\)) estarão contidos em ± 3,92 da média populacional \\(\\mu\\). \\(82 + 3,92 = 85,92\\) \\(82 - 3,92 = 78,08\\) mean&lt;-82 sd&lt;-2 qnormGC(0.95,region=&quot;between&quot;,mean=mean, sd=sd,graph=TRUE) ## [1] 78.08007 85.91993 Portanto, podemos concluir com grau de confiança de 95% que o intervalo de 78,08 - 85,92 contém a média populacional . 0,95 = coeficiente de confiança 78,08 - 85,92 = intervalo de confiança de 95% A forma geral da estimação por intervalo é dada por: \\[\\bar{x} ± z_\\frac{\\alpha}{2} \\frac{\\sigma}{\\sqrt{n}} \\] \\(( 1 - \\alpha) = \\textrm{coeficiente de confiança}\\) \\(\\alpha = \\textrm{Nível de significância}\\) \\(z_\\frac{}{2} = \\textrm{é o valor de z que produz uma área de /2 na cauda superior da distribuição normal padrão de probabilidade}\\) \\(z_\\frac{\\alpha}{2} = \\textrm{Semi amplitude}\\) 8.4.2 Média da população: Desvio Padrão ( ) Desconhecido Quando o  populacional é desconhecido é necessário utilizar-se a mesma amostra para se estimar o  e o  . Nos casos em que o s é usado para estimar o  a margem de erro e a estimação por intervalo da média populacional baseiam-se em uma distribuição de probabilidade chamada de Distribuição t. Isso porque como não se trabalha com o Desvio Padrão da população, não se pode mais trabalhar com a curva normal ou com as probabilidades dadas pela áreas de curva normal. A Distribuição T de Studant traz um fator de correção por se trabalhar com o desvio padrão da amostra, ou seja, um menor nível de precisão. 8.4.2.1 Distribuição de Probabilidade T de Studant A distribuição T de Student é uma distribuição de probabilidade estatística, publicada por um autor que se chamou de Student, pseudônimo de William Sealy Gosset, que não podia usar seu nome verdadeiro para publicar trabalhos enquanto trabalhasse para a cervejaria Guinness. A distribuição t também tem a forma normal e é simétrica sobre a média. A média, moda e mediana são iguais à zero. A principal diferença é que a distribuição t tem mais áreas nas caudas, fazendo com que seus valores críticos sejam maiores que os da distribuição Normal. Como consequência, o intervalo de confiança usando a distribuição t ficará mais largo se usa-se a distribuição Normal. A idéia aqui é que você deve pagar um preço por trabalhar com pequenas amostras. Cada tamanho amostral possui sua própria distribuição t, ou seja, ao contrário da distribuição normal, a distribuição t não tem forma fixa, mas sim uma família de curvas. Cada curva é determinada por um parâmetro chamado grau de liberdade, encontrado pelo tamanho da amostra menos um (GL = n - 1). A idéia aqui é que o preço a ser pago por se ter uma amostra muito pequena, como 5, é mais alto do que o preço por se ter uma amostra de tamanho um pouco maior, como 10 ou 20. A medida que o número de graus de liberdade aumenta, a diferença entre a distribuição t e a distribuição normal padrão torna-se cada vez menor, acima de 30 graus de liberdade a diferença é tão insignificante que pode-se trabalhar com a normal. O grau de liberdade se refere ao número de valores que são livres para variar após estabelecerem algumas restrições de dados. V = (n - 1) graus de liberdade x &lt;- seq(-3, 3, length=100) hx &lt;- dnorm(x) degf &lt;- c(1, 3, 8, 30) colors &lt;- c(&quot;#ef5350&quot;, &quot;#29b6f6&quot;, &quot;#66bb6a&quot;, &quot;#ffca28&quot;, &quot;black&quot;) labels &lt;- c(&quot;df=1&quot;, &quot;df=3&quot;, &quot;df=8&quot;, &quot;df=30&quot;, &quot;normal&quot;) plot(x, hx, type=&quot;l&quot;, lty=1,lwd=3, xlab=&quot;x value&quot;, ylab=&quot;Density&quot;, main=&quot;Comparison of t Distributions&quot;) for (i in 1:4){ lines(x, dt(x,degf[i]), lwd=2, col=colors[i]) } legend(&quot;topright&quot;, inset=.05, title=&quot;Distributions&quot;, labels, lwd=2, lty=c(1, 1, 1, 1, 1), col=colors) 8.4.2.1.1 Graus de liberdade Podemos definir graus de liberdade de diversas maneiras: O número de elementos que são livres para variar Maneira de quantificar as estimativas métricas para um cálculo estatístico qualquer O número de determinações independentes (dimensão da amostra) menos o número de parâmetros estatísticos a serem avaliados na população Medida da dependência das suas estimativas (das suas métricas estatísticas) em relação a sua amostragem Ou seja, nada mais que é que uma maneira de contar quantos parâmetros já foram estimados para que se possa calcular uma outra estimativa e descontando isso do número de observações, trata-se da independência entre os termos a partir do tamanho da sua observação. Quanto menos graus de liberdade você tem, mais restritivo vai sendo pra se achar uma diferença significativa - porque as estimativas vão ficando dependentes umas das outras e a penalização é a diminuição da confiança ! Por exemplo, no caso de se estimar a variância de uma população a partir da amostra, temos uma amostra com n observações, para calcular a variância é preciso calcular a média, logo sobram n-1 graus de liberdade para calcular a variância, pois existe uma dependência entre as estimativas Para calcular a variância para dois grupos de dados sabemos que para calcular a variância é preciso calcular duas médias (uma de cada grupo) portanto, e sobram n1+ n2  2 graus de liberdade para calcular a variância. 8.4.2.2 Margem de erro A estimação por intervalo de uma média populacional com  conhecido é dada por: \\[\\bar{x} ± z_\\frac{\\alpha}{2}\\frac{\\sigma}{\\sqrt{n}}\\] No entanto, para calcular a estimação por intervalo de  para o caso de  desconhecido , o desvio padrão da amostra é usado para estimar  e \\(z_\\alpha/2\\) é substituído pelo valor da distribuição t, \\(t_\\alpha/2\\). A margem de erro é dada qnormGC(0.025,region=&quot;above&quot;,mean=0, sd=1,graph=TRUE) ## [1] 1.959964 Com essa margem de erro a expressão geral de uma estimação por intervalo de uma média populacional quando o  é desconhecido é dado por: \\[\\bar{x} ± t_\\frac{\\alpha}{2}\\frac{s}{\\sqrt{n}}\\] \\(( 1 - ) = \\textrm{ coeficiente de confiança}\\) \\( = \\textrm{Nível de significância}\\) \\(s = \\textrm{Desvio padrão da amostra}\\) \\(t_\\frac{}{2} = \\textrm{ é o valor de t que produz uma área de /2 na cauda superior da dist. t de probabilidade com n - 1 graus de liberdade}\\) \\(t_\\frac{}{2} = \\textrm{ Semi amplitude}\\) A razão pela qual o número de graus de liberdade associado ao valor de t é n - 1 refere-se ao uso de s como uma estimativa do desvio padrão s da população. A expressão de desvio padrão da amostra é : \\[s =\\sqrt{ \\frac{\\sum(x_i- x)^2}{n - 1}}\\] Exemplo: Dada um conjunto de saldos de cartão de crédito em uma amostra de 85 famílias, onde os parâmetros populacionais são desconhecidos, desenvolva uma estimativa de 95% de confiança para média e desvio padrão populacionais. A média amostral é : 5.900 O desvio Padrão amostral é: 3.058 Dado: 95% de confiança n - 1 graus de liberdade grau de liberdade = 85 -1  84 t0,025 = 1,989  De acordo com tabela t \\[ \\bar{x}\\pm t_\\frac{\\alpha}{2} \\frac{s}{\\sqrt{n}} \\] \\(5900 ± 1,989 \\frac{3.058}{\\sqrt{85}}\\) \\(45900 ± 6604\\) Portanto a estimação por intervalo, com confiança de 95% é : $5.240    6560 $ 8.4.3 Determinação do tamanho da amostra Se uma margem de erro for escolhida antes da amostragem, o procedimento a seguir é útil para determinar o tamanho de amostra mínimo necessário para satisfazer os requisitos da margem de erro: \\[n = \\frac{(z_{\\frac{}{2}})^2^2}{E^2}\\] \\(E= \\textrm{margem de erro escolhida}\\) \\(z_{\\frac{}{2}} = \\textrm{grau de confiança a ser usado na estimação por intervalo}\\) \\( = \\textrm{Nível de significância}\\) \\( = \\textrm{Desvio padrão planejado}\\) O valor de  pode ser conhecido ou planejado, o qual pode ser obtido a partir dos seguintes procedimentos: Usar a estimativa do desvio padrão da populacional, calculada a partir de dados históricos Usar um estudo piloto para selecionar uma amostra preliminar e calcular o desvio da amostra Usar julgamento ou melhor palpite de , que pode ser calculada pela amplitude dividida por quatro. É uma aproximação tosca, porém aceitável para . 8.4.4 Proporção da população De forma geral, a estimação por intervalo de uma proporção é dada por: \\[p ± \\textrm{Margem de erro}\\] A distribuição amostral de \\(\\bar{p}\\) desempenha um papel fundamental no cálculo da margem de erro dessa estimação por intervalo. Sabe-se que a distribuição amostral de \\(\\bar{p}\\) pode ser aproximada por meio de uma distribuição normal quando: \\[n × p  5\\] \\[n (1 - p)  5\\] A média da distribuição amostral de \\(\\bar{p}\\) é a proporção p da população. O desvio padrão de \\(\\bar{p}\\) é dado por: \\[_{\\bar{p}}= \\sqrt{\\frac{p(1 - p)}{n}}\\] Dado que a distribuição amostral de \\(\\bar{p}\\) está normalmente distribuída: se \\(z_{\\frac{}{2}}_\\bar{p}\\) for escolhida como a margem de erro de uma estimação por intervalo de uma proporção populacional, saberemos que 100( 1 - )% dos intervalos gerados conterão a proporção populacional verdadeira Mas \\(_\\bar{p}\\) não pode ser utilizado diretamente no cálculo da margem de erro, pois p não será conhecido, p é justamente o que se deseja estimar Então se substitui p por \\(\\bar{p}\\) e temos \\(\\textrm{Margem de erro} = z_{\\alpha /2} \\sqrt{\\frac{\\bar{p}(1 - \\bar{p})}{n}}\\) Margem de erro 0,1 é ok. Pesquisas de opinião pública trabalham com 0,3 - 0,4 Temos então que a expressão geral da estimação por intervalo de uma proporção populacional: \\[\\bar{p} ± z_{\\alpha /2} \\sqrt{\\frac{\\bar{p}(1 - \\bar{p})}{n}}\\] \\(z_{/2} = \\textrm{é o valor de z que produz a área igual a /2 na cauda superior da distribuição normal padrão}\\) \\(1 -  = \\textrm{Coeficiente de confiança}\\) Exemplo: Dado uma amostra de 900 jogadoras de golfe de uma pesquisa a respeito da satisfação com o tratamento dados às mulheres nos cursos de golfe nos EUA. A pesquisa revelou que 396 mulheres estavam satisfeitas, portanto tem-se a proporção de 44% de mulheres satisfeitas. Fazendo o cálculo com 95% de confiança, temos o intervalos de: \\[\\bar{p} ± z_{\\alpha /2} \\sqrt{\\frac{\\bar{p}(1 - \\bar{p})}{n}}\\] \\(0,44 ± 1,96 \\sqrt{\\frac{0,44( 1 - 0,44)}{900}}\\) \\(0,44 ± 0,0324\\) Temos portanto uma margem de erro de 0,0324 e a estimação por intervalo de confiança de 95% da proporção da população é de \\(( 0,4076  p  0,04724)\\) em porcentagem, temos uma proporção entre 40,76 e 47,24 de todas as mulheres golfistas estarem satisfeitas. 8.4.4.1 Determinação do tamanho da amostra Para se determinar o tamanho da amostra necessário para se obter uma estimativa da proporção populacional com um grau de confiança específico, utiliza-se um pensamento análogo ao utilizado para estabelecer o tamanho da amostra para estimar a média populacional. Temos portanto: a margem de erro é dada por: \\[z_{/2} =\\sqrt{\\frac{ \\bar{p}( 1 - \\bar{p})}{n}}\\] esta se baseia no valor de \\(z_{/2}\\) na proporção de p da amostra e no tamanho n da amostra, tendo portanto que tamanhos de amostras maiores maiores produzem margens de erro menores Digamos que E denote a margem de erro: \\[E = z_{/2} \\sqrt{\\frac { \\bar{p}( 1 - \\bar{p})}{n}}\\] Isolando o n na equação, produz-se a fórmula do tamanho da amostra que fornecerá uma margem de erro de tamanho E: \\[n = \\frac{(z_{/2})^2 \\bar{p} (1 - \\bar{p} )}{E^2}\\] Entretanto, não podemos utilizar essa fórmula, para calcular o tamanho da amostra pois p somente será conhecido depois de selecionarmos a amostra. Para contornar, utilizaremos um valor planejado de \\(\\bar{p}\\) o \\(p^*\\) Temos então que a fórmula para calcular o tamanho da amostra para uma estimação por intervalo de uma proporção populacional é dada por: \\[n = \\frac{(z_{/2})^2 p^* (1 - p^* )}{E^2}\\] \\(p^*\\) = Valor planejado de \\(\\bar{p}\\) O valor planejado \\(p^*\\) pode ser obtido: Usando a proporção de uma amostra anterior das mesmas unidades ou de unidades similares Usando um estudo piloto para selecionar uma amostra preliminar Usando o julgamento ou melhor palpite para o valor planejado de \\(p^*\\) Usando o valor planejado de \\(p^* = 0,50\\). Caso nenhuma das alternativas anteriores seja apropriada. Exemplo: Dado uma amostra de 900 jogadoras de golfe de uma pesquisa a respeito da satisfação com o tratamento dados às mulheres nos cursos de golfe nos EUA. A pesquisa revelou que 396 mulheres estavam satisfeitas, portanto tem-se a proporção de 44% de mulheres satisfeitas. Fazendo o cálculo com 95% de confiança, obtemos o intervalo de \\(( 0,4076  p  0,04724)\\) para a proporção populacional de mulheres satisfeitas. Supondo que haja interesse de se fazer uma nova pesquisa, qual o tamanho da amostra necessário para uma margem de erro de 0,025, com 95% de confiança? Sabendo que na amostra anterior o valor de \\(\\bar{ p} = 0,44\\) estãos será utilizado como valor de \\(p^*\\) \\[n = \\frac{(z_{/2})^2 p^* (1 - p^* )}{E^2}\\] \\(n = \\frac{(1,96)^2 0,44 (1 - 0,44 )}{(0,025)^2}=1514,50\\) Portanto, o tamanho mínimo da amostra seria 1515 de mulheres golfistas. Caso fosse utilizado o valor de 0,5 - por não haver um valor histórico para ser utilizado como valor de \\(p^*\\) planejado. \\(n = \\frac{(1,96)^2 0,5 (1 - 0,5 )}{(0,025)^2}=1536,6\\) A diferença do tamanho da amostra seria ligeiramente maior. Observando alguns valor possíveis de \\(p^*\\) \\(p^*\\) \\(p^*(1 - p^*)\\) 0,1 (0,10)(0,90) = 0,09 0,3 (0,30)(0,70) = 0,21 0,4 (0,40)(0,60) = 0,24 0,5 (0,50)(0,50) = 0,25 0,6 (0,60)(0,40) = 0,24 0,7 (0,70)(0,30) = 0,21 0,9 (0,90)(0,10) = 0,09 O valor de 0,5 resultará no maior tamanho da amostra. Assim, no caso de qualquer incerteza a respeito de um valor planejado apropriado, sabemos que \\(p^*=0,5\\) apresentará a recomendação do maior tamanho da amostra. 8.4.4.2 Erro de amostragem Diferença entre os parâmetros da população e as estatísticas da amostra. Porque ocorre? amostragem inadequada amostra não representativa da população amostra insuficiente para fazer inferências sobre a população Características Variam entre amostras Quanto maior a amostra menor o erro de amostragem 8.5 Teorema do Limite Central 8.5.0.0.1 População está normalmente distribuída Se a população tem uma distribuição normal, ou aproximadamente normal a distribuição amostral de x estará normalmente distribuída para qualquer tamanho de amostra 8.5.0.0.2 População não é normalmente distribuída Mãe de todos os teoremas, afirma que quando o tamanho da amostra aumenta, a distribuição amostral da sua média aproxima-se cada vez mais de uma distribuição normal. E fundamental na teoria da inferência estatística. A ilustração abaixo demonstra o Teorema do limite central para três populações não normalmente distribuídas: A população 1 tem a uma distribuição uniforme. A população 2 tem uma distribuição simétrica (chamada também de orelha-de-coelho), onde os valores mais prováveis se encontram nas extremidades. A população 3 tem uma distribuição semelhante a distribuição exponencial, tendo uma inflexão à direita. Nas três populações quanto maior o tamanho da amostra, mais a distribuição se torna aproximadamente normal e as inflexões são acentuadas. Portanto sabe-se que para uma amostra: de n &gt; 30: a distribuição amostral se aproxima de uma distribuição normal Caso a população tenha uma forte inflexão ou pontos fora da curva o adequado é um n &gt; 50 Caso a população seja discreta o tamanho da amostra depende da proporção amostral "],["probabilidade.html", "9 Probabilidade 9.1 Conceitos 9.2 Atribuição de probabilidade 9.3 Teorema de Bayes 9.4 Distribuição de probabilidade", " 9 Probabilidade Definição A medida da incerteza Indica a chance(a medida da possibilidade) ou a probabilidade de um evento ocorrer Quantificação do conhecimento que temos sobre um particular evento Regras 0 = impossível ocorrer 1 = certamente ocorrerá A probabilidade não pode ser negativa ou maior que 1. Deve variar entre 0 e 1 (incluso) A soma das probabilidades de um evento simples, em um espaço da amostra, deve ser igual a 1 O complemento de um evento A é definido como todos os resultados, em um espaço de amostra, que não fazem parte do evento A. 9.1 Conceitos 9.1.1 Espaço da amostra Todos os resultados possíveis de um experimento. Ex: Dados - &gt; números de 1 a 6 9.1.2 Evento Um ou mais resultados de um experimento Ex: O jogar o dado 9.1.3 Experimento E o processo de medir ou observar uma atividade com o propósito de coletar dados. 9.1.3.1 Experimento simples Experimento simples: duas opções (moeda, cara ou coroa) Tipos Experimento determinístico ex. Caneta caindo no chão - resultado sempre o mesmo Experimento aleatório ex. distância entre a caneta que caiu em relação a parede- resultado sempre diferente Ex: Jogar dados 9.1.3.2 Experimento de Múltiplas Etapas Um experimentos em múltiplas etapas é nada mais que realizar diversas vezes um experimento. Ex: Jogar duas moedas O espaço amostral seria: \\(\\small S = [(H, H), (H,T),(T,H),(T,T)]\\) H = Head T=Tail, sendo 4 os resultado experimentais. 9.1.3.2.1 Regra de Contagem \\[\\small \\textrm{Regra de contagem} = n_1×n_2×....×n_k\\] Sendo um experimento uma sequência de k etapas, com \\(n_1\\) resultados possíveis na primeira etapa, com \\(n_2\\) resultados possíveis na segunda etapa, e assim por diante. No caso de um evento envolvendo seis moedas: \\(\\small (2)(2)(2)(2)(2)(2) = 64\\) resultados possíveis. 9.1.3.2.1.1 Diagrama de Árvore Uma forma de visualizar o desdobramento desses eventos é por meio de diagrama de Árvore: 9.1.3.2.2 Regra de contagem de combinações O número de combinações de N objetos, tomados n a cada vez, é: \\[\\small C_n^N= (\\frac{N}{n}) = \\frac{N!}{n!(N - n)!}\\] Permite contar o número de resultados experimentais quando o experimento envolve escolher n objetos de um conjunto ( geralmente maior) de N objetos. Exemplo: \\(\\small N = [ A, B, C, D, E]\\) \\(\\small n = 2\\) \\[\\small C_n^N= (\\frac{N}{n}) = \\frac{N!}{n!(N - n)!}\\] \\(\\small C_2^5= (\\frac{5}{2}) = \\frac{5!}{2!(3)!}\\) \\(\\small \\frac{5!}{2!(3)!} =\\frac{5×4×3×2×1}{2×1×3×2×1} = \\frac{120}{12}= 10\\) N S 1 AB 2 AC 3 AD 4 AE 5 BC 6 BD 7 BE 8 CD 9 CE 10 DE library(&#39;gtools&#39;) choose(n = 5, k = 2) ## [1] 10 9.1.3.2.3 Regra de contagem de Permutações O número de permutações de N objetos, tomados a cada n vez, é dado por: \\[\\small P_n^N= n!(\\frac{N}{n}) = \\frac{N!}{(N - n)!}\\] O número de resultados experimentais quando n objetos são escolhidos de um conjunto de N objetos em que a ordem de escolha é importante. Exemplo: \\(\\small N = [ A, B, C, D, E]\\) \\(\\small n = 2\\) \\[\\small P_n^N= n!(\\frac{N}{n}) = \\frac{N!}{(N - n)!}\\] \\(\\small P_2^5= 2!(\\frac{5}{2}) = \\frac{5!}{(5 - 2)!}\\) \\(\\small \\frac{5!}{3!}=\\frac{5×4×3×2×1}{3×2×1} = \\frac{120}{6}=20\\) S AB e BA AC e CA AD e DA AE e EA BC e CB BD e DB BE e EB CD e DC CE e EC DE e ED library(kableExtra) kbl(permutations(n = 5, r = 2, v = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;))) A B A C A D A E B A B C B D B E C A C B C D C E D A D B D C D E E A E B E C E D 9.2 Atribuição de probabilidade Para atribuição de probabilidade e preciso atender requisitos básicos: A probabilidade atribuída a cada um dos resultados experimentais deve situar-se entre 0 e 1 \\(\\small 0 P(E_i)  1 \\forall i\\) A soma de todas as probabilidades deve ser 1 \\(\\small P(E_1) +P(E_2) + .... + P(E_n) =1\\) Se dois eventos A e B são mutuamente exclusivos, a probabilidade da união do evento A com o evento B equivale a soma da probabilidade do evento A com a probabilidade do evento B, ou seja, \\(\\small P(A \\cup B) = P(A) + P(B)\\) 9.2.1 Probabilidade clássica Utilizada quando sabe-se o número de possíveis resultados e todos são igualmente prováveis 9.2.1.1 Permutação Permutar elementos significa trocá-los de posição. A maneira de calcular as possibilidades de fazer isso, vai depender da natureza dos elementos a serem permutados. 9.2.1.1.1 Permutação simples Uma permutação de n objetos distintos é qualquer agrupamento ordenado desses objetos, de modo que, se denominarmos \\(\\small P_n\\) o número das permutações simples dos n objetos, então: \\[\\small P_n = n!\\] De fato, imaginemos que dispomos de n objetos distintos para serem colocados em fila, ocupando n posições. Pelo Princípio Multiplicativo, temos n objetos para ocupar a 1ª posição. Ocupada a 1ª posição com um objeto, a 2ª posição pode ser ocupada por qualquer um dos n  1 objetos restantes. Daí, ocupada a 2ª posição, a terceira posição pode ser ocupada por qualquer um dos n  2 objetos restantes. Repetindo esse raciocínio até o último objeto, restará para ele a última posição da fila. Logo, pelo Princípio Multiplicativo, teremos: \\(\\small n × (n  1) × (n  2) × (n  3) ×  × 3 × 2 × 1\\) que é exatamente o mesmo que escrever \\(\\small n!\\). Exemplo: De quantas maneiras pode-se colocar 4 pessoas na fila? Solução: Note que, temos 4 pessoas que podem ocupar o 1° lugar da fila. Daí, colocada a primeira pessoa na fila, restam 3 pessoas que podem ocupar o 2° lugar da fila. Em seguida, colocada a 2ª pessoa, agora restam duas pessoas que podem ocupar o 3° lugar da fila. E por fim, colocada a segunda pessoa na fila, sobra uma pessoa para ocupar a última posição. Pelo Princípio Multiplicativo, teremos: \\(\\small 4×3×2×1=4!=24\\) permutations(4,4) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 1 2 4 3 ## [3,] 1 3 2 4 ## [4,] 1 3 4 2 ## [5,] 1 4 2 3 ## [6,] 1 4 3 2 ## [7,] 2 1 3 4 ## [8,] 2 1 4 3 ## [9,] 2 3 1 4 ## [10,] 2 3 4 1 ## [11,] 2 4 1 3 ## [12,] 2 4 3 1 ## [13,] 3 1 2 4 ## [14,] 3 1 4 2 ## [15,] 3 2 1 4 ## [16,] 3 2 4 1 ## [17,] 3 4 1 2 ## [18,] 3 4 2 1 ## [19,] 4 1 2 3 ## [20,] 4 1 3 2 ## [21,] 4 2 1 3 ## [22,] 4 2 3 1 ## [23,] 4 3 1 2 ## [24,] 4 3 2 1 9.2.1.1.2 Arranjos Simples Considere um conjunto com n elementos distintos. Qualquer sequência de p desses elementos (todos distintos) é chamada de Arranjo Simples \\(\\small (0  p  n, \\textrm{com n e p naturais})\\). Dizemos arranjo simples de n elementos tomados p a p, e simbolizamos por \\(\\small A_{(n,p)}\\) Esse arranjo simples pode ser calculado da seguinte forma: \\[\\small A_{(n,p)} =\\frac{n!}{(n-p)!}\\] De fato, suponha que dispomos de n objetos distintos, e escolheremos p desses objetos para serem colocados em uma fila, com p posições. Dessa forma a fila terá p objetos. Pelo Princípio Multiplicativo, temos n objetos para ocupar a 1ª posição. Ocupada a 1ª posição com um objeto, a 2ª posição pode ser ocupada por qualquer um dos \\(\\small n-1\\) objetos restantes. Daí, ocupada a 2ª posição, a terceira posição pode ser ocupada por qualquer um dos \\(\\small n-2\\) objetos restantes. Repetindo esse raciocínio até a posição de número p, teremos para ela \\(\\small n  p + 1\\) objetos disponíveis para ocupá-la. É importante enfatizar que nos problemas que envolvem a ferramenta do arranjo, a ordem dos termos agrupados importa, uma vez que uma sequência será diferente de uma outra se seus respectivos termos estiverem ordenados de forma distinta. Exemplo: Considere os algarismos 1,2,3,4 e 5. Quantos números com algarismos distintos, superiores a 100 e inferiores a 1.000, podemos formar? Solução O problema solicita que encontremos todos os números com três algarismos distintos uma vez que, todos os números maiores que 100 e menores que 1.000 têm três dígitos. Dessa forma, temos cinco algarismos disponíveis e usar três deles para formar números de três algarismos distintos. A solução do problema será o arranjo simples de 5 elementos tomados 3 a 3. Ou seja, \\[\\small A_{(n,p)} =\\frac{n!}{(n-p)!}\\] \\(\\small A_{(5,3)} =\\frac{5!}{(5-3)!}\\) \\(\\small A_{(5,3)} =\\frac{5!}{(2)!}=60\\) tail(permutations(5,3)) ## [,1] [,2] [,3] ## [55,] 5 3 1 ## [56,] 5 3 2 ## [57,] 5 3 4 ## [58,] 5 4 1 ## [59,] 5 4 2 ## [60,] 5 4 3 9.2.1.1.3 Arranjos com repetição Considere um conjunto com n elementos distintos. Qualquer sequência de p desses elementos é chamada de Arranjo com repetição (0  p  n, com n e p naturais). Note que os p elementos podem ser distintos ou não, isto é, pode haver elementos repetidos. Daí o nome, arranjo com repetição. Dizemos arranjo com repetição de n elementos tomados p a p, e simbolizamos por: \\[\\small AR_{n,p} = n^p\\] De fato, suponha que dispomos de n objetos distintos, e escolheremos p desses objetos para serem colocados em uma fila, com p posições. Dessa forma a fila terá p objetos. Pelo Princípio Multiplicativo, temos n objetos para ocupar a \\(\\small 1^a\\) posição. Ocupada a \\(\\small 1^a\\) posição com um objeto, como os objetos na fila podem ser repetidos, para \\(2^a\\) posição ainda temos n objetos disponíveis. Ocupada a \\(\\small 1^a\\) posição com um objeto, como os objetos na fila podem ser repetidos, para \\(\\small 2^a\\) posição ainda temos n objetos disponíveis. Repetindo esse raciocínio até a última posição, que é a posição de número p, como os objetos podem ser repetidos, ainda teremos n objetos disponíveis para essa posição. Assim, pelo Princípio Multiplicativo, teremos. \\(\\small A_{n,p} = n.n.n....n\\textrm{ (p vezes)}\\) \\(\\small A_{n,p} = n^p\\) Exemplo: Considere os algarismos 1,2,3,4 e 5. Quantos números, superiores a 100 e inferiores a 1.000, podemos formar? Solução: O problema solicita que encontremos todos os números com três algarismos (distintos ou não) uma vez que, todos os números maiores que 100 e menores que 1.000 têm três dígitos. Assim, temos 5 elementos e precisamos escolher 3 para formar números, onde os algarismos podem ser repetidos ou não. Dessa forma, a solução do problema será o arranjo com repetição de 5 elementos tomados 3 a 3. Ou seja, \\(\\small AR_{n,p} =5.5.5 = 5^3 = 125\\) Note que, assim como foi feito no arranjo simples, podemos também no arranjo com repetição resolver qualquer problema usando o Princípio Multiplicativo, da seguinte forma: library(&#39;gtools&#39;) tail(permutations(n = 5, r = 3,repeats.allowed = T)) ## [,1] [,2] [,3] ## [120,] 5 4 5 ## [121,] 5 5 1 ## [122,] 5 5 2 ## [123,] 5 5 3 ## [124,] 5 5 4 ## [125,] 5 5 5 9.2.1.2 Combinação Conhecemos como combinação a contagem de todos os subconjuntos de k elementos que podemos formar de um conjunto de n elementos 9.2.1.2.1 Combinações Simples Considere um conjunto com n elementos distintos. Qualquer subconjunto formado por de p desses elementos (todos distintos) é chamado de Combinação Simples (0  p  n, com n e p naturais). Dizemos combinação simples de n elementos tomados p a p, e simbolizamos por \\(\\small C_{n,p}\\) Essa combinação simples pode ser calculada da seguinte forma: \\[\\small C_{n,p}=\\frac{n!}{p!(n-p)!}\\] De fato, considere um conjunto com n elementos distintos. Seja \\(\\small C_{n,p}\\) é a quantidade de subconjuntos com p elementos distintos que podemos formar. Note que, em cada subconjunto formado, a ordem não importa. Se a ordem importasse, teríamos um arranjo simples desses elementos, que é \\(\\small A_{n,p}\\) É importante enfatizar que nos problemas que envolvem a ferramenta da combinação a ordem dos termos agrupados não importa, uma vez que um subconjunto A será igual a um outro subconjunto B se seus respectivos elementos forem os mesmos. Exemplo Uma escola quer organizar um torneio esportivo com 10 equipes, de forma que cada equipe jogue exatamente uma vez com cada uma das outras. Quantos jogos terá o torneio? Solução Considere \\(\\small E = \\{E_1, E_2, E_3,  , E_{10}\\}\\) o conjunto dos times do referido torneio. Note que, resolver esse problema é determinar o número de subconjuntos com dois elementos que podemos formar, a partir dos elementos do conjunto E. Teremos, portanto: \\(\\small C_{n,p}=\\frac{10!}{2!( 10- 2 )!} = \\frac{10 × 9× 8!}{2×1×8!}= \\frac{10 × 9}{2×1} = 45\\) Logo, teremos 45 subconjuntos, ou seja, 45 jogos nesse torneio. library(&#39;gtools&#39;) choose(n=10,k = 2) ## [1] 45 9.2.1.3 Probabilidade usando combinações A Probabilidade permite analisar ou calcular as chances de obter determinado resultado diante de um experimento aleatório. São exemplos as chances de um número sair em um lançamento de dados ou a possibilidade de ganhar na loteria. A partir disso, a probabilidade é determinada pela razão entre o número de eventos possíveis e número de eventos favoráveis, sendo apresentada pela seguinte expressão: \\[\\small P(A) = \\frac{n(A)}{n()}\\] Sendo: \\(\\small \\textrm{P(A)= probabilidade de ocorrer um evento A}\\) \\(\\small \\textrm{n(A)= número de resultados favoráveis}\\) \\(\\small \\textrm{n()= número total de resultados possíveis}\\) Para encontrar o número de casos possíveis e favoráveis, muitas vezes necessitamos recorrer as fórmulas estudadas em análise combinatória. Sendo a probabilidade conhecida, agora basta Exemplo: A probabilidade de um jogador acertar um lance livre é de 80%. Qual a probabilidade de acertar 3 de 5 arremessos? solução: Na situação acima para calcular as combinações de 5 arremessos onde 3 serão acertos temos o coeficiente binomial \\(\\small \\binom{3}{5}\\), portanto: \\(\\small \\binom{3}{5}) = \\frac{5!}{3!(5-3)!} =\\frac{5×4}{2} = 10\\) Agora basta elevar a potência cada uma das probabilidades e multiplicar pelas combinações: \\[\\small P(Acertos)^{n° acertos} × P(Erros)^{n° erros} × n° combinações\\] \\(\\small 0,8^3×0,2^2×10\\) \\(\\small 0,512×0,04×10 = 0,2048\\) Portanto, em 5 arremessos, existe 20,48% de acertar 3. E são 10 as combinações diferentes possíveis. Exemplo: A probabilidade de um jogador acertar um lance livre é de 80%. Qual a probabilidade de acertar pelo menos 3 de 5 arremessos? Solução: Na situação acima para calcular as combinações de : 5 arremessos onde 3 serão acertos = coeficiente binomial\\(\\small \\binom{3}{5}\\) 5 arremessos onde 4 serão acertos = coeficiente binomial\\(\\small \\binom{4}{5}\\) 5 arremessos onde 5 serão acertos = coeficiente binomial\\(\\small \\binom{5}{5}\\) Temos então que: \\(\\small \\binom{3}{5}=10\\) \\(\\small \\binom{4}{5}=5\\) \\(\\small \\binom{5}{5}=1\\) Então: \\(\\small (0,8^3×0,2^2×10) + (0,8^4×0,2^1× 5) + (0,8^5×0,2^1×1)\\) \\(\\small 0,2048 + 0,4096 +0,32768 = 0,94208\\) Portanto, há 94,208% de chance de se acertar pelo menos 3 arremessos de 5. dbinom(x=3, size = 5,prob = 0.8) ## [1] 0.2048 dbinom(x=4, size = 5,prob = 0.8) ## [1] 0.4096 dbinom(x=5, size = 5,prob = 0.8) ## [1] 0.32768 dbinom(x=3, size = 5,prob = 0.8) + dbinom(x=4, size = 5,prob = 0.8)+dbinom(x=5, size = 5,prob = 0.8) ## [1] 0.94208 9.2.2 Probabilidade empírica Usada quando não se tem a informações detalhadas sobre o evento Ex: Compras em loja, onde não se tem a informação do porquê da compra ou quando foi realizada. Podendo ser calculada registrando o número de clientes que entraram na loja (número total de observações) e o número de clientes que realizaram a compra (frequência que evento A ocorre) \\[ \\small P(A)=\\frac{\\textrm{Frequência em que o evento A ocorre}}{\\textrm{Número total de observações}} \\] 9.2.3 Probabilidade Subjetiva Estimada pela experiência e julgamento Usada quando Não se pode utilizar a clássica nem a empírica Não há disponibilidade de realização de experimentos 9.2.4 Probabilidade em eventos compostos 9.2.4.1 Complemento de um evento Dado um evento A, o complemento de A é definido como o evento que consiste em todos os pontos amostrais que não estão em A. O complemento de A é denotado de \\(\\small A^C\\). Em termos de probabilidade temos: \\[\\small P(A) + P(A^C) = 1\\] E para obtermos a probabilidade de A por meio do completo basta isolar a probabilidade de A. 9.2.4.2 União de eventos Probabilidade de pelo menos um dos eventos ocorrerem (Ou A ou B, ou Ambos). Denotada por todos os pontos amostrais pertencentes a A, B ou ambos. Exemplo: Considere o estoque de uma loja: Preta Branca Total Camisa 150 230 380 Jaqueta 560 750 1310 Calça 98 140 238 Total 8080 1120 1928 Defina: Evento A: Probabilidade selecionar aleatoriamente uma camiseta (branca ou preta) Evento B:Probabilidade selecionar aleatoriamente qualquer peça da cor preta Probabilidade de A OU B ocorrerem: ou seja, uma peça escolhida aleatóriamente ser preta ou camiseta. \\(\\small P(A): \\frac{150+230}{1928}=\\frac{380}{1928} = 0,1970\\) \\(\\small P(B): \\frac{150+560+98}{1928}=\\frac{808}{1928} = 04190\\) \\(\\small P(A) + P(B) = \\frac{380+808}{1928} = 0,6161\\) 9.2.4.2.1 Eventos Mutuamente exclusivos Eventos que não acontecem ao mesmo tempo. Denotados por não possuírem nenhum ponto amostral em comum. \\(\\small P(AB) = P(A) + P(B)\\) Exemplo: Considere os pontos obtidos em um jogo: Pontos Homens Mulheres Total 95 60 30 90 90 40 80 120 85 0 40 40 Total 100 150 150 Defina: Evento A: Probabilidade de se fazer 90 pontos Evento: Probabilidade de se fazer 85 pontos Probablidade de se fazer 85 ou 90 pontos. \\(\\small P(A)=\\frac{120}{250}=0,48\\) \\(\\small P(B)=\\frac{40}{250}=0,16\\) \\(\\small P(\\textrm{A OU B}) =0,48+0,16 = 0,64\\) 9.2.4.2.2 Eventos Não Mutuamente Exclusivos Eventos que podem ocorrer ao mesmo tempo e possuem pontos amostrais em comum. \\(\\small P(AB) = P(A) + P(B) - P (AB)\\) Tal cálculo, se justifica pela fato dos pontos da intercessão estar presente duas vezes, tanto em A quanto em B, portanto, precisa ser retirado uma vez para que o resultado seja preciso. 9.2.4.3 Probabilidade Condicional A probabilidade condicional, é a probabilidade de um evento ocorrer, dado que outro evento já ocorreu. \\(\\small P(A | B)\\) = lê-se - Probabilidade de A dado B \\(\\small P( A | B) = P(A  B)P(B) P( B | A) = P(A  B)P(A)\\) Ou seja, a probabilidade condicional é dada pelo quociente da probabilidade associada pela probabilidade marginal Exemplo: H = o evento de um policial ser homem M = o evento de um policial ser mulher A = o evento de um policial ser promovido \\(\\small A^C\\)= o evento de um policial não ser promovido Probabilidade Marginal Probabilidade Associada P(H) = 0,8 P(H  \\(A^C\\)) = 0,56 P(M) = 0,2 P(H  A) = 0,24 P(A) = 0,27 P(M  A) =0,03 P(\\(A^C\\))= 0,73 P(H \\(A^C\\)) = 0,17 A probabilidade da interseção desses eventos é uma probabilidade associada. Tal informação pode ser vista em uma tabela de probabilidade associada (em vermelho): Homens Mulheres Total Promovidos 288 36 324 Não Promovidos 672 204 876 Total 960 240 1200 Categoria Homens Mulheres Total Promovidos(A) 0.24 0.03 0.27 Não Promovidos \\((A^c)\\) 0.56 0.17 0.73 Total 0.8 0.2 1 Em verde estão as chamadas, probabilidades marginais, em virtude da localização na tabela de probabilidade associada. Em rosa está a área que se busca a probabilidade. Ou seja, dada a ocorrência de A qual a probabilidade de B ocorrer? Calcula-se então, dada a probabilidade de B, qual a probabilidade de ocorrer exatamente os pontos amostrais em comum com A. Portanto: \\[\\small P( A | B) = \\frac{P(A  B)}{P(B)}\\] No exemplo poderíamos usar \\(\\small P(A | M)\\): \\(\\small P( A | M) = \\frac{P(A  M)}{P(M)}\\) \\(\\small P( A | M) = \\frac{0,03}{0,20}= 0,15\\) 9.2.4.3.1 Eventos Dependentes Um evento dependente é denotado pela mudança da sua chance de ocorrer, devido a ocorrência ou não de outro evento. Portanto: \\(\\small P(A | H)  P(A)\\) \\(\\small P(H | A)  P(H)\\) Então o evento A é afetado pela ocorrência do evento H. Como ocorre no caso das probabilidades condicionais. 9.2.4.3.2 Evento Independentes Um evento independente é denotado pela não alteração da sua probabilidade de ocorrer, devido a ocorrência ou não de outro evento. Portanto: \\(\\small P(A | H) = P(A)\\) \\(\\small P(H | A) = P(H)\\) Então o evento A não é afetado pela ocorrência do evento H, como ocorre no caso das probabilidades condicionais. Retormando o exemplo dos pontos em um jogo: Pontos Homens Mulheres Total 95 60 30 90 90 40 80 120 85 0 40 40 Total 100 150 150 Se buscarmos a probabilidade de uma mulher obter 90 pontos teremos: Evento A: obter 90 pontos Evento B: ser mulher P(A e B): mulher obter 90 pontos \\(\\small P(A)= \\frac{120}{150}=0,48\\) \\(\\small P(B)= \\frac{150}{250}=0,60\\) \\(\\small P(\\textrm{A e B})= \\frac{80}{250} = 0,32\\) \\(\\small P(\\textrm{A ou B})= P(A) + P(B) - P(\\textrm{A e B})\\) \\(\\small P(\\textrm{A ou B}) = 0,48+0,60-0,32=0,76\\) 9.2.4.4 Intersecção de eventos - Lei da multiplicação Probabilidade de evento A e evento B ocorrem ao mesmo tempo. Denotado por todos os pontos amostrais de A que também pertencem a B. 9.2.4.4.1 Eventos Dependentes O cálculo para descobrir a probabilidade da área de intersecção de eventos dependentes: \\(\\small P(A B) = P(B) × P(A | B)\\) ou \\(\\small P(A B) = P(A) × P(B | A)\\) 9.2.4.4.2 Eventos Independentes O cálculo para descobrir a probabilidade da área de intersecção de eventos dependentes: \\(\\small P(A B) = P(A) × P(B)\\) 9.3 Teorema de Bayes O teorema de Bayes pode ser utilizado para revisão de probabilidades quando novas informações são adicionadas. São frequentemente utilizadas na análise de decisão, onde as probabilidades a priori geralmente são subjetivas e depois complementadas com informações de amostra, e então, calculada-se as probabilidades a posteriori. Então o processo é: % de peças boas % de peças ruins Fornecedor 1 98 2 Fornecedor 2 95 5 Traduzindo o esquema acima em valores teremos: Agora, se a pergunta for, dada uma peça ruim, qual a probabilidade de se originar do fornecedor 1? e do fornecedor 2? Buscamos as seguintes probabilidades: \\(\\small P(F1 | R) = P(F1  R)P(R)\\) \\(\\small P(F2 | R) = P(F2  R)P(R)\\) E de acordo com a árvore de probabilidades sabemos que: \\(\\small P(F1 R) = P(F1) × P(R | F1)\\) Em relação a probabilidade de R, sabemos que só ocorre em duas ocasiões: \\(\\small (F1 R) e (F2 R)\\) Portanto: \\(\\small P(R) = P(F1 R) + P(F2 R)\\) \\(\\small =P(F1) × P(R | F1) + P(F2) × P(R | F2)\\) Reescrevendo toda a equação chegamos em: \\[\\small P(F1 | R) = \\frac{P(F1) × P(R | F1)}{P(F1) × P(R | F1) + P(F2) × P(R | F2)}\\] \\[\\small P(F2 | R) = \\frac{P(F2) × P(R | F2)}{P(F1) × P(R | F1) + P(F2) × P(R | F2)}\\] Que nada mais é que o teorema de Bayes para dois eventos. Substituindo os valores na fórmula teremos: \\(\\small P(F1 | R) = \\frac{P(F1) × P(R | F1)}{P(F1) × P(R | F1) + P(F2) × P(R | F2)}\\) \\(\\small P(F1 | R) = \\frac{ (0,65 )× (0,02)}{(0,65 )× (0,02) + (0,35) × (0,05)}\\) \\(\\small P(F1 | R) = \\frac{0,013}{(0,013) + (0,0175)}\\) \\(\\small P(F1 | R) = \\frac{0,013}{0,305} = 0,4262\\) \\(\\small P(F2 | R) = \\frac{P(F2) × P(R | F2)}{P(F1) × P(R | F1) + P(F2) × P(R | F2)}\\) \\(\\small P(F2 | R) = \\frac{(0,35 )× (0,05)}{(0,65 )× (0,02) + (0,35) × (0,05)}\\) \\(\\small P(F2 | R) = \\frac{0,0175}{(0,013) + (0,0175)}\\) \\(\\small P(F2 | R) = \\frac{0,0175}{0,305} = 0,5738\\) Em resumo, o Teorema de Bayes é aplicável quando os eventos que se deseja calcular as probabilidades a posteriori são mutuamente exclusivos e a união deles é um espaço amostral inteiro ( coletivamente exaustivos). Não existindo limite para a quantidades de eventos, desde que cumpram com os requisitos. \\[\\small P( F_i| R) = \\frac{P(F_i) × P(R | F_i)}{P(F_1) × P(R | F_1) + P(F_2) × P(R | F_2) + ... + P(F_n) × P(R | F_n)}\\] 9.3.1 Abordagem Tabular Uma abordagem tabular, em tabelas, pode ser útil para efetuar os cálculos do Teorema de Bayes. Segue-se as etapas: Monta-se as colunas: Eventos \\(\\small A_i\\) , mutuamente exclusivos, que se desejam as probabilidades a posteriori Probabilidades a priori dos eventos \\(\\small P(A_i)\\) As probabilidades condicionais da nova informação R dada para cada evento \\(\\small P(R | A_i)\\) Calcule as probabilidades associadas correspondente a cada evento e a nova informação usando a lei da multiplicação \\(\\small P( A_i  R) =P( A_i) × P(R | A_i)\\) Some as probabilidades associadas da etapa anterior e obtenha a probabilidade da nova informação: \\(\\small P(R)\\) Na próxima coluna, calcule as probabilidades a posteriori usando a relação básica da probabilidade condicional \\(\\small P(F_i | R) = \\frac{P(F_i  R)}{P(R)}\\) (1.a) Eventos \\(\\small (A_i)\\) (1.b) Probabilidade a priori \\(\\small P(A_i)\\) (1.a) Probabilidades condicionais \\(\\small P(R \\|A_i)\\) (2) Probabilidades associadas\\(\\small P( A_i  R)\\) (4) Probabilidade a posteriori \\(\\small P( A_i \\| R)\\) A1 0,65 0,02 0,0130 \\(\\small \\frac{0,0130}{0,0305}=0,4262\\) A2 0,35 0,05 0,0175 \\(\\small \\frac{0,0175}{0,0305}=0,5738\\) Total = 1 Total(3) (P(R)) = 0,0305 Total = 1 9.4 Distribuição de probabilidade A distribuição de probabilidade de uma variável aleatória descreve como as probabilidades estão distribuídas sobre os valores da variável aleatória. Para uma variável discreta x, a distribuição de probabilidade é definida por uma função de probabilidade, denotada por f(x). A função de probabilidade fornece a probabilidade correspondente a cada um dos valores da variável aleatória. Portanto, associa uma probabilidade a cada resultado numérico de um experimento. O domínio dessa função são os valores da variável A imagem são as probabilidades da variável assumir cada valor do domínio conjunto imagem restrito ao intervalo de 0 e 1 A função precisa atender a duas condições: \\(\\small f(x)  0\\) \\(\\small \\sum f(x) = 1\\) 9.4.1 Distribuição Discreta Descreve quantidades aleatórias de dados que podem assumir valores finitos. Pode ser expressa pela seguinte função: \\(\\small f(x) = \\frac{fr(x)}{n}\\) \\(\\small fr(x) = \\textrm{frequência de x}\\) \\(\\small n = \\textrm{número de elementos}\\) E a versão acumulada: \\[ \\small F(x)=P(X \\leq x)=\\int\\_{-\\infty}^{x} f(x) d x=\\left\\{\\begin{array}{cll}0, &amp; \\text { se } &amp; x&lt;\\alpha \\\\ \\frac{x-\\alpha}{\\beta-\\alpha}, &amp; \\text { se } &amp; \\alpha \\leq x&lt;\\beta \\\\ 1, &amp; \\text { se }&amp; x \\geq \\beta\\end{array}\\right.\\] Veículos vendidos/ dia Total dias Probabilidade 0 54 \\(\\small f(0) = \\frac{54}{300} = 0,18\\) 1 117 \\(\\small f(1) = \\frac{117}{300} = 0,39\\) 2 72 \\(\\small f(2) = \\frac{72}{300} = 0,24\\) 3 42 \\(\\small f(3) = \\frac{42}{300} = 0,14\\) 4 12 \\(\\small f(4) = \\frac{12}{300} = 0,04\\) 5 3 \\(\\small f(5) = \\frac{3}{300} = 0,01\\) Total 300 1 library(ggplot2) v&lt;-c(54,117,72,42,12,3) df&lt;-data.frame(c(0:5),v) colnames(df)&lt;-c(&quot;veiculos&quot;,&quot;dias&quot;) ggplot(data=df, aes(x=veiculos, y=dias)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;steelblue&quot;)+ geom_text(aes(label=dias), vjust=-0.3, color=&quot;black&quot;, size=3.5)+ xlab(&quot;Veículos Vendidos/dia&quot;)+ ylab(&quot;Total dias&quot;)+ ggtitle(&quot;Histograma dos veículos vendidos por dia&quot;)+ scale_x_continuous(breaks = c(0,1,2,3,4,5))+ theme_minimal() df[&quot;prop&quot;]&lt;-prop.table(df$dias) ggplot(data=df, aes(x=veiculos, y=prop)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;steelblue&quot;)+ geom_text(aes(label=prop), vjust=-0.3, color=&quot;black&quot;, size=3.5)+ xlab(&quot;Veículos Vendidos/dia&quot;)+ ylab(&quot;Probabilidade&quot;)+ ggtitle(&quot;Distribuição de probabilidade para o número de automóveis vendidos por dia&quot;)+ scale_x_continuous(breaks = c(0,1,2,3,4,5))+ theme_gray() Principais tipos de distribuição que utilizam distribuição de probabilidade discreta Binominal Poisson Hipergeométrica Bernoulli 9.4.1.1 Distribuição de Probabilidade Binomial A distribuição de probabilidade binomial é uma distribuição de probabilidade discreta associada a um experimento de múltiplas etapas, chamado experimento binomial. Um experimento binomial possui quatro propriedades: Consiste em uma sequência de n ensaios idênticos Dois resultados são possíveis: sucesso e fracasso os quais nãos tem conotação positiva ou negativa A probabilidade de sucesso, denotada por p não se modifica de ensaio para ensaio. Tampouco a probabilidade de fracasso se modifica, denotada por 1 - p. Os ensaios são independentes Se somente as propriedades: 2,3,4 estiverem presentes, trata-se de um Ensaio de Bernoulli Exemplo: Vamos imaginar que nosso experimento seja contar quantos clientes que entram em uma loja de celulares, adquirem um plano pós-pago. Para este experimento, temos 2 possibilidades para cada observação: adquirir ou não adquirir o plano. Vamos imaginar agora, que historicamente, 10% dos clientes que entram na loja, adquirem um plano pós-pago. Portanto, a probabilidade de sucesso (que vamos chamar de p) para cada observação é 0.10. E a probabilidade de falha (que vamos chamar de q) para cada observação é 0.90. Temos então que: \\(\\small p = \\textrm{probabilidade de sucesso}\\) \\(\\small q = \\textrm{probabilidade de fracasso}\\) Então em relação as propriedades observamos que: O experimento consiste em n ensaios idênticos (clientes entrando na loja e comprando ou não o plano de celular) Somente dois resultados são possíveis: comprar ou não comprar o plano de celular A probabilidade de p= 0,10 e q = 0,90. Tais probabilidades não se alteram de um ensaio para outro. Os ensaios são independentes. Pois um cliente adquirir um plano não interfere na probabilidade de outro cliente adquirir também. Ou seja, se trata de um experimento binomial. Valor de x = número de clientes que fizeram a compra O número de resultados que resultam em x sucessos em n ensaios pode ser calculado com a fórmula abaixo: \\[\\small \\binom{n}{x}=\\frac{n!}{x!(n-x)!}\\] Em que: \\(\\small n! = n(n-1)(n-2)....(2)(1)\\) e por definição: \\(\\small 0! = 1\\) Obs: Na calculadora faz-se (n) nCr (x) No caso, se buscarmos quantas formas podemos obter 2 sucessos em 3 ensaios: Então, x = 2 e n = 3 \\(\\small \\binom{n}{x}=\\frac{n!}{x!(n-x)!}\\) \\(\\small \\binom{3}{2}=\\frac{3!}{2!(2 -3)!}\\) \\(\\small \\frac{3×2×1}{(2×1)(1)}=\\frac{6}{2} = 3\\) Portanto, há três possibilidades de se obter 2 sucesso em 3 ensaios. O que pode ser comprovado ao observar a árvore de resultados experimentais. Mas como descobrir a probabilidade de se obter um certo número de sucessos? Basta multiplicar as probabilidades de p e q correspondentes. Então no caso de se buscar 2 sucessos em 3 ensaios teremos: \\(\\small p = 0,10\\) \\(\\small p×p×q\\) \\(\\small p×p×( 1 -p)\\) \\(\\small (0,10)×(0,10)×(1 - 0,10)\\) \\(\\small (0,10)×(0,10)×(0,90 ) =0,009\\) Obs: Independente da sequência exata do resultado, sendo a proporção de sucessos e fracassos a mesma a probabilidade é a mesma. Juntando a formulação de quantidades de x sucessos em n ensaios com a probabilidade de se obter tal resultado temos a Função Probabilidade Binomial: \\[ \\small f(x)=\\binom{n}{x}p^x (1-p)^{(n-x)} \\] \\(\\small \\binom{n}{x}=\\frac{n!}{x!(n -x)!}\\) \\(\\small f(x) = \\textrm{a probabilidade de x sucessos em n ensaios}\\) \\(\\small n = \\textrm{o número de ensaios}\\) \\(\\small x = \\textrm{o número de sucessos}\\) \\(\\small p = \\textrm{a probabilidade de sucessos em qualquer ensaio}\\) \\(\\small 1 - p = \\textrm{a probabilidade de fracasso em qualquer ensaio}\\) Aplicando a fórmula para todos os casos teremos: x f(x) 0 \\(\\small \\frac{3!}{0!3!} = (0,10)^0(0,90)^3 =0,729\\) 1 \\(\\small \\frac{3!}{1!2!} = (0,10)^1(0,90)^2 =0,081\\) 2 \\(\\small \\frac{3!}{2!1!} = (0,10)^2(0,90)^1 =0,009\\) 3 \\(\\small \\frac{3!}{3!0!} = (0,10)^3(0,90)^0 =0,001\\) 9.4.1.1.1 Valor Esperado O valor esperado, ou média, de uma Distribuição Binomial, representa a média de longo prazo de sucessos esperados, baseado no número de observações. \\[\\small E(x) =  = n×p\\] Ou seja, no caso das compras de planos de celular o valor esperado para 5 ensaios seria: \\(\\small E(x) =  = 5×0,1 = 0,5\\) 9.4.1.1.2 Variância e Desvio padrão A Variância de uma Distribuição Binomial, representa a variação que existe no número de sucessos (p) sobre um número (n) de observações. Dado pela fórmula: \\(\\small Var(x) = ^2 = n×p×(1 - p)\\) \\(\\small  = \\sqrt{n ×p ×(1 - p)}\\) Ou seja, no caso das compras de planos de celular o valor esperado para 5 ensaios seria: \\(\\small Var(x) = ^2 = 5×0,1×(1 - 0,1)\\) \\(\\small Var(x) = ^2 = 5×0,1×0,9 = 0,45\\) \\(\\small  =\\sqrt{5 ×0,1 ×0,9} = 0,67\\) 9.4.1.1.3 R Exemplo: A probabilidade de um paciente com um ataque cardíaco morrer do ataque é de 0.04 (ou seja, 4 de 100 morrem do ataque). Suponha que tenhamos 5 pacientes que sofrem um ataque cardíaco, qual é a probabilidade de que todos sobrevivam? Para este exemplo, vamos chamar um sucesso um ataque fatal (p = 0.04). Temos n = 5 pacientes e queremos saber a probabilidade de que todos sobrevivam ou, em outras palavras, que nenhum seja fatal (0 sucessos). # X = Número de sobreviventes ao ataque #p = 0.04 #n = 5 #dbinom(X, n, p) a &lt;- dbinom(0, 5, 0.04) print(a) ## [1] 0.8153727 #Desenhando a distribuição de probabilidades graph &lt;- function(n,p){ x &lt;- dbinom(0:n, size = n, prob = p) barplot(x,ylim=c(0,1),names.arg=0:n, main=sprintf(paste(&#39;Distribuição Binomial (n,p) &#39;,n,p,sep=&#39;,&#39;))) } graph(5,0.04) #Criando o gráfico de uma distribuição binomial x &lt;- seq(0,50,by = 1) y &lt;- dbinom(x,50,0.5) plot(x,y) 9.4.1.2 Distribuição Uniforme Distribuição onde a probabilidade de todos os elementos é a mesma. \\[\\small f(x) = \\frac{1}{n}\\] \\(\\small n = \\textrm{número de valores que a variável aleatória pode assumir}\\) É o caso de jogar dados não viciados. 9.4.1.2.1 Valor Esperado Valor esperado, ou média, de uma variável aleatória é a medida da posição central da variável aleatória. A qual é dada pela fórmula: \\[\\small E(x) =  = \\sum x×f(x)\\] Ou seja, deve-se multiplicar cada valor da variável aleatória pela sua probabilidade. Como no exemplo abaixo: Veículos vendidos/ dia Probabilidade \\(x × f(x)\\) 0 0,18 0 × 0,18 = 0 1 0,39 1 × 0,39 = 0,39 2 0,24 2 × 0,24 = 0,48 3 0,14 3 × 0,14 = 0,42 4 0,04 4 × 0,04 = 0,16 5 0,01 5 × 0,01 = 0,05 Total 1 1,50 Neste caso significa que, durante o período de 300 dias de operação, pode-se esperar a média de 1,5 carros vendidos por dia. 9.4.1.2.2 Variância e Desvio Padrão A variabilidade, ou dispersão, nos valores da variável aleatória é medido pela variância pela aplicação da seguinte função: \\[\\small Var(x) = ^2 = \\sum(x - )^2 × f(x)\\] \\(\\small  = \\sqrt{\\sigma^2}\\) Ou seja, o valor de x menos à média, ao quadrado, multiplicado pela probabilidade de x. Como no exemplo abaixo: Veículos vendidos/ dia \\(x - \\) \\((x - )^2\\) \\(f(x)\\) \\((x - )^2 × f(x)\\) 0 0 - 1,50 = -1,50 2,25 0,18 2,25 × 0,18 = 0,4050 1 1 - 1,50 = -0,50 0,25 0,39 0,25 × 0,39 = 0,0975 2 2 - 1,50 = 0,50 0,25 0,24 0,25 × 0,24 = 0,0600 3 3 - 1,50 = 1,50 2,25 0,14 2,25 × 0,14 = 0,3150 4 4 - 1,50 = 2,50 6,25 0,04 6,25 × 0,04 = 0,2500 5 5 - 1,50 = 3,50 12,25 0,01 12,25 × 0,01 = 0,1225 Total 1 1,25 Portanto a variância do conjunto é 1,25. E o desvio padrão: \\(\\small  = \\sqrt{1,25} = 1,118\\) A explicação se baseia em medir o quão afastado um valor se encontra da média (valor esperado), e então os desvios são elevados ao quadrado e ponderados pelo valor correspondente da função de probabilidade. 9.4.1.3 Distribuição Poisson A Distribuição Poisson é muito útil para calcular a probabilidade de um certo número de eventos que ocorrerá em um específico intervalo de tempo ou espaço. Para um experimento ser classificado como Poisson precisa atender as seguintes propriedades: A probabilidade de uma ocorrência é a mesma para dois intervalos quaisquer de igual comprimento A ocorrência ou não ocorrência em determinado intervalo é independente da ocorrência ou não ocorrência em outro intervalo Nós poderíamos usar este tipo de distribuição para determinar a probabilidade de 10 clientes entrarem em uma loja nos próximos 30 minutos ou a probabilidade de 2 acidentes de carro ocorrerem em um determinado cruzamento no próximo mês. A Distribuição Poisson é um modelo para o número de eventos observados numa unidade de tempo ou de espaço, dado que a taxa de eventos por unidade é constante e os eventos ocorrem de modo independente. A fórmula de cálculo de Poisson é a seguinte: \\[\\small f(x) = \\frac{^x × e^{-}}{x!}\\] \\(\\small f(x) = \\textrm{a probabilidade de x ocorrência em um intervalo}\\) \\(\\small  = \\textrm{valor esperado, ou número médio de ocorrências}\\) \\(\\small e = (euler) 2,71828\\) Exemplo: Dado interesse em saber o número de carros que chegam a um caixa automático de banco durante o período de 15 minutos nas manhãs de final de semana, sabendo que: a probabilidade de um carro chegar é a mesma para dois períodos quaisquer de igual duração o fato de carros chegarem ou não chegarem em qualquer período é independente da chegada ou não chegada de outros carros em qualquer período. Portanto, Poisson é aplicável. Sabe-se que o número médio de carros que chegam no período de 15 minutos é 10, então ao aplicar a fórmula temos: \\(\\small f(x) =\\frac{^x × e^-}{x!}\\) \\(\\small f(x) = \\frac{10x × e-10}{x!}\\) Caso se busque saber a probabilidade de 5 carros chegarem no período de 15 minutos temos: \\(\\small f(x) = \\frac{10^5 × e^-10}{5!}= 0,0378\\) Obs: Caso se deseje a probabilidade em período menor de tempo, basta dividir a média proporcionalmente ao tempo. Por exemplo, para 15 minutos temos a média 10 e para 3 minutos teríamos a média 2. 9.4.1.3.1 Dist. Binomial Vs Dist. de Poisson Diferenças A Distribuição Poisson não conta o número de sucessos, como na distribuição binomial. A Distribuição Poisson conta o número de ocorrências de um evento particular sobre um intervalo específico de tempo ou espaço. Distribuição Binomial, o número de sucessos observados é limitado ao número de possibilidades. Na Distribuição Poisson, o número de resultados pode ser qualquer um. 9.4.1.3.2 Média, Variância e Desvio Padrão A média, ou valor esperado na distribuição de Poisson já é dada inicialmente devido a característica da distribuição. Por sua vez, a variância é igual a média. E o desvio padrão, a raiz da variância. Logo no caso dos carros teríamos: \\(\\small ^2 =  = 10\\) \\(\\small  = \\sqrt{10}= 3,16\\) 9.4.1.3.3 R Exemplo: Considere um processo que têm uma taxa de 0,5 defeitos por unidade. Qual a probabilidade de uma unidade apresentar dois defeitos? E nenhum defeito? O único parâmetro da Poisson é  (lambda), que representa a taxa de eventos por unidade. dpois(2, 0.5) ## [1] 0.07581633 dpois(0, 0.5) ## [1] 0.6065307 9.4.1.4 Distribuição Hipergeométrica A distribuição hipergeométrica é utilizada para calcular a probabilidade de obtermos x elementos rotulados de sucesso e (n - x) elementos rotulados como fracasso em uma seleção aleatória de n elementos, selecionados sem substituição. Para tanto precisamos obter: x sucessos dos r sucessos na população (n - x) fracassos dos (N - r) fracassos A distribuição hipergeométrica é restritamente relacionada com a distribuição binomial. Entretanto possuem significativas diferenças em relação a probabilidade dos ensaios e a relação entre ensaios. \\[\\small f(x) = \\frac{\\binom{r}{x} \\binom{N-r}{n-x}}{\\binom{N}{n}}\\] Para \\(\\small 0  x  r\\) \\(\\small r = \\textrm{número de elementos na população rotulados como sucesso}\\) \\(\\small N -r = \\textrm{número de elementos na população rotulados como fracasso}\\) \\(\\small n =\\textrm{número de ensaios}\\) \\(\\small N =\\textrm{número de elementos na população}\\) \\(\\small f(x) =\\textrm{probabilidade de x sucessos em n ensaios}\\) \\(\\small \\binom{N}{n} =\\textrm{número de maneiras que uma amostra de tamanho n pode ser selecionada de uma população tamanho N}\\) \\(\\small \\binom{r}{x}=\\textrm{n° de maneiras pelas quais x sucessos podem ser selecionados de um total de r sucessos da população}\\) \\(\\small \\binom{N-r}{n-x}=\\textrm{n° de maneiras pelas quais(n -x) frac. podem ser selecionados de um total de(N - r) frac. da pop.}\\) \\(\\small \\binom{r}{x}=\\frac{r!}{x!(r -x)!}\\) Exemplo: Uma caixa de fusíveis possui 12 unidades de fusíveis, sabendo-se que a caixa tem 5 fusíveis defeituosos, caso o controlador selecione 3 fusíveis aleatório, qual a probabilidade de encontrar um fusível defeituoso? Temos: n = 3 (selecionados 3) N = 12 (população de 12 elementos) r = 5 (contém 5 elementos defeituosos (sucesso)) x = 1 (busca-se 1 fusível defeituoso (sucesso) na coleta) OBS: \\(\\small \\binom{r}{x}=\\frac{r!}{x!(r -x)!}\\) \\(\\small f(x) =\\frac{ \\binom{r}{x} \\binom{N-r}{n-x}}{\\binom{N}{n}}\\) \\(\\small f(x) = \\frac{\\binom{5}{1} \\binom{12-5}{3-1}}{\\binom{12}{3}}\\) \\(\\small f(x) = \\frac{\\binom{5}{1} \\binom{7}{2}}{\\binom{12}{3}}\\) \\(\\small f(x) = \\frac{(\\frac{5!}{1! (4!)} ) (\\frac{7!}{2! (5!)} )}{(\\frac{12!}{3! (9!)})}\\) \\(\\small f(x) = \\frac{(5 ) (\\frac{7×6}{2} )}{(\\frac{12×11×10}{6})}\\) \\(\\small f(x) = \\frac{(5 ) (21 )}{(220)}= 0,4773\\) Portanto, a probabilidade de se encontrar 1 fusível defeituoso numa coleta de 3 fusíveis é de 0,4773. Caso, por exemplo, se buscasse a probabilidade de pelo menos um fusível ser defeituoso numa coleta de 3, o mais simples seria buscar a probabilidade de não ser coletado nenhum defeituoso e subtrair de 1. Ou seja, se buscaria a probabilidade do complemento de A ao invés da probabilidade de A. 9.4.1.4.1 Dist. Hipergeométrica Vs Dist. Binomial =  Ambos dividem os casos em sucesso e fracasso Na Distribuição de Probabilidade Hipergeométrica os ensaios não são independentes Se o número de ensaios na Distribuição de Probabilidade Hipergeométrica for grande o suficiente, o termo \\(\\small \\frac{(N - n)}{(N - 1)}\\) aproxima-se de 1. Em consequência o valor esperado e a variância podem ser escritos como \\(\\small E(x) = n×p\\) e \\(\\small Var(x) = n×p(1 - p)\\), expressões estas, similares as utilizadas para calcular o valor esperado e variância da Distribuição Binomial. Portanto, tendo população grande o suficiente, a Dist. Hipergeométrica pode ser aproximada por meio de uma Dist. Binomial com n ensaios e uma probabilidade de \\(\\small p = {r}{N}\\) Na Distribuição de Probabilidade Hipergeométrica a probabilidade de sucesso de altera a cada ensaio 9.4.1.4.2 Valor Esperado O valor esperado, ou média da distribuição hipergeométrica é dado por: \\[\\small E(x) =  = n×(\\frac{r}{N})\\] \\(\\small r = \\textrm{número de elementos na população rotulados como sucesso}\\) \\(\\small N =\\textrm{número de elementos na população}\\) \\(\\small n =\\textrm{número de ensaios}\\) No exemplo anterior teríamos: \\(\\small E(x) =  = n×(\\frac{r}{N})\\) \\(\\small E(x) =  = 3×\\frac{5}{12}= 1,25\\) 9.4.1.4.3 Variância e Desvio Padrão \\[ \\small \\operatorname{Var}(x)=\\sigma^{2}=n \\times\\left(\\frac{r}{N}\\right) \\times\\left(1-\\frac{r}{N}\\right) \\times\\left(\\frac{N-n}{N-1}\\right) \\] \\(\\small r = \\textrm{número de elementos na população rotulados como sucesso}\\) \\(\\small N =\\textrm{número de elementos na população}\\) \\(\\small n =\\textrm{número de ensaios}\\) No exemplo anterior teríamos: \\(\\small \\operatorname{Var}(x)=\\sigma^{2}=n \\times\\left(\\frac{r}{N}\\right) \\times\\left(1-\\frac{r}{N}\\right) \\times\\left(\\frac{N-n}{N-1}\\right)\\) \\(\\small \\operatorname{Var}(x)=\\sigma^{2}=3 \\times\\left(\\frac{5}{12}\\right) \\times\\left(1-\\frac{5}{12}\\right) \\times\\left(\\frac{12-3}{12-1}\\right)\\) \\(\\small 3× \\left(\\frac{5}{12}\\right)×\\left(\\frac{7}{12}\\right)×\\left(\\frac{9}{11}\\right) = \\frac{105}{176}=0,60\\) 9.4.2 Distribuição de Probabilidade Contínua Descreve quantidades aleatórias de dados que podem assumir valores infinitos. Principais tipos de distribuição Uniforme Exponencial Gama Chi-Quadrado Formatos mais comuns Momentos em que são mais úteis Distribuição Normal dados tendem ao centro da distribuição e outliers são raros Distribuição Uniforme descrever os dados quando todos os valores têm a mesma chance de ocorrer 9.4.2.1 Diferença em relação a probabilidade de variáveis discretas Variável Aleatória Discreta Variável Aleatória Contínua  Assume uma probabilidade para um valor em particular Assume uma probabilidade para um intervalo  Probabilidade definida pelos pontos e combinações possíveis. Probabilidade definida pela área sob o gráfico correspondente ao intervalo  Cada ponto tem uma probabilidade específica Todos os pontos do intervalo têm a mesma probabilidade  Um ponto específico tem uma probabilidade específica Um ponto específico tem probabilidade zero 9.4.2.2 Distribuição Uniforme Uma distribuição de probabilidade é uniforme quando a probabilidade é proporcional ao comprimento do intervalo e a variável aleatória encontra-se uniformemente distribuída. Trata-se portanto da probabilidade da variável aleatória assumir um valor DENTRO de um intervalo e NÃO de um VALOR EM PARTICULAR. A probabilidade é dada pela área sob o gráfico da função de densidade de probabilidade do intervalo que se situa entre \\(\\small x\\) e \\(\\small x_2\\). \\[ \\small f(x)=\\left\\{\\begin{array}{l} \\frac{1}{b-a} \\text { para } a \\leq x \\leq b \\\\ 0 \\text { para outro ponto qualquer } \\end{array}\\right\\} \\] \\(\\small x = \\textrm{variável aleatória}\\) \\(\\small a =\\textrm{início do intervalo}\\) \\(\\small b =\\textrm{fim do intervalo}\\) Exemplo: Dado que o tempo de voo de Chicago a Nova York possa ter qualquer valor no intervalo de 120 a 140 minutos, Então entende-se que qualquer minuto entre 120 - 140 minutos tem a mesma probabilidade de ocorrer. Observando na função: \\(\\small f(x)=\\left\\{\\begin{array}{l} \\frac{1}{140-120} \\text { para } 120 \\leq x \\leq 140 \\\\ 0 \\text { para outro ponto qualquer } \\end{array}\\right\\}\\) \\(\\small f(x)=\\left\\{\\begin{array}{l} \\frac{1}{20} \\text { para } 120 \\leq x \\leq 140 \\\\ 0 \\text { para outro ponto qualquer } \\end{array}\\right\\}\\) A probabilidade de um intervalo, é dado pela área sob o gráfico correspondente ao intervalo, sendo portanto o produto da probabilidade de cada ponto pelo comprimento do intervalo. No caso de um intervalos de voo entre 120 e 130 minutos teremos: \\(\\small P(a  x  b) = f(x) ×(b - a)\\) Dado que 130 e 125 então dentro do intervalo de f(x)1; \\(\\small P(120  x  130) =\\frac{1}{20}×(130 - 120) = \\frac{10}{20} = 0,5\\) 9.4.2.2.1 Valor Esperado \\[\\small E(x) =  = \\frac{a + b}{2}\\] No exemplo acima o valor esperado seria: \\(\\small E(x) =  = \\frac{a + b}{2}\\) \\(\\small E(x) =  = \\frac{120 + 140}{2} = 130\\) 9.4.2.2.2 Variância e Desvio Padrão \\(\\small Var(x) = ^2 = \\frac{(b - a)^2}{12}\\) \\(\\small  = \\sqrt{\\frac{(b - a)^2}{12}}\\) No exemplo acima a variância e desvio padrão seriam: \\(\\small Var(x) = ^2 = \\frac{(b - a)^2}{12}\\) \\(\\small Var(x) = ^2 = \\frac{(140 - 120)2}{12} 33,33...\\) \\(\\small  = \\sqrt{\\frac{(b + a)^2}{12}}  5,77\\) 9.4.2.3 Distribuição Normal / Distribuição Gaussiana A Distribuição Normal, ou Gaussiana, é a mais importante distribuição contínua, devido sua variedade de aplicações práticas e em inferência estatística. A curva normal tem formato de sino: A função densidade de probabilidade é dada por: \\[\\small f(x) = \\frac{1}{\\sqrt{2}} -(x - )^2/ 2^2\\] \\(\\small  = média\\) \\(\\small  = 3,14159 ...\\) \\(\\small  = 2,7182...\\) \\(\\small  = \\textrm{Desvio Padrão}\\) 9.4.2.3.1 Propriedades 9.4.2.3.1.1 Principais Características O formato de distribuição é simétrico em forma de sino em torno da média, portanto, metade dos dados se encontram acima da média e metade abaixo. A posição e forma são definidos pela média() e desvio padrão() Média = Mediana = Moda = Ponto máximo A probabilidade é dada pela área sob a curva. A área total corresponde a 1 de probabilidade e a área sob a curva à direita e à esquerda da média, possuem probabilidade de 0,5 cada. A regra empírica é aplicável para dedução da probabilidade dos dados. 9.4.2.3.1.2 Curva Normal e Desvio Padrão O Desvio Padrão determina o formato da curva padrão. Quanto maior o desvio padrão de um conjunto de dados, mais dispersos se encontram em relação à média, portanto, na representação gráfica o formato do sino se encontra mais achatado. Portanto, quando mais achatada a curva, maior o desvio padrão. 9.4.2.3.1.3 Curva normal e Média A média de uma curva normal determina seu posicionamento na reta. Regra O valor médio de todas as médias de amostras possíveis, a partir de um dado tamanho de população (n &gt; 20), é igual a média da população 9.4.2.3.2 Distribuição Normal Padrão de Probabilidade A distribuição normal padrão de probabilidade é caracterizado pela  = 0 e  = 1. A figura abaixo exemplifica a distribuição normal padrão: Devido às propriedades especiais da média e desvio padrão a função de densidade normal padrão de probabilidade pode ser simplificada para a seguinte equação: \\[\\small f(x) = \\frac{1}{\\sqrt{2}} ^{- z^2/ 2}\\] \\(\\small  = 3,14159 ...\\) \\(\\small  = 2,7182...\\) \\(\\small z =\\textrm{Score Z}\\) \\(\\small z = \\frac{x - }{}\\) 9.4.2.3.3 Aproximação Normal às Probabilidades Binomiais Quando \\(\\small n × p  5\\) e \\(\\small n(1 - p)  5\\) é favorável a utilização da distribuição normal para aproximação da probabilidade ao invés do uso da probabilidade binomial. Basta realizar o ajuste: \\(\\small  = n × p\\) \\(\\small  = \\sqrt{ n ×p ( 1 - p)}\\) e ao buscar o valor na tabela de score z, deve-se considerar o intervalo ±0,5 do valor buscado. Esse processo chama-se fator de correção de continuidade. Exemplo: Uma empresa tem o histórico de cometer erros em 10% das faturas que emite. Dada uma amostra de 100 faturas, qual a probabilidade de serem cometidos 12 erros? Realizando o cálculo por meio da função binomial temos: \\[\\small f(x)= \\binom{n}{x}p^x(1-p)^{(n-x)}\\] \\(\\small \\binom{n}{x} = \\frac{n!}{x!(n-x)!}\\) \\(\\small n = 100\\) \\(\\small x = 12\\) \\(\\small p = 0,1\\) \\(\\small (1 - p) = 0,9\\) 12 \\(\\small \\frac{100!}{12!88!} × (0,10)^{12}(0,90)^{88} =0,098\\) Na calculadora: (n) nCr (x) * (0,1)^12 * (0,9)^88 Realizando o cálculo por meio da aproximação com a normal: \\(\\small  = n × p\\) \\(\\small  = 100 × 0,1 = 10\\) \\(\\small  = n ×p ( 1 - p)\\) \\(\\small  =\\sqrt{100 ×0.1 ( 1 - 0.1)} =\\sqrt{100 ×0.1 ×0.9} = \\sqrt{9} = 3\\) Fator de correção de continuidade \\(\\small 11,5  x  12,5\\) library(tigerstats) pbinomGC(c(12,12),region=&quot;between&quot;, prob =0.1, size=100,graph=TRUE) ## [1] 0.09878801 pnormGC(c(11.5,12.5),region=&quot;between&quot;, mean = 10, sd = 3,graph=TRUE) ## [1] 0.1062092 \\(\\small z = \\frac{x - }{}\\) Para 12,5: \\(\\small z = \\frac{12,5 - 10}{3} =0,83\\) Para 11,5: \\(\\small z = \\frac{11,5 - 10}{3} = 0,50\\) Consultando a tabela de probabilidades a partir do score z temos que: \\(\\small P( 12,5  x  ) = Z(0,83)= 0,2967\\) \\(\\small P( 11,5  x  ) = Z(0,50)= 0,1915\\) Portanto, a \\(\\small P(11,5  x  12,5)\\) é dado por, \\(\\small P( 12,5  x  ) - P( 11,5  x  )\\) \\(\\small 0,2967 - 0,1915 = 0,1052\\) Portanto, a probabilidade de 12 erros em 100 faturas é de 0,1052 9.4.2.3.4 R O R inclui funcionalidades para operações com distribuições de probabilidades. Para cada distribuição há 4 operações básicas indicadas pelas letras: d: calcula a densidade de probabilidade f(x) no ponto p: calcula a função de probabilidade acumulada F(x) no ponto q: calcula o quantil correspondente a uma dada probabilidade r: retira uma amostra da distribuição Para utilizar as funções combina-se uma das letras acima com uma abreviatura do nome da distribuição. Por exemplo, para calcular probabilidades usamos: pnorm para normal, pexp para exponencial, pbinom para binomial, ppois para Poisson e assim por diante. #x &lt;- rnorm(n, mean, sd) Onde n é o tamanho da amostra e mean e sd são parâmetros opcionais relacionados à média e desvio padrão, respectivamente. 9.4.2.3.4.1 Distribuição Normal x &lt;- rnorm(100) qplot(x,binwidth=1,col=I(&quot;black&quot;)) 9.4.2.3.4.2 Densidade Observe que o gráfico gerado assemelha-se a uma Gaussiana e não apresenta assimetria. Quando o gráfico da distribuição possui tal forma, há grandes chances de se tratar de uma distribuição normal. x &lt;- seq(-6, 6, by=0.01) y &lt;- dnorm(x) data&lt;-data.frame(x,y) ggplot(data, aes(x=x, y=y))+ geom_line() 9.4.2.4 Distribuição exponencial de Probabilidade A distribuição exponencial de probabilidade pode ser utilizada para variáveis aleatórias como intervalos de tempo de chegada de carros, tempo de carregamento de caminhões, distância entre defeitos importantes em uma rodovia, filas de espera. A função densidade exponencial de probabilidade é a seguinte: \\[\\small f(x) = \\frac{1}{}e^{-x / } \\textrm{ para } x0, &gt;0\\] Exemplo: Dado o tempo de carga médio de 15 minutos e distribuição exponencial. Qual a probabilidade do carregamento levar 6 minutos ou menos? e 18 minutos ou menos? A função de probabilidade da situação citada seria a seguinte: \\(\\small f(x) = \\frac{1}{15}e^{-x / 15} \\textrm{ para } x0, &gt;0\\) E o gráfico da função seria o seguinte: Neste tipo de distribuição a probabilidade é definida pela área sob a curva, portanto, se considera um intervalo de probabilidade. A probabilidade cumulativa é dada pela seguinte função: \\[\\small P( x  x_0) 1 - e^{-x_{0}/ }\\] Portanto, para o cálculo de tempo de carregamento de 6 minutos ou menos: \\(\\small P( x  x_0) 1 - e^{-x_{0}/ }\\) \\(\\small P( x  6) 1 - e^{-6/ 15}=0,3297\\) Portanto, para o cálculo de tempo de carregamento de 6 minutos ou menos: \\(\\small P( x  x_0) 1 - e^{-x_{0}/ }\\) \\(\\small P( x  18) 1 - e^{-18/ 15}=0,6988\\) A partir disso podemos também concluir que a probabilidade de um carregamento demorar entre 6 minutos e 18 minutos é de \\(\\small P( x  18)\\) subtraído de \\(\\small P( x  6)\\) \\(\\small P( x  18) - P( x  6) = 0,6988 - 0,3297\\) O que graficamente corresponde a: 9.4.2.4.1 Média e Desvio Padrão Na distribuição exponencial, a média e desvio padrão são iguais, a variância portanto, o quadrado do desvio padrão. No exemplo acima teríamos: \\(\\small  = 15\\) \\(\\small  = 15\\) \\(\\small ^2= (15)^2 = 225\\) 9.4.2.4.2 Relação entre Dist. de Poisson e Dist. exponencial Distribuição de Poisson Distribuição Exponencial Fornece a descrição do número de ocorrências por intervalo Fornece a descrição da extensão do intervalo entre as ocorrências Exemplo: Dado que, em média, 10 carros chegam a um lava rápido durante uma hora, podemos descrever a situação com a distribuição de Poisson: \\[\\small f(x) = \\frac{^xe^{-}}{x!}\\] \\(\\small  = \\textrm{o valor esperado, o número médio de ocorrências durante um intervalo específico}\\) \\(\\small f(x) = \\frac{10^xe^{-10}}{x!}\\) Obs: se as chegadas seguem uma distribuição de Poisson, o tempo entre as chegadas deve seguir uma distribuição exponencial. O tempo médio de carros que chegam é de: \\(\\small 1 hora = \\frac{0,1 hora/ carro}{10\\textrm{ carros}}\\) Portanto a distribuição exponencial correspondente que descreve o tempo de chegadas tem uma média de 0,1 hora por carro, em consequência, a função densidade exponencial de probabilidade apropriada é: \\(\\small f(x) = \\frac{1}{0,1} e^{-x/0,1} = 10e^{-10x}\\) Para um x= 1 teríamos: Poisson: \\(\\small4,54 ×10^{-4}\\) Exponencial: \\(\\small4,54 ×10^{-4}\\) 9.4.2.5 Distribuição Chi-Quadrado A distribuição qui-quadrado foi descoberta por K. Pearson quando utilizou o \\(\\small ^2\\) como teste de significância para comprovar o ajustamento das curvas de frequência (goodness of fit). Na verdade foi uma redescoberta, embora Pearson não tivesse conhecimento, pois o astrônomo alemão F. R. Helmert já a havia descoberta em 1875, mas noutro contexto, constituindo mais um exemplo da lei de eponimia de Stigler. A distribuição é utilizada para análises estatísticas como teste de hipóteses e cálculo de intervalo de confiança, ajustamento de curvas de frequência e pode ser observado em alguns eventos da vida real. A distribuição qui-quadrada pode ser interpretada de duas formas, como um caso particular da distribuição gamma, que será analisada mais adiante, ou como sendo a soma de normais padronizadas ao quadrado. Tome \\(\\small _i N(0,1)\\) então: \\[ \\small \\sum_{j=1}^{r} X_{j}^{2}=\\chi_{r}^{2} \\] A formulação acima trata de elevar ao quadrado todos os elementos de uma variável aleatória normalmente distribuída, assim a distribuição resultante será uma distribuição qui-quadrado. A função densidade é exibida abaixo, sendo k os graus de liberdade: A função densidade correspondente seria: \\[\\small f(x)=\\frac{x^{k / 2-1} e^{-x / 2}}{2^{k / 2} \\Gamma(k / 2)} \\quad para \\quad x \\geq 0\\] Os graus de liberdade são definidos pela quantidade de elementos independentes e livres para variar na distribuição. Notemos pelo gráfico da distribuição qui-quadrado que ela é assimétrica e positiva, isto vale para qualquer grau de liberdade. Sua positividade é fácil de ser verificada, pois ela é soma de normais ao quadrado, portanto só pode ser positiva. A distribuição qui-quadrado possui diversas aplicações na inferência estatística. Quanto maior os graus de liberdade mais semelhante a uma distribuição normal ela se torna. A tabela abaixo demonstra a tabela de probabilidade da distribuição chi-quadrado para diversos graus de liberdade: 9.4.2.5.1 Variância \\[\\small ^2 = 2k\\] Onde k são os graus de liberdade 9.4.2.5.2 Valor esperado \\[\\small  = k\\] Onde k são os graus de liberdade 9.4.2.5.3 Teste Chi Quadrado O teste Chi-Quadrado tem por objetivo comparar proporções, ou seja, possíveis divergências entre as frequências observadas e esperadas para um certo evento. Portanto ele compara: Frequência de um determinado acontecimento observado de uma amostra se desvia significativamente ou não da frequência com que ele é esperado Comparar a distribuição de diversos acontecimentos em diferentes amostras, a fim de avaliar se as proporções observadas destes eventos mostram ou não diferenças significativas ou se as amostras diferem significativamente quanto às proporções desses acontecimentos. Condições para ser utilizado: Dados nominais, ordinais e intervalares (variável categórica) Amostra aleatória Amostra independente Cada observação pertence a uma e somente uma categoria Nenhuma frequência esperada deve ser menor do que 5 Quando forem dois fatores (tabela 2x2) Se alguma frequência esperada for menor que 10 é preciso utilizar a correção de Yates 9.4.2.5.4 Passos: Insira a Frequência Observada Insira a Frequência Esperada Calcule a diferença entre a frequência observada e a frequência esperada \\(\\small \\frac{( o - e)^2}{e}\\) Eleve a diferença ao quadrado \\(\\small \\frac{( d)^2}{e}\\) Divida a diferença elevada ao quadrado pela frequência esperada. Somar todos os resultados do passo 5 e obter a estatística de teste, \\(\\small \\chi^2= \\sum \\frac{d^2}{e}\\) 1 2 3 4 5 Categoria 1 \\(\\small FrO_1\\) \\(\\small FrE_1\\) \\(\\small FrO_1 - FrE_1\\) \\(\\small (FrO_1 - FrE_1)^2\\) \\(\\small \\frac{(FrO_1 - FrE_1)^2}{FrE_1}\\) Categoria 2 \\(\\small FrO_2\\) \\(\\small FrE_2\\) \\(\\small FrO_2 - FrE_2\\) \\(\\small (FrO_2 - FrE_2)^2\\) \\(\\small \\frac{(FrO_2 - FrE_2)^2}{ FrE_2}\\) FrO: Frequência Observada FrE Frequência Esperada Obs: A diferença é elevada ao quadrado porque caso fosse somente somada resultaria em 0. Portanto, é preciso elevar ao quadrado para alterar sua escala, e assim ser possível trabalhar com os valores. A divisão pela frequência esperada resulta na estatística de teste do teste qui-quadrado. O teste \\(\\small \\chi^2\\) é, essencialmente, um mecanismo pelo qual os desvios de uma proporção hipotética são reduzidos a um único valor, que permite determinar uma probabilidade a respeito da casualidade ou não dos desvios entre as proporções observadas e esperadas. Neste sentido, o \\(\\small \\chi^2\\) será o somatório destes desvios. Assim, quando as frequências observadas são muito próximas às esperadas, o valor de \\(\\small \\chi^2\\) é pequeno, e quando as divergências são grandes, consequentemente assume valores altos. Exemplo: \\(\\small FrO_n\\) \\(\\small FrE_n\\) \\(\\small FrO_2 - FrE_2\\) \\(\\small (FrO_2 - FrE_2)^2\\) \\(\\small \\frac{(FrO_2 - FrE_2)^2}{FrE_2}\\) Categoria 1 38 20 18 324 16,2 Categoria 2 25 20 5 25 1,25 Categoria 3 16 20 -4 16 0,8 Categoria 4 12 20 -8 64 3,2 Categoria 5 9 20 -11 121 6,05 \\(\\small \\chi^2=\\) 27,5 library(data.table) frObs&lt;- data.table( Categoria_1 = 38, Categoria_2 = 25, Categoria_3 = 16, Categoria_4 = 12, Categoria_5 = 9) quiqua &lt;-chisq.test(frObs) quiqua ## ## Chi-squared test for given probabilities ## ## data: frObs ## X-squared = 27.5, df = 4, p-value = 1.575e-05 O parâmetro p não foi informado porque a frequência esperada era a mesma para todas as categorias, tornando assim dispensável o preenchimento, visto que, por padrão a função já é assim configurada. 9.4.2.5.5 Correção de Yates Ao aplicar o teste do \\(\\small \\chi^2\\) supõe-se que o tamanho amostral será relativamente grande, assim como cada classe amostral . Se isso não ocorrer o qui-quadrado calculado pode ser superestimado. Nestes casos alguns autores recomendam o uso do fator de correção de Yates. \\[\\small \\chi^2 = \\sum_{i=1}{k}\\frac{(|f_i - e_i| -0,5)}{e_i}\\] \\(\\small f_i= \\textrm{frequência observada para categoria i}\\) \\(\\small e_i = \\textrm{frequência esperada para categoria i}\\) \\(\\small k = \\textrm{número de categorias}\\) Como regra básica essa correção é usada quando o qui-quadrado observado é maior que o crítico e: O tamanho da amostra é menor que 40; ou Há pelo menos uma classe com frequência esperada menor que 5 Apesar de a correção de continuidade não provocar grandes alterações no valor do $^2 $ ,essas alterações podem ser importantes quando se está próximo do limite entre região de rejeição e a região de não rejeição. Obs: A correção de Yates é considerada muito conservadora e portanto pouco indicada. O teste exato de Fisherpode oferecer uma correção mais adequada. "],["teste-de-hipótese.html", "10 Teste de hipótese 10.1 Como formular hipóteses? 10.2 Erros do tipo I e tipo II 10.3 Média da população: Desvio Padrão  conhecido 10.4 Média da população: Desvio Padrão () desconhecido 10.5 Proporção da população 10.6 Inferência acerca da diferença entre médias 10.7 Inferência acerca da diferença entre duas proporções 10.8 Proporção de uma população multinomial 10.9 Teste exato de Fisher 10.10 ANOVA - Análise de Variância 10.11 Transformação de dados 10.12 Comparações Envolvendo Proporções e Teste de Independência", " 10 Teste de hipótese Teste de hipóteses, teste estatístico ou teste de significância é um procedimento estatístico que permite tomar uma decisão entre duas ou mais hipóteses, utilizando os dados observados de um determinado experimento. Uma hipótese é suposição sobre um parâmetro específico de uma população, como média, proporção ou desvio padrão. Em muitas situações práticas o interesse do pesquisador é verificar a veracidade sobre um ou mais parâmetros populacionais \\(\\small (,^2,p)\\) ou sobre a distribuição de uma variável aleatória. Um dos primeiros trabalhos sobre testes foi publicado em 1710 (John Arbuthnot); Um dos primeiros procedimentos estatísticos que chega perto de um teste, no sentido moderno foi proposto por Karl Pearson em 1900. Esse foi o famoso teste do Qui-quadrado, utilizado para comparar uma distribuição de frequência observada com uma distribuição teoricamente assumida. A ideia de testar hipóteses foi posteriormente codificada e elaborada por R. A Fischer (1925), que considerou os dados como um vetor de variáveis aleatórias que pertenciam a uma distribuição de probabilidade Uma outra abordagem (competitiva a de Fischer) foi estabelecida por J. Neyman e Egon Pearson (1928) Mais tarde, Lehmann (1993) argumentou que de fato era possível unificar as formulação, combinando as melhores características das duas abordagens As ferramentas que são usadas para testar hipóteses são as hipóteses nula e alternativa: \\[\\small H_0= \\textrm{Hipótese Nula}\\] \\[\\small H_a= \\textrm{Hipótese Alternativa}\\] Cada hipótese representa um tipo de situação: Hipótese Nula Status quo Comprovar uma suposição ou afirmação Valida que o parâmetro da população é  ou  a um valor específico É para ser verdadeira, ao menos que seja comprovada por evidência contrária Usado para ver se alguma hipótese estabelecida inicialmente pode ser rejeitada ou não Hipótese alternativa Representa o oposto da hipótese nula Ao testar hipóteses, iniciamos por criar uma hipótese experimental a respeito de um parâmetro da população. Essa hipótese experimental é chamada hipótese nula. Ela é denotada por \\(\\small H_0\\). Definimos então outra hipótese, denominada hipótese alternativa, a qual é o oposto daquilo que é formulado na hipótese nula \\(\\small H_a\\). 10.1 Como formular hipóteses? A hipótese a ser testada pela pesquisa deve ser formulada como hipótese alternativa, enquanto a hipótese nula representa o status quo. Se o objetivo é testar uma afirmação é verdadeira o valor será colocado na hipótese nula. Pode também ser usada em situações de tomada de decisão representando um padrão/ valor esperado Os símbolos matemáticos de comparação: Hipótese Nula:    Hipótese Alternativa: &lt; &gt; = Exemplo: Um certo modelo de automóvel atinge a eficiência média de 10,21 Km/L em termos de consumo de combustível. Um novo sistema foi criado e precisa comprovar que esse novo sistema aumenta a taxa média de quilômetros por litro. Nesse caso a hipótese de pesquisa é que o novo sistema produzirá uma taxa média superior a 10,21, ou seja,  &gt; 10,21. Como diretriz geral, uma hipótese de pesquisa deve ser formulada como a hipótese alternativa. Portanto as hipóteses nula e alternativa relativas ao estudo são: \\[\\small H_0:   10,21\\] \\[\\small H_a:  &gt; 10,21\\] Se os resultados da amostra indicaram que \\(\\small H_0\\) não pode ser rejeitada, os pesquisadores não poderão concluir que o novo sistema de injeção de combustível é melhor. Entretanto, se os resultados da amostra indicarem que \\(\\small H_0\\) pode ser rejeitada, os pesquisadores poderão inferir que \\(\\small H_a:  &gt; 10,21\\) é verdadeira. Com essa conclusão, os pesquisadores obtêm base estatística necessária para afirmar que o novo sistema aumenta o número médio de quilômetros por litro. A conclusão de que a hipótese de pesquisa pode ser verdadeira é obtida se os dados da amostra contradisserem a hipótese nula. Hipótese Nula \\(\\small H_0:   10,21\\) \\(\\small H_0:   10,21\\) \\(\\small H_0:  = 10,21\\) Hipótese Alternativa \\(\\small H_a:  &gt; 10,21\\) \\(\\small H_a:  &lt; 10,21\\) \\(\\small H_a:   10,21\\) 10.2 Erros do tipo I e tipo II Um erro do Tipo I consiste em rejeitar a \\(\\small H_0\\) verdadeira, ou seja, o estudo indica que a hipótese nula é falsa, quando na verdade não é. Um erro do Tipo II consiste em aceitar uma \\(\\small H_0\\) falsa, ou seja, o estudo indica que hipótese nula é verdadeira quando na verdade é falsa. Conclusão \\(\\small H_0\\) Verdadeira \\(\\small H_0\\) Falsa Aceitar \\(\\small H_0\\) Correto Erro do tipo II Rejeitar \\(\\small H_0\\) Erro do tipo I Correto O nível de significância ()indica a probabilidade de cometer erro do Tipo I, quando a hipótese nula é verdadeira enquanto a igualdade. As escolhas comuns para o nível de significância é de 0,05 e 0,01. Testes de hipótese que somente controlam o erro de tipo I são chamados teste de significância. Nestes, somente se chega à conclusão de Não rejeitar a \\(\\small H_0\\), já que a conclusão de Aceitar \\(\\small H_0\\) coloca-se em risco de cometer um erro de tipo II. Exemplo: Um certo modelo de automóvel atinge a eficiência média de 10,21 Km/L em termos de consumo de combustível. Um novo sistema foi criado e precisa comprovar que esse novo sistema aumenta a taxa média de quilômetros por litro. Nesse caso a hipótese de pesquisa é que o novo sistema produzirá uma taxa média superior a 10,21, ou seja,  &gt; 10,21. Como diretriz geral, um hipótese de pesquisa deve ser formulada como a hipótese alternativa. Portanto as hipóteses nula e alternativa relativas ao estudo são: \\[\\small H_0:   10,21\\] \\[\\small H_a:  &gt; 10,21\\] O nível de significância, portanto trataria da probabilidade de rejeitar \\(\\small H_0\\) quando =10,21. 10.3 Média da população: Desvio Padrão  conhecido Testes a respeito da média acerca uma população normalmente distribuída, ou grande o suficiente Teorema do Limite Central com desvio padrão conhecido. 10.3.1 Teste unicaudal Os testes unicaudais assumem as seguintes formas: Teste de Cauda Inferior Teste de Cauda Superior \\(\\small H_0:   _0\\) \\(\\small H_0:   _0\\) \\(\\small H_a:  &lt; _0\\) \\(\\small H_a:  &gt; _0\\) Exemplo - Teste de cauda Inferior: Uma certa fábrica de café informa em suas embalagens que cada lata de café contém 3 libras de produto. Sabe-se ser impossível que cada lata contenha exatamente 3 libras de café, entretanto, a média de enchimento de cada lata é de no mínimo 3 libras, o que garante os direitos dos consumidores . Temos portanto que a hipótese nula e alternativa são: \\[\\small H_0:   3\\] \\[\\small H_a:  &lt; 3\\] Isto porque a afirmação do estado atual (fato) é que as latas possuem ao menos, em média, 3 libras de café por lata, e o que se busca provar/ testar é a possibilidade de haver menos de 3 libras de café em cada lata. Supondo que uma amostra de 36 latas foi tomada e a média amostral \\((\\bar{x})\\) foi calculada como uma estimativa da média da população (). Se: o valor da média populacional for inferior a 3 libras, a hipótese nula será posta em dúvida então quanto menor a média populacional deve ser para podermos rejeitar a hipótese nula? Essa questão pode ser respondida pelo nível de significância escolhido, o qual informa a hipótese de se cometer um erro do tipo I e rejeitar a \\(\\small H_0\\) enquanto igualdade, quando ela na realidade é verdadeira. Digamos que nesta situação a probabilidade aceita de se cometer um erro de tipo I seja de 1%, ou seja,  = 0,01 A partir disso vamos calcular as estatísticas de teste: O desvio padrão dessa população é conhecido:  = 0,18 A população de pesos de enchimento está normalmente distribuída, portanto a distribuição amostral da x também estará O tamanho da amostra = 36 Sabendo que distribuição amostral da \\(\\small \\bar{x}\\) está normalmente distribuída, a distribuição amostral de: \\[\\small z = \\frac{\\bar{x} - _0}{_{\\bar{x}}}\\] \\[\\small z = \\frac{\\bar{x} - 3}{0,03}\\] Com base na tabela de distribuição normal sabemos que: z = -1 significa que o de \\(\\small \\bar{x}\\) está um erro padrão abaixo do valor hipotético da média esta área corresponde a uma probabilidade de aproximadamente: \\(0,5 - 0,3413 = 0,1587\\) z = -2 significa que o de \\(\\small \\bar{x}\\) está dois erros padrão abaixo do valor hipotético da média esta área corresponde a uma probabilidade de aproximadamente: \\(0,5 - 0,4772 = 0,0228\\) z = -3 significa que o de \\(\\small \\bar{x}\\) está três erros padrão abaixo do valor hipotético da média esta área corresponde a uma probabilidade de aproximadamente: \\(0,5 - 0,4987 = 0,0013\\) Portanto, para se obter a estatística de teste para determinar se \\(\\small \\bar{x}\\) se desvia do valor hipotético de  o suficiente para justificar a rejeição da hipótese nula: \\[\\small z = \\frac{\\bar{x} - _0}{/\\sqrt{n}}\\] Dois critérios podem ser utilizados para responder essa questão: Usando o valor de z para calcular a probabilidade denominada valor p Valor p : mede o suporte ( ou a falta de suporte) que uma amostra da a hipótese nula - base para determinar se a hipótese nula deve ser rejeitada ou não, dado o nível de significância Vantagem: o valor p informa o quão significativos são os resultados ( nível observado de significância) Determinando o valor crítico Ponto de referência para determinar se o valor da estatística de teste é pequeno o bastante para rejeitar a hipótese nula 10.3.1.1 Valor p O valor p, p-value ou nível observado de significância, é uma probabilidade calculada usando-se a estatística de teste, que mede o apoio ( ou a falta de apoio) proporcionado pela amostra a hipótese nula. É o menor nível de significância com que se rejeitaria a hipótese nula. O valor p varia de 0 a 1. Quanto mais próximo a 1, mais suporte a estatística de teste da a hipótese nula (\\(\\small H_0\\)). Valores p grandes levam a não rejeição da hipótese nula Quanto mais próximo a 0, menos suporte a estatística de teste da a hipótese nula(\\(\\small H_0\\)). O que é incomum dada a suposição de uma \\(\\small H_0\\) verdadeira, logo levam a rejeição da hipótese nula (\\(\\small H_0\\)) Agora utiliza-se a estatística de teste para calcular o valor p, o qual depende do tipo de teste que será feito ( cauda inferior, cauda superior, bicaudal). Num teste de cauda inferior, o valor p é a probabilidade de obtermos um valor para estatística de teste tão pequeno ou menor que aquele produzido pela amostra. Para tanto, deve-se encontrar a área da curva normal padrão à esquerda da estatística de teste, que fornece o valor p relativo ao teste da cauda inferior no caso em que o  é conhecido. Do exemplo anterior, calcularemos o valor z da estatística de teste para uma média amostral x = 2,92: \\[\\small z =\\frac{\\bar{x} - _0}{/\\sqrt{n}}\\] \\[\\small z = \\frac{2,92 - 3}{0,18/\\sqrt{36}} = -2,67\\] Portanto, o valor p é a probabilidade da estatística de teste z ser menor ou igual a \\(\\small -2,67\\) ( a área sob a curva normal padrão à esquerda da estatística de teste. Usando a tabela de distribuição normal padrão temos que a área entre a média e \\(\\small z = -2,67\\) é \\(\\small 0,4962\\). Assim o p valor: \\[p - value : 0,5 - 0,4962 = 0,0038\\] Tal valor p indica uma pequena probabilidade de se obter uma média amostral de \\(\\small \\bar{x}= 2,92\\) (e uma estatística de teste igual a -2,67) ou menor quando se extrai a amostra de uma população com  = 3. Dado que o diretor definiu a probabilidade máxima de 1% de cometer um erro de tipo I, sabemos que o nível de significância, o  é igual a \\(\\small 0,01\\). Nosso p-value então é menor que nosso alfa, ou seja, a chance de cometermos um erro do tipo I é menor que a chance definida pelo diretor, portanto podemos rejeitar a \\(\\small H_0\\) estando dentro dos parâmetros delimitados pelo estudo. library(tigerstats) pnormGC(bound = 2.92, region = &quot;below&quot;, mean = 3, sd = 0.03, graph = TRUE) ## [1] 0.003830381 Regra de Rejeição quando se usa o p-value: Rejeitar \\(\\small H_0\\) se o valor de p   10.3.1.2 Valor crítico Para um teste de cauda inferior, o valor crítico é o valor da estatística de teste que corresponde a uma área de ( o nível de significância) localizado na cauda inferior da distribuição amostral da estatística de teste. Ou seja, o maior valor da estatística de teste que resultará na rejeição da hipótese nula. No caso do exemplo, temos que o valor crítico é o valor da estatística de teste que corresponde a uma área de \\(= 0,01\\) na cauda inferior da distribuição normal padrão. De acordo com a tabela normal padrão temos que \\(\\small z = -2,33\\) produz uma área igual a \\(\\small 0,01\\) na cauda inferior. Portanto se a amostra resultar em um valor da estatística de teste menor ou igual a \\(\\small -2,33\\), o valor p correspondente será menor ou igual a \\(\\small 0,01\\); nesse caso, deveríamos rejeitar a hipótese nula. A regra de rejeição para este caso então é : Rejeitar a \\(\\small H_0\\) se z  -2,33 No exemplo dado, o z da fábrica de café é de \\(\\small -2,67\\), correspondente à média \\(\\small \\bar{x}\\) de 2,92. Uma vez que \\(\\small -2,67 &lt; -2,33\\) então podemos rejeitar a \\(\\small H_0\\) A regra de rejeição então é : Rejeitar a \\(\\small H_0\\) se z  \\(-z_\\) \\(z_\\) = valor crítico 10.3.1.3 Cauda superior Em um teste de cauda superior o valor p informa a probabilidade de se obter um valor para a estatística de teste que seja tão grande ou maior que aquele que é produzido pela amostra. Para tanto deve se calcular a área sob a curva normal padrão à direita da estatística de teste. O uso do critério do valor crítico, faz com que rejeitemos a hipótese nula se o valor de estatística de teste for maior ou igual ao valor crítico. A regra de rejeição então é : Rejeitar a \\(\\small H_0\\) se z  \\(-z_\\) A área em vermelho pode ser chamada de zona de rejeição ou zona crítica e define um conjunto de valores que chama para rejeitar a hipótese nula. A área compreendida entre os desvios padrão (em branco) é a área que é considerada como DIFERENÇA NÃO SIGNIFICATIVA, e a área fora é considerada DIFERENÇA SIGNIFICATIVA. 10.3.2 Teste Bicaudal A regra para um teste bicaudal é expresso da seguinte maneira: \\[H_0:  =_0\\] \\[H_a:  _0\\] Exemplo de teste bicaudal: A norma uma empresa de equipamentos determina que bolas de golfe atinjam a média de arremesso de 295 jardas. Valores muito abaixo ou muito acima da média não são aceitos. O programa de controle de qualidade testa periodicamente uma amostra de 50 bolas de golfe para monitorar o cumprimento da média de arremesso. Temos portanto as hipóteses: \\[H_0:  =295\\] \\[H_a:  \\neq 295\\] Como a média de 295 jardas é o padrão da fábrica, esperamos que este seja um fato, logo trata-se da hipótese nula, e o estudo busca provar que o padrão não está sendo cumprido, trata-se então da hipótese alternativa. Se a média encontrada na amostra for significamente maior ou menor que a média demonstrada na \\(\\small H_0\\) rejeitaremos a hipótese nula. O nível de significância definido pelo controle de qualidade foi de  = 0,05, e o desvio padrão, de amostras históricas dentro do padrão, mostram que pode-se presumir que o desvio padrão populacional é conhecido tendo o valor de  = 12. Desse modo o desvio padrão de x: \\[\\small \\sigma_{\\bar{x}}= \\frac{\\sigma}{\\sqrt{n}}\\] \\[\\small \\sigma_{\\bar{x}}= \\frac{12}{\\sqrt{50}}=1,7\\] Dado que na amostra de 50 elementos foi encontrada uma média (\\(\\small \\bar{x}\\)) de 297,6 seria esta amostra grande demais para  Tal pergunta pode ser respondida pelo critério do p-value ou pelo valor crítico. 10.3.2.1 Valor p O valor p, p-value ou nível observado de significância, é uma probabilidade calculada usando-se a estatística de teste, que mede o apoio ( ou a falta de apoio) proporcionado pela amostra a hipótese nula. O valor p varia de 0 a 1. Quanto mais próximo a 1, mais suporte a estatística de teste da a hipótese nula (\\(\\small H_0\\)). Valores p grandes levam a não rejeição da hipótese nula Quanto mais próximo a 0, menos suporte a estatística de teste da a hipótese nula (\\(\\small H_0\\)). O que é incomum dada a suposição de uma \\(\\small H_0\\) verdadeira, logo levam a rejeição da hipótese nula (\\(\\small H_0\\)) Em um teste bicaudal, o valor p é a probabilidade de se obter um valor para a estatística de teste tão ou mais improvável do que aquele que é fornecido pela amostra. A estatística de teste para a média fornecida pela amostra é : \\[z = \\frac{\\bar{x} - _0}{/\\sqrt{n}}\\] \\[z = \\frac{297,6 - 295}{12/\\sqrt{50}} = 1,53\\] Agora, busca-se a probabilidade de se obter um valor para a estatística de teste, que seja, no mínimo tão improvável quanto z = 1,53. E por se tratar de um teste bicaudal, também é tratada a hipótese de \\(\\small z = -1,53\\) ser um valor tão improvável quanto a estatística de teste fornecida pela amostra. O valor p bicaudal para este caso, é dado por \\(\\small P( z  -1,53) + P( z  1,53)\\). Visto que a curva é simétrica, podemos encontrar somente a probabilidade da área sob a curva a direita da média e a duplicando. A tabela da distribuição normal padrão mostra que a área sob a curva entre a média e \\(\\small z = 1,53\\) é \\(\\small 0,4370\\). Portanto, a área sob a curva normal à direita da estatística de teste \\(\\small z = 1,53\\) é: \\[\\small p - value \\textrm{(1 lado)} : 0,5 - 0,4370 = 0,0630\\] \\[\\small p - value \\textrm{(bicaudal)} : 0.0630 × 2 = 0,1260\\] Agora, comparando o valor p com o nível de significância, a fim de verificar se a hipótese nula deve ser rejeitada, verificamos que: \\[\\small  = 0,05\\] \\[\\small p-value: 0,1260\\] \\[\\small  (0,05) &lt; p-value (0,1260)\\] Portanto, a hipótese nula não deve ser rejeitada, pois a probabilidade de uma população de média 295 produzir uma amostra com média igual ou maior a 297,6 (ou igual ou menor que 292,4 )é de 12,6%. Tal probabilidade é maior que a probabilidade admissível de se cometer um erro do Tipo I, que trata de afirmar que com 95% de certeza que uma população de média 295 não poderia produzir uma amostra de média 297,6. df&lt;- read.csv(&quot;data/Golf.csv&quot;,sep=&quot;,&quot;) ttestGC(~Yards, data=df,mu=295,sd=12, alternative=&quot;two.sided&quot;,conf.level = 0.95,graph=TRUE) ## ## ## Inferential Procedures for One Mean mu: ## ## ## Descriptive Results: ## ## variable mean sd n ## Yards 297.600 11.297 50 ## ## ## Inferential Results: ## ## Estimate of mu: 297.6 ## SE(x.bar): 1.598 ## ## 95% Confidence Interval for mu: ## ## lower.bound upper.bound ## 294.389297 300.810703 ## ## Test of Significance: ## ## H_0: mu = 295 ## H_a: mu != 295 ## ## Test Statistic: t = 1.627 ## Degrees of Freedom: 49 ## P-value: P = 0.1101 10.3.2.2 Valor crítico Para um teste bicaudal, o valor crítico é o valor da estatística de teste que corresponde a uma área de ( o nível de significância) localizado na cauda inferior e superior da distribuição amostral da estatística de teste. Ou seja, se o valor da estatística de teste ultrapassar os limites dos valores críticos a hipótese nula será rejeitada. No caso do exemplo, temos que o valor crítico é o valor da estatística de teste que corresponde a uma área total de = 0,05, a qual corresponde a uma área de 0,025 ambas as caudas da distribuição normal padrão. pnormGC(c(-1.96,1.96),mean=0,sd=1,region =&quot;outside&quot;, graph=TRUE) ## [1] 0.04999579 De acordo com a tabela normal padrão um z = 1,96 produz uma área de 0,025 em ambas as caudas. Portanto se a amostra resultar em um valor da estatística de teste menor ou igual a -1,96 ou 1,96, o valor p correspondente será menor ou igual a 0,025; nesse caso, deveríamos rejeitar a hipótese nula. A regra de rejeição para este caso então é : Rejeitar a \\(\\small H_0\\) se z  -1,96 ou se z  1,96 No exemplo dado, o z da amostra dos lançamentos da bola de golfe é de 1,53, correspondente à média x de 296,6. Uma vez que 1,53 &lt; 1,96 então não podemos rejeitar a \\(\\small H_0\\) A regra de rejeição então é : Rejeitar a \\(\\small H_0\\) se z  \\(\\small -z_\\) ou se z  \\(-z_\\) \\(\\small -z_\\) = valor crítico 10.3.2.3 Testar a partir do intervalo de confiança A regra para um teste bicaudal é expresso da seguinte maneira: \\[\\small H_0:  =_0\\] \\[\\small H_a:  \\neq _0\\] Para desenvolver o intervalo de confiança: Selecione uma amostra e use o valor da média amostral para desenvolver o intervalo de confiança da média populacional \\(\\small \\bar{x} ± z_{\\frac{}{2}}\\frac{\\sigma}{\\sqrt{n}}\\) \\(\\small( 1 - )\\) = coeficiente de confiança \\(\\small \\) = Nível de significância \\(\\small z_{\\frac{}{2}}\\) = é o valor de z que produz uma área de /2 na cauda superior da distribuição normal padrão de probabilidade \\(\\small z_{\\frac{}{2}}\\) = Semi amplitude Se o intervalo de confiança contiver o valor hipotético \\(\\small _0\\) não rejeite \\(\\small H_0\\). Caso contrário, rejeite \\(\\small H_0\\) No exemplo das bolas de golfe teríamos: \\[\\small \\bar{x} ± z_{\\frac{}{2}}\\frac{\\sigma}{\\sqrt{n}}\\] \\[\\small 297,6 ± 1,96\\frac{12}{50}\\] \\[\\small 297,6 ± 3,3\\] \\[\\small 294,3    300,9\\] Portanto, podemos afirmar com 95% de confiança que a distância média atingida pela população das bolas de golfe está entre 294,3 e 300,9 jardas. Como o valor hipotético da média populacional \\(\\small _0: = 295\\) está contido dentro do intervalo, a conclusão do teste de hipóteses é que a hipótese nula, \\(\\small _0: = 295\\), não pode ser rejeitada. 10.3.3 Resumo Teste de Cauda Inferior Teste de Cauda Superior Teste Bicaudal Hipótese \\(\\small H_0:\\mu \\geq \\mu_0\\) \\(\\small H_a:\\mu &lt; \\mu_0\\) \\(\\small H_0:\\mu \\leq \\mu_0\\) \\(\\small H_a:\\mu &gt; \\mu_0\\) \\(\\small H_0:\\mu = \\mu_0\\) \\(\\small H_a:\\mu \\neq \\mu_0\\) Estatística de Teste \\(\\small z=\\frac{\\bar{x}-\\mu_0}{\\sigma/ \\sqrt{n}}\\) \\(\\small z=\\frac{\\bar{x}-\\mu_0}{\\sigma/ \\sqrt{n}}\\) \\(\\small z=\\frac{\\bar{x}-\\mu_0}{\\sigma/ \\sqrt{n}}\\) Regra de Rejeição: Critério do Valor p Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Regra de Rejeição: Critério do Valor Crítico Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\leq -z_\\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\geq z_\\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\leq -z_{\\alpha/2}\\) ou se \\(\\small z \\geq z_{\\alpha/2}\\) P - value Conclusão Menor que 0,01 Esmagadora evidência que \\(\\small H_a\\) é verdadeira Entre 0,01 e 0,05 Forte evidência que \\(\\small H_0\\) é verdadeira Entre 0,01 e 0,05 Fraca evidência que \\(\\small H_a\\) é verdadeira Maior que 0,01 Insuficiente evidência que \\(\\small H_a\\) é verdadeira Só podemos rejeitar ou não rejeitar a hipótese nula, nunca aceitar. 10.4 Média da população: Desvio Padrão () desconhecido Testes a respeito da média acerca uma população normalmente distribuída, ou grande o suficiente Teorema do Limite Central com desvio padrão desconhecido. O desvio padrão desconhecido corresponde a uma situação em que não se pode desenvolver uma estimativa de desvio padrão populacional antes de se fazer uma amostragem, a amostra deve ser utilizada para desenvolver uma estimativa de , tanto quanto de . Assim a média amostral \\(\\small \\bar{x}\\) será a estimativa de populacional e o desvio padrão da amostra scomo estimativa de . Diferente do caso de uma população normalmente distribuída e com desvio padrão conhecido, um teste com uma população com desvio padrão desconhecido tem uma variabilidade ligeiramente maior porque a amostra é usada para desenvolver estimativas tanto de  como de  e é baseado na distribuição probabilística chamada distribuição T, onde para o caso de o desconhecido se trata de uma estatística de teste com n-1 graus de liberdade. 10.4.1 Teste Unicaudal A fórmula da estatística de teste para teste de hipótese a respeito de uma média populacional de  desconhecido: \\[\\small t = \\frac{\\bar{x} - _0}{s/ \\sqrt{n}}\\] Exemplo: Numa avaliação de atendimento de aeroporto, onde a nota varia de 0 a 10, uma nota 7 é considerada um atendimento de alto nível. Numa pesquisa foram coletadas 60 avaliações de aeroportos e a média encontrada num certo aeroporto foi de \\(\\small \\bar{x}\\) = 7,25 e um desvio padrão s = 1,052. Um teste de hipóteses deve ser desenvolvido , onde se testa a hipótese da média populacional da avaliação do aeroporto em questão ser maior que 7. \\[\\small H_0:   7\\] \\[\\small H_a:  &gt; 7\\] No teste será usado o nível de significância  = 0,05. 10.4.1.1 Valor p \\[\\small t = \\frac{\\bar{x} - _0}{s/ \\sqrt{n}}\\] \\[\\small t = \\frac{7,25 - 7}{1,052/ \\sqrt{60}}=1,84\\] A distribuição amostral de T tem: \\[\\small \\textrm{n - 1 = graus de liberdade}\\] \\[\\small \\textrm{60 - 1 = 59 graus de liberdade}\\] Uma significância de 0,05 com 59 graus de liberdade numa distribuição t: Área da cauda superior 0,20 0,10 0,05 0,025 0,01 0,005 Valor t ( 59 graus de liberdade ) 0,848 1,296 1,671 2,001 2,391 2,662 O t = 1,84 está entre 1,671 e 2,001. Isso significa que o p-value está entre 0,05 e 0,025 , o que, dado que o nível de significância é 0,05 podemos concluir que a hipótese nula deve ser rejeitada e portanto o aeroporto em questão deve ser considerado de alto nível, nota maior que 7. Regra de Rejeição quando se usa o p-value: Rejeitar \\(\\small H_0\\) se o valor de p   0,035  0,05  Rejeita a \\(\\small H_0\\) 10.4.1.2 Valor Crítico Considerando um  = 0,05 e uma distribuição t com 59 graus de liberdade, temos um \\(\\small t_{0,05} = 1,671\\) é o valor crítico de teste. A regra de rejeição neste caso é: Regra de rejeição : Rejeitar a \\(\\small H_0\\) se \\(\\small t  z_\\) 1,84  1,671  Portanto, rejeitar a \\(\\small H_0\\) 10.4.2 Teste Bicaudal A fórmula da estatística de teste para teste de hipótese a respeito de uma média populacional de  desconhecido: \\[\\small t = \\frac{\\bar{x} - _0}{s/ \\sqrt{n}}\\] Exemplo: Uma certa empresa de manufatura tem mais de mil pontos de revenda e precisa planejar seu nível de produção para a próxima estação, para tanto, precisa planejar a quantidade de produção de cada brinquedo, antes de se conhecer a real demanda do mercado. Para um novo brinquedo o diretor de marketing planeja a venda de 40 unidades por ponto de revenda. Antes de tomar a decisão final a empresa decidiu pesquisar uma amostra de 25 varejistas a fim de desenvolver mais informações acerca da demanda do novo produto. Aos varejistas foram fornecidas as características e preço do novo brinquedo e solicitada uma quantidade prevista de compra. Considerando que  denota a média dos lotes de compra da população por ponto de revenda, os dados serão usados para realizar o seguinte teste bicaudal: \\[\\small H_0:  = 40\\] \\[\\small H_a:   40\\] Se \\(\\small H_0\\) não puder ser rejeitada, a empresa continuará com os planos de produção, baseado na estimativa feita pelo diretor de marketing. Entretanto, se \\(\\small H_0\\) for rejeitada, a empresa reavaliará os planos de produção. O teste bicaudal poderá informar se a média de compra é maior ou menor que a prevista. Como se trata de um novo produto, a média e desvio padrão populacionais serão estimados com base na média (\\(\\small \\bar{x}\\)) e desvio padrão () amostrais. A amostra de 25 elementos produziu uma média de \\(\\small \\bar{x} = 37,5\\) e desvio padrão \\(\\small =11,79\\). Um histograma foi montado a fim de observar o formato da distribuição e nenhum ponto de assimetria ou pontos fora da curva foram observados, portanto, foi adotado (n - 1) = (25 - 1) graus de liberdade. Temos portanto que t : 10.4.2.1 Valor p \\[\\small t = \\frac{\\bar{x} - _0}{s/ \\sqrt{n}}\\] \\[t = \\frac{37,4 - 40}{11,79/ \\sqrt{25} }= -1,10\\] O p-value, por se tratar de um teste bicaudal, deve ser calculado multiplicando por 2 o valor encontrado na tabela, no caso: Área da cauda superior 0,20 0,10 0,05 0,025 0,01 0,005 Valor t ( 24 graus de liberdade ) 0,857 1,318 1,711 2,064 2,492 2,797 O t = 1,10 está entre 0,857 e 1,318. Isso significa que o p-value está entre 0,20 e 0,10 e dado que se trata de um teste bicaudal, devemos multiplicar o valor de p por dois, logo temos que o p-value está entre 0,40 e 0,20 o que, dado que o nível de significância é 0,05 podemos concluir que a hipótese nula não deve ser rejeitada e portanto a previsão realizada deve ser mantida, já que não há evidências suficientes que a previsão deva ser alterada. 10.4.2.2 Valor crítico O valor crítico também pode ser utilizado para avaliar a hipótese, no caso, teríamos, com um  = 0,05e 24 graus de liberdade um de \\(\\small -t_{0,025} = -2,064\\) e \\(\\small t_{0,025} = 2,064\\) como valores críticos para o teste bicaudal. Portanto: Regra de rejeição : Rejeitar a \\(\\small H_0\\) se \\(\\small t  -z_\\) ou se \\(\\small t  z_\\) t  -2,064 ou se t  2,064 Com base no valor de t = -1,10 podemos concluir que a hipótese nula não deve ser rejeitada e a empresa deve manter os planos originais de produção baseados em  = 40. 10.4.3 Resumo Teste de Cauda Inferior Teste de Cauda Superior Teste Bicaudal Hipótese \\(\\small H_0:\\mu \\geq \\mu_0\\) \\(\\small H_a:\\mu &lt; \\mu_0\\) \\(\\small H_0:\\mu \\leq \\mu_0\\) \\(\\small H_a:\\mu &gt; \\mu_0\\) \\(\\small H_0:\\mu = \\mu_0\\) \\(\\small H_a:\\mu \\neq \\mu_0\\) Estatística de Teste \\(\\small t=\\frac{\\bar{x}-\\mu_0}{\\sigma/ \\sqrt{n}}\\) \\(\\small t=\\frac{\\bar{x}-\\mu_0}{\\sigma/ \\sqrt{n}}\\) \\(\\small t=\\frac{\\bar{x}-\\mu_0}{\\sigma/ \\sqrt{n}}\\) Regra de Rejeição: Critério do Valor p Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Regra de Rejeição: Critério do Valor Crítico Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\leq -z_\\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\geq z_\\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\leq -z_{\\alpha/2}\\) ou se \\(\\small z \\geq z_{\\alpha/2}\\) 10.5 Proporção da população Para realizar um teste de hipótese a respeito de uma proporção populacional utilizaremos p0para denotar o valor hipotético da proporção populacional. De forma semelhante ao teste de hipótese da média, são três os possíveis testes a serem realizados a respeito de uma proporção populacional: Teste de Cauda Inferior Teste de Cauda Superior Teste Bicaudal \\(\\small H_0: p  p_0\\) \\(\\small H_0: p  p_0\\) \\(\\small H_0: p  p_0\\) \\(\\small H_a: p &lt; p_0\\) \\(\\small H_a: p &gt; p_0\\) \\(\\small H_a: p &gt; p_0\\) Os testes de hipótese a respeito de uma proporção populacional se baseiam na diferença entre a proporção amostral \\(\\small \\bar{p}\\) e a proporção populacional \\(\\small p_0\\) hipotética. Os métodos utilizados para realizar o teste de hipóteses são semelhantes ao método utilizado no teste da média populacional, com a diferença do uso do erro padrão para o cálculo da estatística de teste. Exemplo - teste de cauda superior Numa empresa que oferece curso de golfe, encontra-se a proporção de 20% de mulheres. A fim de aumentar esse número, uma promoção foi lançada, e agora, um mês após o lançamento deseja-se saber que a proporção de mulheres aumentou, temos portanto as hipóteses: \\[\\small H_0: p  0,20\\] \\[\\small H_a: p &gt; 0,20\\] Na execução desse teste de hipóteses deve ser usado o nível de significância  = 0,05. A rejeição da hipótese nula significa que a existe suporte estatístico a hipótese que a promoção aumentou o número de mulheres no curso de golfe. Quando a hipótese nula é verdadeira enquanto igualdade, o valor esperado de \\(\\small \\bar{p}\\) equivale ao valor de hipotético de \\(\\small p_0\\); ou seja, \\(\\small E(\\bar{p}) = p_0\\). O erro padrão de p é dado por: \\[\\small _{\\bar{p}}=\\sqrt{\\frac{p_0(1 - p_0)}{n}}\\] Se \\(\\small np  5 \\textrm{ e } n ( 1 - p) 5\\) a distribuição amostral de p pode ser aproximada a uma distribuição normal. \\[\\small z = \\frac{\\bar{p} - p_0}{_{\\bar{p}}}\\] Sendo: \\[\\small _{\\bar{p}}=\\sqrt{\\frac{p_0 ( 1 - p_0)}{n}}\\] Portanto, temos que z: \\[\\small z = \\frac{p - p_0}{\\sqrt{\\frac{p_0 ( 1 - p_0)}{n}}}\\] No caso exemplificado, consideremos uma amostra de n = 400 , onde 100 jogadores sejam mulheres. Temos então: \\[\\small \\bar{p}=\\frac{100}{400} = 0,25\\] Usando a equação acima temos que z: \\[\\small z = \\frac{p - p_0}{\\sqrt{\\frac{p_0 ( 1 - p_0)}{n}}}\\] \\[\\small z = \\frac{0,25 - 0,20}{\\sqrt{\\frac{0,20 ( 1 - 0,20)}{400}}}\\] \\[\\small z = \\frac{0,05}{0,02} = 2,50\\] 10.5.1 Valor p O p-value correspondente a z = 2,50 é 0,0062. Logo: Regra de Rejeição quando se usa o p-value: Rejeitar \\(\\small H_0\\) se o valor de p   0,0062  0,05  Rejeita a \\(\\small H_0\\) Portanto, a promoção aumentou o número de mulheres no curso de golfe. 10.5.2 Valor crítico O valor crítico correspondente a uma área de 0,05 na cauda superior de uma distribuição normal padrão é \\(\\small z_{0,05}= 1,645\\). Regra de rejeição : Rejeitar a \\(\\small H_0\\) se t  z 2,5  1,645  Portanto, rejeitar a \\(\\small H_0\\) 10.5.3 Resumo O procedimento para realizar um teste de hipóteses a respeito de uma proporção populacional é o mesmo que o utilizado para testar uma média populacional. A única mudança é o termo utilizado para se referir a proporção populacional ao invés de se referir a média populacional. Teste de Cauda Inferior Teste de Cauda Superior Teste Bicaudal Hipótese \\(\\small H_0:\\mu \\geq \\mu_0\\) \\(\\small H_a:\\mu &lt; \\mu_0\\) \\(\\small H_0:\\mu \\leq \\mu_0\\) \\(\\small H_a:\\mu &gt; \\mu_0\\) \\(\\small H_0:\\mu = \\mu_0\\) \\(\\small H_a:\\mu \\neq \\mu_0\\) Estatística de Teste \\(\\small z = \\frac{p - p_0}{\\sqrt{\\frac{p_0 ( 1 - p_0)}{n}}}\\) \\(\\small z = \\frac{p - p_0}{\\sqrt{\\frac{p_0 ( 1 - p_0)}{n}}}\\) \\(\\small z = \\frac{p - p_0}{\\sqrt{\\frac{p_0 ( 1 - p_0)}{n}}}\\) Regra de Rejeição: Critério do Valor p Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Regra de Rejeição: Critério do Valor Crítico Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\leq -z_\\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\geq z_\\alpha\\) Rejeitar \\(\\small H_0\\) se o valor de \\(\\small z \\leq -z_{\\alpha/2}\\) ou se \\(\\small z \\geq z_{\\alpha/2}\\) 10.6 Inferência acerca da diferença entre médias A inferência a respeito da diferença entre médias é útil para desenvolver uma estimação por intervalo da diferença da média dos salários iniciais de homens e mulheres ou testar se a média de horas entre a ocorrência de panes é o mesmo para quatro máquinas diferentes. Para tanto, devemos desenvolver estimação por intervalo e realizar testes de hipóteses a respeito da diferença entre duas médias populacionais. 10.6.1 Desvio padrão conhecido Admitindo que \\(\\small _1\\) denota a média da população 1 e \\(\\small _2\\) a média da população 2, uma amostra de \\(\\small n_1\\) unidades deve ser coletada na população 1 e uma amostra de \\(\\small n_2\\) unidades deve ser coletada na população 2. As duas amostras aleatórias simples, tomadas de maneira separada e independente, são chamadas de amostras aleatórias simples independentes. Consideremos que antes da realização das coletas de amostra os desvios padrão de ambas as populações são conhecidos, como \\(_1\\) e \\(_2\\) . Exemplo: Uma empresa possui duas lojas numa mesma cidade, uma localizada no centro da cidade e outro num shopping na periferia. O gerente regional notou que os produtos que tem uma boa vendagem numa loja nem sempre vendem bem na outra. O gerente acredita que tal diferença seja devido a diferença entre os aspectos demográficos entre os clientes das duas localidades e solicitou uma investigação na diferença entre as médias de idade entre os clientes que compram nas duas lojas. Consideremos como população 1 os clientes da loja do centro e população 2 os clientes da loja do shopping: \\(\\small _1\\) : média da população 1 (média da idade dos clientes da loja do centro) \\(\\small _2\\) : média da população 2 (média da idade dos clientes da loja do shopping) A diferença entre as médias das populações é dado por: \\(\\small _1- _2\\) Para estimar \\(\\small _1- _2\\) , selecionamos uma amostra aleatória simples de \\(\\small n_1\\) clientes da população 1 e uma amostra de \\(\\small n_2\\) clientes da população 2 . Então calculamos as duas médias amostrais: \\(\\small \\bar{x_1}\\): média amostral da idade de uma amostra aleatória simples de \\(\\small n_1\\) clientes da loja do centro \\(\\small \\bar{x_2}\\): média amostral da idade de uma amostra aleatória simples de \\(\\small n_2\\) clientes da loja do centro O estimador por ponto da diferença entre as médias amostrais das duas populações é a diferença entre as duas médias amostrais. \\[\\small \\bar{x_1} - \\bar{x_2}\\] À semelhança do que ocorre com outros estimadores por ponto, o estimador por ponto de \\(\\small \\bar{x_1}- \\bar{x_2}\\) tem um erro padrão que descreve a variação da distribuição amostral do estimador. Com duas amostras aleatórias independentes, o erro padrão de \\(\\small \\bar{x_1}- \\bar{x_2}\\) é o seguinte: \\[\\small _{\\bar{x}_1- \\bar{x}_2}= \\sqrt{\\frac{_1^2}{n_1} + \\frac{_2^2}{n_2}} \\] Se ambas as populações tiverem uma distribuição normal, ou se os tamanhos de amostra forem suficientemente grandes a ponto de o teorema do limite central nos permitir concluir que as distribuições amostrais de \\(\\small \\bar{x}_1\\) e de \\(\\small \\bar{x}_2\\) possam ser aproximadas a uma distribuição normal, a distribuição de \\(\\small \\bar{x}_1 - \\bar{x}_2\\) terá uma distribuição normal com uma média dada por \\(\\small _1- _2\\). Uma estimação por intervalo é dado por uma estimação por ponto ± uma margem de erro. No caso da estimação da diferença entre duas médias populacionais uma estimação por intervalo irá assumir a seguinte forma: \\[\\small \\bar{x}_1 - \\bar{x}_2 ± \\textrm{Margem de erro}\\] Com a distribuição amostral de \\(\\small \\bar{x_1} - \\bar{x_2}\\) tendo uma distribuição normal, podemos escrever a margem de erro da seguinte forma: \\[\\small \\textrm{Margem de erro} = z_{/2} _{\\bar{x}_1- \\bar{x}_2} =z_{/2} \\sqrt{\\frac{_1^2}{n_1} +\\frac{_2^2}{n_2}}\\] Por fim, a estimação por intervalo da diferença entre as duas médias populacionais é dada por: \\[\\small \\bar{x}_1- \\bar{x}_2 ± z_{/2} \\sqrt{\\frac{_1^2}{n_1} +\\frac{_2^2}{n_2}}\\] No exemplo dado temos a seguinte resultado das coletas: Loja do Centro Loja do Shopping Tamanho da Amostra \\(\\small n_1=36\\) \\(\\small n_2=49\\) Média Amostral \\(\\small \\bar{x}_1= \\textrm{40 anos}\\) \\(\\small \\bar{x}_2 = \\textrm{35 anos}\\) Desvio Padrão Populacional \\(\\small _1= \\textrm{9 anos}\\) \\(\\small _2= \\textrm{10 anos }\\) A estimação por ponto da diferença entre a média de idade das duas populações é dado por: \\[\\small \\bar{x}_1- \\bar{x}_2\\] \\[\\small 40 - 35 = \\textrm{5 anos}\\] Portanto, os clientes da loja do centro tem uma média de idade de 5 anos maior que a média de idade dos clientes da loja da periferia. Agora, para calcular a margem de erro e a estimação por intervalo com 95% de confiança iremos: \\[\\small z_{/2} = z_{0,025} = 1,96\\] \\[\\small \\bar{x}_1- \\bar{x}_2 ± z_{/2} \\sqrt{\\frac{_1^2}{n_1} + \\frac{_2^2}{n2}}\\] \\[\\small 40 - 35 ± 1,96 \\sqrt{\\frac{9^2}{36} + \\frac{10^2}{49}}\\] \\[\\small 5 ± 4,06\\] \\[\\small 0,94  _1- _2  9,06\\] Portanto, a margem de erro é de 4,06 anos e a estimação por intervalo de confiança de 95% entre as duas médias populacionais é de 0,94 anos a 9,06 anos. 10.6.1.1 Teste de Hipóteses sobre a diferença entre médias \\(\\small _1- _2\\) Consideremos os testes de hipóteses sobre a diferença entre as médias de duas populações. Usando \\(\\small D_0\\) para denotar as diferenças hipotéticas entre \\(\\small _1- _2\\), as três formas de um teste de hipóteses são as seguintes: Teste de Cauda Inferior Teste de Cauda Superior Teste Bicaudal \\(\\small H_0: _1- _2  D_0\\) \\(\\small H_0: _1- _2  D_0\\) \\(\\small H_0: _1- _2  D_0\\) \\(\\small H_a: _1- _2 &lt; D_0\\) \\(\\small H_a: _1- _2 &gt; D_0\\) \\(\\small H_a: _1- _2 &gt; D_0\\) Os passos para a realização do teste de hipótese são os mesmos utilizados em outras aplicações: Escolhe-se um nível de significância Calcula-se o valor da estatística de teste Encontra-se o valor p A partir do valor p determina-se se a hipótese deve ser rejeitada Com duas amostras aleatórias simples independentes, mostramos que o estimador por ponto \\(\\small \\bar{x}_1- \\bar{x}_2\\) tem erro padrão \\(\\small _{\\bar{x}_1- \\bar{x}_2}\\) e que a distribuição de \\(\\small \\bar{x}_1- \\bar{x}_2\\) pode ser descrita por uma distribuição normal. Nesse caso, a estatística de teste da diferença entre as duas médias populacionais quando \\(\\small _1\\) e \\(\\small _2\\) são conhecidos é a seguinte: \\[\\small z = \\frac{( \\bar{x}_1- \\bar{x}_2 ) - D_0}{\\sqrt{\\frac{_1^2}{n_1} +\\frac{_2^2}{n_2}}}\\] Exemplo: Como parte de um estudo para avaliar as diferenças na qualidade educacional entre dois centros de ensino, um exame padronizado é aplicado a pessoas que estudam nesses centros. A diferença entre a média das notas obtidas no exame é usada para avaliar as diferenças de qualidade entre os centros. As médias populacionais correspondentes aos dois centros são as seguintes: \\(\\small _1\\): média da população 1 (média das notas dos estudantes que estudam no centro de ensino A) \\(\\small _2\\): média da população 2 (média das notas dos estudantes que estudam no centro de ensino B) A diferença entre as médias das populações é dado por: \\(\\small _1- _2\\) . Iniciamos com a hipótese experimental de que não existe diferença entre a qualidade de ensino oferecida entre os dois centros. Temos então as hipóteses: \\[\\small H_0: _1- _2 = 0\\] \\[\\small H_a: _1- _2  0\\] O exame padronizado, aplicado anteriormente em outros centros educacionais, sempre resultou em um desvio padrão de notas próximo a 10 pontos. Usaremos então essa informação para supor que os desvio padrão populacionais sejam conhecidos, sendo \\(\\small _1= 10\\) e \\(\\small _2= 10\\), um nível de significância de  = 0,05 é especificado para o estudo. Para estimar \\(\\small _1- _2\\) , selecionamos uma amostra aleatória simples de \\(\\small n_1 = 30\\) estudantes da população 1 e uma amostra de \\(\\small n_2 = 40\\) estudantes da população 2 . Então calculamos as duas médias amostrais: \\(\\small \\bar{x}_1\\): média amostral da idade de uma amostra aleatória simples de \\(\\small n_1\\) clientes da loja do centro) \\(\\small \\bar{x}_2\\): média amostral da idade de uma amostra aleatória simples de \\(\\small n_2\\) clientes da loja do centro) As médias encontradas foram: \\(\\small \\bar{x}_1: 82\\) \\(\\small \\bar{x}_2: 78\\) A questão é: Os dados sugerem uma diferença significativa entre as médias das notas dos dois centros educacionais? A estatística de teste nos ajuda a responder essa questão: \\[\\small z = \\frac{( \\bar{x}_1 - \\bar{x}_2 ) - D_0}{\\sqrt{\\frac{_1^2}{n_1} +\\frac{_2^2}{n_2}}}\\] \\[\\small z = \\frac{(82 - 78) - 0} {\\sqrt{\\frac{10^2}{30} +\\frac{10^2}{40}}} = 1,66\\] 10.6.1.1.1 Valor p O valor p para um teste bicaudal é 0,0970. Seguindo a regra de rejeição: Regra de Rejeição quando se usa o p-value: Rejeitar \\(\\small H_0\\) se o valor de p   0,0970 &gt; 0,05  Não rejeita a \\(\\small H_0\\) Portanto, os dados amostrais não nos fornecem evidências suficientes para concluirmos que os centros de ensino diferem em termos de qualidade. 10.6.1.1.2 Valor crítico Considerando  = 0,05 e \\(\\small z_{/2}=z_{0,025} = 1,96\\) Regra de rejeição : Rejeitar a \\(\\small H_0\\) se \\(\\small t  -z_\\) ou se \\(\\small t  z_\\) z  -1,96 ou se z  1,96 No caso, z = 1,66 portanto, a hipótese nula não pode ser rejeitada. 10.6.2 Desvio padrão desconhecido No caso em que os desvio padrão das populações \\(\\small _1\\) e \\(\\small _2\\) forem desconhecidos, os desvio padrão da amostra \\(\\small s_1\\) e \\(\\small s_2\\) devem ser utilizados para estimar os desvio padrão desconhecidos. Devido a isso, os procedimentos de estimação por intervalo e de teste de hipóteses vão se basear na distribuição t em vez da distribuição normal padrão. Exemplo: Um banco deseja analisar as diferenças entre as utilizações de conta entre os clientes de duas de suas filiais. Uma amostra de 28 contas é selecionada de cada uma das filiais, sendo coletado o saldo atual dos cliente. O resultado foram o seguintes: Filial A Filial B Tamanho da Amostra \\(\\small n_1=28\\) \\(\\small n_2=22\\) Média Amostral \\(\\small \\bar{x}_1= \\textrm{US} \\$ 1.025\\) \\(\\small \\bar{x}_1=US\\$ 910\\) Desvio Padrão da Amostra \\(\\small s_1= US\\$ 150\\) \\(\\small s_2= US\\$ 125\\) O banco deseja estimar a diferença entre a média do saldo das contas mantidas pelos clientes das filiais A e B. Para tanto vamos desenvolver a margem de erro e uma estimação por intervalo da diferença entre essas duas médias populacionais. \\[\\small \\bar{x}_1- \\bar{x}_2 ± z_{/2} \\sqrt{\\frac{_1^2}{n_1} +\\frac{_2^2}{n_2}}\\] Como o desvio padrão é desconhecido ( \\(\\small _1\\) e \\(\\small _1\\)), usaremos os desvio padrão amostrais (\\(\\small s_1\\) e \\(\\small s_1\\)), para estimar os desvio padrão e substituiremos \\(\\small z_{/2}\\) por \\(\\small t_{/2}\\), portanto, a fórmula para estimação por intervalo da diferença entre duas médias populacionais é dada pela seguinte expressão: \\[\\small \\bar{x}_1- \\bar{x}_2 ± t_{/2} \\sqrt{\\frac{s_1^2}{n_1} +\\frac{s_2^2}{n_2}}\\] Os graus de liberdade são calculados pela fórmula abaixo: \\[\\small gl = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2} {\\frac{1}{n_1 -1}(\\frac{s_1^2}{n_1})^2 + \\frac{1}{n_2 -1}(\\frac{s_2^2}{n_2})^2}\\] \\[\\small gl = \\frac{(\\frac{150^2}{28} + \\frac{125^2}{22})^2} {\\frac{1}{28 -1}(\\frac{150^2}{28})^2 + \\frac{1}{22 -1}(\\frac{125^2}{22})^2 }=47,8\\] Arredondamos para 47 os graus de liberdade, assim teremos um valor t ligeiramente maior e uma estimação por intervalo mais conservadora. Para 47 graus de liberdade temos \\(\\small t_{0,025}=2,012\\). Usando a equação para se desenvolver um intervalo de confiança de 95% temos: \\[\\small \\bar{x}_1- \\bar{x}_2± t_{/2} \\sqrt{\\frac{s_1^2}{n_1} +\\frac{s_2^2}{n_2}}\\] \\[\\small 1025 - 910± 2,012 \\sqrt{\\frac{150^2}{28} +\\frac{125^2}{22}}\\] \\[\\small 115± 78\\] \\[\\small 37 _1-_2  193\\] Portanto, a estimação por ponto da diferença entre a média populacional dos saldos de conta corrente nas duas filiais é de US$ 115. A margem de erro é de US$ 78 e a estimação por intervalo de confiança de 95% da diferença entre as médias populacionais é US$37 a US$193. 10.6.2.1 Teste de hipóteses sobre a diferença entre médias Admitindo \\(\\small D_0\\) como a diferença hipotética entre \\(\\small _1\\) e \\(\\small _2\\) e equação para determinar a estatística de teste é a seguinte: \\[\\small t = \\frac{( \\bar{x}_1- \\bar{x}_2 ) - D_0}{\\sqrt{\\frac{s_1^2}{n_1} +\\frac{s_2^2}{n_2}}}\\] Exemplo: Considere um novo pacote de software desenvolvido a fim de agilizar o processo de desenvolvimento de software. Para analisar se o novo pacote realmente agiliza o desenvolvimento de software 24 desenvolvedores foram selecionados, onde 12 deverão usar o novo pacote e 12 continuar utilizando as tecnologias atuais. Um treinamento é realizado com os desenvolvedores que devem utilizar o novo pacote e uma especificação de software é entregue para que ambos os grupos desenvolvam. Temos portanto duas populações: uma que se utiliza do novo pacote de software e outro que se utiliza das tecnologias atuais. As médias populacionais são as seguintes \\(\\small _1\\): tempo médio de conclusão do projeto para os desenvolvedores que usam tecnologia atual \\(\\small _2\\): tempo médio de conclusão do projeto para os desenvolvedores que usam o novo pacote de desenvolvimento A diferença entre as médias das populações é dado por: \\(\\small _1- _2\\) . Iniciamos com a hipótese experimental de que o novo pacote de software apresentará uma média de tempo menor para o desenvolvimento do software centros, ou seja, evidência de que \\(\\small _2\\) é menor que \\(\\small _1\\). Temos então as hipóteses: \\[\\small H_0: _1- _2  0\\] \\[\\small H_a: _1- _2&gt; 0\\] O nível de significância será  = 0,05. Os dados coletados são os seguintes: Atual Novo pacote 300 274 280 220 344 308 385 336 372 198 360 300 288 315 321 258 376 318 290 310 301 332 283 263 Sumário Estatístico Amostras Tamanho da amostra Média amostral Desvio Padrão da Amostra Amostra 1 \\(\\small n_1=12\\) \\(\\small x_1= 325\\) \\(\\small s_1=40\\) Amostra 2 \\(\\small n_2=12\\) \\(\\small x_2= 286\\) \\(\\small s_2=44\\) O cálculo da estatística de teste então é o seguinte: \\[\\small t = \\frac{( \\bar{x}_1- \\bar{x}_2 ) - D_0}{\\sqrt{\\frac{s_1^2}{n_1} +\\frac{s_2^2}{n_2}}}\\] \\[\\small t = \\frac{(325- 286 ) - 0} {\\sqrt{\\frac{40^2}{12} +\\frac{44^2}{12} }} = 2,27\\] O cálculo dos graus de liberdade: \\[\\small gl = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{1}{n_1 -1}(\\frac{s_1^2}{n_1})^2 + \\frac{1}{n_2 -1}(\\frac{s_2^2}{n_2})^2}\\] \\[\\small gl = \\frac{(\\frac{40^2}{12} + \\frac{44^2}{12})^2}{\\frac{1}{12 -1}(\\frac{40^2}{12})^2 + \\frac{1}{12 -1}(\\frac{44^2}{12})^2} = 21,8\\] Arredondando, usaremos 21 graus de liberdade. A linha de 21 graus de liberdade na tabela t é: Área da cauda superior 0,20 0,10 0,05 0,025 0,01 0,005 Valor t ( 59 graus de liberdade ) 0,859 1,323 1,721 2,080 2,518 2,831 Um t de 2,27 está entre 2,080 e 2,518, portanto, o p está entre 0,025 e 0,01. Desse modo o valor p é menor que  = 0,05. Regra de Rejeição quando se usa o p-value: Rejeitar H0se o valor de p   0,025  0,05  Rejeita a \\(\\small H_0\\) Portanto, os resultados amostrais levam à conclusão que \\(\\small _1- _2\\) &gt; 0 e \\(\\small _1&gt; _2\\) , ou seja, o novo pacote de software oferece uma média populacional menor de tempo de conclusão. 10.6.2.2 Observações Os procedimentos de estimação por intervalo e teste de hipóteses são bastante precisos desde que respeitado que \\(\\small n_1- n_2  20\\) e sempre que possível que os tamanhos de amostras sejam iguais, ou aproximadamente iguais. Se as distribuições das populações forem altamente assimétricas tamanhos de amostra maiores são recomendados. Tamanhos de amostras menores só devem ser utilizados se houver muita segurança de que a população está normalmente distribuída. Outro critério utilizado para se fazer inferências a respeito da diferença entre duas médias quando o desvio padrão populacional é desconhecido baseia-se na hipótese de que os desvio padrão populacionais são iguais \\((_1=_2=)\\). Dessa hipótese, os dois desvio padrão amostrais são combinados para produzir a seguinte variância amostral combinada. \\[\\small s_p^2=\\frac {(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2} {n_1 + n_2 - 2}\\] A estatística de teste torna-se: \\[\\small t = \\frac{(\\bar{x}_1 - \\bar{x}_2) - D_0}{ s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\\] Uma dificuldade apresentada por este procedimento é que a hipótese de que os dois desvio padrão são iguais é difícil de verificar. Desvio padrão populacionais não-iguais frequentemente são encontrados. Os resultados do procedimento agrupado podem não ser muito satisfatório principalmente se os tamanhos de amostra forem muito diferentes. 10.6.3 Amostras relacionadas ou dependentes Suponha que numa empresa de manufatura os funcionários possam usar dois diferentes métodos de produção. A fim de maximizar a produção, a empresa deseja identificar o método mais eficiente, ou seja, o método que possui a menor média populacional de tempo de conclusão. Digamos que : \\(\\small _1\\): média populacional de tempo de conclusão utilizando o método A \\(\\small _2\\): média populacional de tempo de conclusão utilizando o método B A diferença entre as médias das populações é dado por: \\(\\small _1- _2\\) . Iniciamos com a hipótese experimental de que não existe diferença entre média de tempo de conclusão dos dois métodos. Temos então as hipóteses: \\[\\small H_0: _1- _2 = 0 \\\\ H_a: _1- _2  0\\] Ao escolher o procedimento de amostragem que usaremos para coletar os dados referentes ao tempo de produção e testar as hipóteses, consideramos duas alternativas de projeto. Uma se baseia em amostras independentes e a outra em amostras relacionadas: Projeto de amostra independente: Uma amostra aleatória simples de funcionários é selecionada e cada funcionário da amostra usa o método 1. Uma segunda amostra aleatória simples é selecionada e cada funcionário utiliza o método 2. Projeto de amostras relacionadas (ou combinadas): Uma amostra aleatória simples de funcionários é selecionada. Casa funcionário usa primeiramente um método e depois o outro. A ordem dos dois métodos é atribuída aleatoriamente aos funcionários. Cada funcionário produz um par de valores de dados, um correspondente ao método 1 e outro ao método 2 No projeto de amostras relacionadas, os dois métodos são testados de forma idêntica, ou seja, com os mesmos funcionários, portanto esse projeto acarreta em um erro de amostragem menor que o projeto de amostras independentes. Isso acontece devido a eliminação de variações entre funcionários já que são usadas as mesmas pessoas para ambos os métodos de produção. Utilizando o método de amostras relacionadas, uma amostra de 6 funcionários é coletada. A amostra é listada abaixo: Funcionário Tempo de conclusão - Método 1 Tempo de conclusão - Método 2 Diferença dos Tempos de conclusão 1 6,0 5,4 0,6 2 5,0 5,2 -0,2 3 7,0 6,5 0,5 4 6,2 5,9 0,3 5 6,0 6,0 0,0 6 6,4 5,8 0,6 No método de amostras relacionadas, somente a diferença é levada em consideração. Admitamos que \\(\\small _d\\) como a média dos valores de diferença para a população de funcionários. Com essa notação, as hipóteses nula e alternativa são reescritas da seguinte maneira: \\[\\small H_0: _d = 0 \\\\ H_a: _d  0\\] A média amostral e o desvio padrão amostral dos seis valores de diferença são os seguintes: \\[\\small d=\\frac{d_i}{n} = \\frac{1,8}{6} = 0,30\\] \\[\\small s_d=\\sqrt{\\frac{(d_i- \\bar{d})}{n -1}} =\\sqrt{\\frac{0,56}{5}}= 0,335\\] Devido a amostra ser pequena, 6 elementos, precisamos levantar a hipótese de que a população de diferenças tem uma distribuição normal. Essa hipótese é necessária a fim de podermos usar a distribuição t para os procedimentos de teste de hipóteses e de estimação por intervalo. Com base nessa hipótese, a seguinte estatística de teste tem uma distribuição t com n -1 graus de liberdade: \\[\\small t = \\frac{\\bar{d} - _d}{s_{d/\\sqrt{n}}}\\] \\[\\small t = \\frac{0,30 - 0}{0,335/\\sqrt{6}} = 2,20\\] Vamos calcular o valor de p para esse teste bicaudal. A linha de 5 graus de liberdade na tabela t é: Área da cauda superior 0,20 0,10 0,05 0,025 0,01 0,005 Valor t ( 21 graus de liberdade ) 0,920 1,476 2,015 2,571 3,365 4,032 Portanto verificamos que a estatística t se encontra entre a área da cauda superior entre 0,05 e 0,025. Uma vez que se trata de um teste bicaudal o valor deve ser duplicado, logo o valor p se encontra entre 0,10 e 0,05. Essa valor p é maior que  = 0,05. Assim a hipótese nula \\(\\small H_0: _d = 0\\) não é rejeitada. Uma estimação por intervalo da diferença entre as duas médias populacionais usando a metodologia das populações simples. Com 95% de confiança o cálculo é o seguinte: \\[\\small \\bar{d}± t_{0,025}\\frac{s_d}{\\sqrt{n}}\\] \\[\\small 0,3± 2,571(\\frac{0,335}{\\sqrt{6}})\\] \\[\\small 0,3± 0,35\\] \\[\\small -0,5 _d  0,65\\] A margem de erro : 0,35 10.6.3.1 Observação A correspondência de relação ou dependência não se dá somente por um mesmo elemento produzir mais de um valor de amostra, a correspondencia pode ser realizada por meio de características como: idade, educação, sexo, experiência profissional, etc. O projeto de dependência geralmente produz melhor precisão que o critério de amostras independentes. 10.7 Inferência acerca da diferença entre duas proporções Para realizar a comparação da diferença entre proporções populacionais precisamos realizar os seguintes passos: Selecionar duas amostras aleatórias independentes (maiores que 5 elementos) Realizar a estimação por ponto da diferença entre as proporções populacionais Realizar a estimação por intervalo da diferença entre as proporções populacionais Realizar um teste de hipótese Para tornar mais claro os passos vamos tomar como exemplo a comparação da qualidade de trabalho de dois escritórios no quesito preenchimento correto de cadastros. Foram selecionadas aleatoriamente amostras de cadastros preenchidos pelos escritórios A e B: Amostra A \\(\\small n_1\\): 250 n° de erros: 35 Amostra B \\(\\small n_2\\): 300 n° de erros: 27 Intervalo de confiança: 90% A partir dessas informações será possível verificar a precisão amostral dos cadastros e será possível estimar a proporção dos cadastros preenchidos incorretamente em cada escritório. Estimação por ponto A estimação por ponto da diferença entre as duas proporções populacionais é dada por: \\[\\small \\bar{p}_1-\\bar{p}_2\\] e é calculada a partir da diferença entre as duas proporções amostrais das amostras colhidas. Portanto: \\[\\small \\bar{p}_1=\\frac{35}{250} = 0,14\\] \\[\\small \\bar{p}_2=\\frac{27}{300} = 0,09\\] \\[\\small \\bar{p}1-\\bar{p}2 =0,14 -0,09 = 0,05\\] estimamos que o escritório A tem um índice de erro 5% maior que o do escritório 2. Estimação por intervalo Se fossem tomadas, repetidamente, amostras aleatórias independentes dos cadastros preenchidos pelos escritórios A e B teríamos uma distribuição amostral que iria refletir os possíveis valores de \\(\\small \\bar{p}_1-\\bar{p}_2\\) . A média desta distribuição amostral é \\(\\small \\bar{p}_1-\\bar{p}_2\\) e o erro padrão é o seguinte: \\[\\small _{\\bar{p}_1-\\bar{p}_2} = \\sqrt{\\frac{p_1(1 - p_1)}{n1} + \\frac{p_2(1 - p_2)}{n_2}}\\] Se os tamanhos das amostras forem de tamanho suficiente a distribuição amostral será aproximada de uma distribuição normal. A estimação por intervalo é dada por: \\[\\small \\bar{p}_1-\\bar{p}_2 ± \\textrm{Margem de erro}\\] E a margem de erro é calculada(considerando uma distribuição amostral aproximada de uma distribuição normal): \\[\\small \\textrm{Margem de erro} = z_{/2}_{\\bar{p}_1- \\bar{p}_2}\\] Portanto: \\[\\small \\bar{p}_1- \\bar{p}_2± \\sqrt{\\frac{p_1(1 - p_1)}{n1} + \\frac{p_2(1 - p_2)}{n_2}}\\] \\[\\small 0,05± z_{/2}\\sqrt{\\frac{0,14(1 -0,14)}{250} +\\frac{0,09(1 -0,09)}{300}}\\] \\[\\small 0,05± z_{/2}\\sqrt{\\frac{0,1204}{250} +\\frac{0,0819}{300}}\\] \\[\\small 0,05± z_{/2}\\sqrt{0,0004816 +0,000273}\\] \\[\\small 0,05± z_{/2}\\sqrt{0,0007546}\\] \\[\\small 0,05± z_{/2} ×0,02747\\] \\[\\small 0,05±1,645 ×0,02747\\] \\[\\small 0,05±0,045\\] \\[\\small 0,005&lt; \\bar{p}_1-\\bar{p}_2 &lt;0,095\\] Com uma margem de erro de 0,045 e um intervalo de confiança de 90% nossa estimação da diferença entre proporções varia de 0,005 a 0,095. Teste de hipótese Como desejamos saber se há diferença entre as proporções de erros entre os escritórios vamos estabelecer um hipótese nula que considere que as proporções populacionais são iguais, ou seja, que não há diferença entre elas: \\[ \\small H_0: p_1- p_2 = 0 \\\\ H_a: p_1- p_2  0 \\] Baseamos a estatística de teste na distribuição amostral do estimador por ponto \\(\\small \\bar{p}_1-\\bar{p}_2\\) . Para calcular o erro padrão de \\(\\small \\bar{p}_1-\\bar{p}_2\\) utilizamos a seguinte equação: \\[\\small _{\\bar{p}_1-\\bar{p}_2} = \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)} {n_2}}\\] No entanto, sob a hipótese que \\(\\small H_0\\) é verdadeira enquanto igualdade, as proporções populacionais devem ser iguais e \\(\\small \\bar{p}_1-\\bar{p}_2 =p\\) e sendo este o caso \\(\\small _{\\bar{p}_1-\\bar{p}_2}\\) torna-se: \\[\\small _{\\bar{p}_1-\\bar{p}_2} = \\sqrt{\\frac{ p(1 -p)}{n_1} +\\frac{p(1 - p)} {n_2}}\\] \\[\\small _{\\bar{p}_1-\\bar{p}_2} = \\sqrt{p(1-p) \\frac{1}{n_1} + \\frac{1}{n_2}}\\] Substituindo \\(\\small \\bar{p}\\) por p obtemos uma estimativa do erro padrão de \\(\\small \\bar{p}_1-\\bar{p}_2\\). Essa estimativa do erro padrão é usada na estatística de teste. Com p desconhecido, agrupamos , ou combinamos, os estimadores por ponto das duas amostras ( \\(\\small \\bar{p}_1 \\textrm{ e }\\bar{p}_2\\)) para obtermos um único estimador por ponto de p da seguinte maneira: \\[\\small \\bar{p}=\\frac{n_1\\bar{p}_1 + n_2 \\bar{p}_2}{n_1 +n_2}\\] Esse estimador agrupado (pooled estimator) de p é uma média ponderada de \\(\\small \\bar{p}_1 \\textrm{ e }\\bar{p}_2\\). No caso teremos: \\[\\small \\bar{p}=\\frac{n_1\\bar{p}_1 + n_2 \\bar{p}_2}{n_1 +n_2}\\] \\[\\small \\bar{p}=\\frac{250 × 0,14+ 300 × 0,09}{250+300}\\] \\[\\small \\bar{p}=\\frac{35+ 27}{550}\\] \\[\\small \\bar{p}=0,11\\bar{27}\\] Agora vamos calcular a estatística de teste para o teste de hipóteses sobre \\(\\small \\bar{p}_1 -\\bar{p}_2\\): \\[\\small z=\\frac{ ( \\bar{p}_1 - \\bar{p}_2)}{\\sqrt{\\bar{p}(1-\\bar{p}) (\\frac{1}{n_1} +\\frac{1}{n_2})}} \\] \\[\\small z=\\frac{(0,14 - 0,09)}{\\sqrt{0,1127(1-0,1127)\\frac{1}{250} +\\frac{1}{300}}}\\] \\[\\small z=\\frac{0,05}{\\sqrt{0,1127(0,8873)\\frac{6 + 5}{1500}}}\\] \\[\\small z=\\frac{0,05}{\\sqrt{0,09999871× \\frac{11}{1500}}}\\] \\[\\small z=\\frac{0,05}{\\sqrt{0,0073}}\\] \\[\\small z=\\frac{0,05}{0,02708}\\] \\[\\small z=1,85\\] O valor de p para este teste bicaudal é 0,0644 (0,0322 de cada lado). Como o valor de p (0,06) é menor que o  (0,10) podemos rejeitar a \\(\\small H_0\\). Portanto, as taxas de erro entre os dois escritórios são diferentes. O resultado apontado pelo teste de hipótese é coerente com a estimação por intervalo da diferença entre as taxas de erros entre os escritórios, admitindo o intervalo: \\(\\small 0,005&lt; \\bar{p}_1- \\bar{p}_2 &lt;0,095\\). Se observamos a taxa do escritório 1 (0,14), esta se encontra fora do intervalo, sendo maior que os valores admitidos. 10.8 Proporção de uma população multinomial Para realizar a comparação da diferença entre a proporção de elementos de uma população pertencentes a somente uma das várias classes ou categorias, precisamos realizar os seguintes passos: Estabelecer a hipótese nula e alternativa \\(\\small H_0\\): A população segue uma distribuição multinomial com probabilidades especificadas para cada uma das k categorias \\(\\small H_a\\): A população não segue uma distribuição multinomial com as probabilidades especificadas para cada uma das k categorias Selecione uma amostra aleatória e registre as frequências observadas \\(\\small f_i\\) para cada categoria Suponha que a hipótese nula seja verdadeira e determine a frequência esperada \\(\\small e_i\\) em cada categoria Realizar um teste de hipótese A população multinomial, nada mais é que uma população que se divide em classes ou categorias onde um elemento pode pertencer a somente uma delas. A distribuição multinomial de probabilidade pode ser vista como uma extensão da distribuição binomial para o caso de três ou mais categorias de resultados, onde em casa ensaio ocorre um e somente um dos resultados (categorias). Presume-se a independência dos ensaios, ou seja, as probabilidades (das categorias) permaneçam as mesmas para cada ensaio. Para exemplificar o caso vamos tomar como exemplo a seguinte situação: Uma empresa de pesquisa de mercado foi contratada para verificar se o lançamento de um produto alterou a quota de mercado de três empresas. Consideremos: \\(\\small P_A\\): fatia de mercado da empresa A \\(\\small P_B\\): fatia de mercado da empresa B \\(\\small P_C\\): fatia de mercado da empresa C Uma pesquisa amostral será feita e a partir dela será calculada a proporção dos que preferem o produto de uma das empresas e um teste de hipótese será realizado para verificar se o novo produto causou alguma alteração nas fatias de mercado. Hipótese nula e alternativa Supondo que o novo produto da empresa C não altere as fatias de mercado, as hipóteses nula e alternativa são estabelecidas da seguinte maneira: \\[ \\small H_0: P_A = 0,30 \\textrm{ , } P_B =0,50\\textrm{ e } P_C=0,20 \\\\ H_a: \\textrm{as proporções populacionais não são } P_A=0,30 \\textrm{ , } P_B=0,50 \\textrm{ e } P_C=0,20 \\] Frequências A pesquisa de mercado consultou 200 consumidores acerca da preferência de compra entre as três alternativas (produtos da empresa A,B e C) e o resumo das respostas é o seguinte: Frequência Observada Produto da Empresa A Produto da Empresa B Produto da Empresa C 48 98 54 Agora o teste de eficiência de ajuste determinará se a amostra das preferências de compra é coerente com a hipótese nula. Qui-Quadrado : Teste de eficiência de ajuste O teste de eficiência de ajuste baseia-se na comparação da amostra de resultados observados e resultados esperados sob a suposição de que a hipótese nula é verdadeira. Portanto, agora basta calcular as frequências esperadas dos 200 clientes sob a suposição que \\(\\small P_A=0,30 \\textrm{ , } P_B=0,50 \\textrm{ e } P_C=0,20\\) Frequência Esperada Produto da Empresa A Produto da Empresa B Produto da Empresa C 200(0,3) = 60 200(0,5) = 100 200(0,2) = 40 Agora deve-se observar a diferença entre as frequências esperadas e observadas. Diferenças grandes entre as frequências levanta dúvidas sobre a suposição que as proporções hipotéticas estejam corretas. A estatística de teste explica o quão grande ou pequena é a diferença entre as frequências. \\[\\small ^2=\\sum_{i=1}^{k} \\frac{(f_i - e_i)}{e_i}\\] \\(\\small f_i= \\textrm{frequência observada para categoria i} \\\\ e_i= \\textrm{frequência esperada para categoria i} \\\\ k= \\textrm{número de categorias}\\) Obs: A estatística de teste tem uma distribuição qui-quadrado com k-1 graus de liberdade, desde que as frequências esperadas sejam 5 ou mais para todas as categorias. Obs: O teste de eficiência de ajuste é sempre um teste unicaudal, e a rejeição ocorre na cauda superior da distribuição qui-quadrado Categoria Proporção Hipotética Frequência Observada (\\(\\small fi\\)) Frequência Esperada (\\(\\small e_i\\)) Diferença (\\(\\small f_i - e_i\\)) Quadrado da Diferença (\\(\\small f_i - e_i)^2\\) Quadrado Dividido pela Frequência Esperada (\\(\\small f_i - e_i)^2/e_i\\) Empresa A 0,30 48 60 -12 144 2,40 Empresa B 0,50 98 100 -2 4 0,04 Empresa C 0,20 54 40 14 196 4,90 Total 200 \\(\\small ^2=7,34\\) observada &lt;- c(48,98,54) esperada &lt;- c(0.3 ,0.5, 0.2) quiqua &lt;-chisq.test(observada, p=esperada) quiqua ## ## Chi-squared test for given probabilities ## ## data: observada ## X-squared = 7.34, df = 2, p-value = 0.02548 Portanto, como o p-value (0,02) é menor que o alfa (0,05), rejeitamos a hipótese nula e concluímos que o novo produto da empresa C alterará a atual estrutura de participação de mercado, Obs: Graus de Liberdade (df.) : é a diferença entre o número de classes de resultados e o número de informações da amostra que são necessários ao cálculo dos valores esperados nessas classes 10.9 Teste exato de Fisher O teste exato de Fisher é um teste de significância estatística utilizado na análise de tabelas de contingência. Na prática ele é usado quando os tamanhos das amostras são pequenos, no entanto é válido para todos os tamanhos de amostra. É um teste exato porque fornece um valor p exato, e não uma aproximação, como no teste qui quadrado(onde quanto maior a amostra mais exato o valor de p se torna) Fisher teria concebido o teste depois de um comentário de uma senhora que afirmava ser capaz de detectar o que foi adicionado primeiro em sua xícara: o chá ou o leite. Ele realizou o teste no experimento dama apreciadora de chá. O experimento No experimento Fisher ofereceu 8 xícaras a senhora, quatro de cada tipo, em ordem aleatória: 4 preparadas adicionando primeiro leite, 4 preparadas adicionando primeiro chá. A senhora deveria que selecionar 4 xícaras por um método. Isso oferecia a vantagem de julgar as xícaras por comparação. Ela estava inteiramente informada do método experimental. A hipótese nula era que a senhora não tinha tal habilidade. Não há hipótese alternativa; (abordagem Neyman-Pearson) O teste estatístico era uma simples contagem do número de sucessos em selecionar 4 xícaras. A distribuição da hipótese nula era computada pelo número de permutações. O número de permutações selecionadas igualava o número de permutações não selecionadas. Contagem de sucesso Permutações de seleção Número de permutações 0 oooo 1 × 1 = 1 1 ooox, ooxo, oxoo, xooo 4 × 4 = 16 2 ooxx, oxox, oxxo, xoxo, xxoo, xoox 6 × 6 = 36 3 oxxx, xoxx, xxox, xxxo 4 × 4 = 16 4 xxxx 1 × 1 = 1 Total 70 A região crítica era o único caso de 4 sucessos de 4 possibilidades baseadas em um critério de probabilidade convencional (&lt; 5%; 1 de 70  1.4%). Se e somente se a senhora categorizasse corretamente todas as 8 xícaras Fisher estaria disposto a rejeitar a sua hipótese nula  efetivamente reconhecendo a capacidade da senhora ao nível de significância de 1,4% (mas sem quantificar sua capacidade). No teste, a senhora acertou todas as oito xícaras. As chances de alguém, com base em adivinhação, acertar todas as xícaras, (assumindo que ela supõe que em quatro o chá tenha sido colocado primeiro e em quatro o leite), seriam de apenas 1 em 70 (combinação de 8 tomados 4 a 4). Usos O teste é útil para dados categóricos, que resultam de classificação de objetos em duas maneiras diferentes; ele é usado para examinar a significância da associação (contingência) entre os dois tipos de classificação. Assim, no exemplo original de Fisher, um critério de classificação poderia ser se o leite ou chá foi colocado na xícara primeiro; o outro poderia ser se a senhora pensava que o leite ou chá, fora colocado em primeiro lugar. Queremos saber se essas duas classificações são associadas - isto é, se a senhora realmente poderia dizer se o leite ou o chá foi servido em primeiro lugar. A maioria dos usos do teste exato de Fisher envolvem, como neste exemplo, uma tabela de contingência 2×2. O p-valor do teste é calculado como se as margens da tabela fossem fixas, isto é, como se no exemplo da degustação de chá, a senhora soubesse o número de xícaras com cada tratamento (leite ou chá primeiro) que havia e poderia, portanto, fornecer estimativas com o número correto em cada categoria. Como apontado por Fisher, isso leva, sob a hipótese nula de independência a uma distribuição hipergeométrica dos números nas células da tabela. Teste exato de Fisher Vs Teste Qui-Quadrado O teste qui-quadrado é mais adequado para grandes amostras, visto que, em amostras pequenas ou desigualmente distribuídas entre as células da tabela (valores esperados ficam pequenos) a fórmula de obtenção de X² poderá produzir um valor significativo (&gt; do que o X² crítico), e portanto maior do que o valor real. A regra de ouro usual para decidir se o teste de aproximação da qui-quadrado é bom o suficiente é não ser: abaixo de 5 ou abaixo de 10 quando há apenas um grau de liberdade Em dados pequenos, esparsos, ou não balanceados, o p-valor exato e o assintótico podem ser muito diferentes e podem levar a conclusões opostas sobre a hipótese de interesse. O teste exato de Fisher é, como seu nome indica, exato, e mantém os totais das linhas e colunas fixos, e pode, portanto, ser utilizado independentemente das características da amostra. No entanto, é complexo de se calcular com amostras grandes ou tabelas bem equilibradas, as quais são exatamente as condições em que o teste qui-quadrado é apropriado. Exemplo Uma amostra de adolescentes pode ser dividida em masculino e feminino e entre os que estudam e não estudam. Vamos supor, por exemplo, que a proporção de pessoas estudando é maior entre mulheres do que entre os homens, e queremos testar se é significativa a diferença das proporções que observadas. Os dados podem parecer como a tabela abaixo: Homens Mulheres Total da linha Estudiosos 1 9 10 Não estudiosos 11 3 14 Total da coluna 12 12 24 A pergunta que se faz sobre esses dados é: sabendo que 10 destes 24 adolescentes são estudiosos, e que 12 dos 24 são do sexo feminino, e supondo que a hipótese nula de que homens e mulheres têm a mesma probabilidade de estudar, qual é a probabilidade de que esses 10 estudiosos seria tão desigualmente distribuídos entre as mulheres e os homens? Se tivéssemos que escolher 10 dos adolescentes ao acaso, qual a probabilidade de que 9 ou mais deles estarem entre as 12 mulheres, e apenas 1 ou menos estarem entre os 12 homens? Nós representamos as células pelas letras a, b, c e d, chame os totais das linhas e colunas de totais marginais, e represente o total por n. Assim, a tabela agora tem esse aspecto: Homens Mulheres Total da linha Estudiosos a b a+b Não estudiosos c d c+d Total da coluna a+c b+d a+b+c+d = n Fisher mostrou que a probabilidade de obtenção de tais valores é dada pela distribuição hipergeométrica: \\[\\small p=\\frac{\\binom{a+b}{a} + \\binom{c+d}{c}}{\\binom{n}{a+c}} = \\frac{(a + b )! (c + d)! (a + c)! (b + d)!}{a! b! c! d! n!}\\] Onde \\(\\binom{n}{k}\\) é o coeficiente binomial. Com os dados acima, isso nos dá: \\[\\small p=\\frac{\\binom{10}{1} + \\binom{14}{11}}{\\binom{24}{12}} = \\frac{10! 14! 12! 12!}{1! 9! 11! 3! 24!} \\approx 0,001346076\\] 10.10 ANOVA - Análise de Variância Análise da Variância (ANOVA) é um método para testar a igualdade de três ou mais médias populacionais, baseado na análise das variâncias amostrais. ANOVA pode ter utilizada para analisar dados obtidos tanto de um estudo observacional como de um estudo experimental. Os experimentos podem envolver variáveis de resposta, fator e tratamento Exemplo: Uma fábrica tem três linhas de produção e estão interessados em saber o quanto seus funcionários sabem sobre o gerenciamento de qualidade total. Uma amostra de 6 funcionários de cada linha foi selecionado e seus integrantes foram submetidos a um exame de seus conhecimentos sobre qualidade. As notas obtidas pelos funcionários estão listadas na tabela abaixo: Observação Atlanta Dallas Seattle 1 85 71 59 2 75 75 64 3 82 73 62 4 76 74 69 5 71 69 75 6 85 82 67 Média Amostral 79 74 66 Variação Amostral 34 20 32 Desvio Padrão Amostral 5,83 4,47 5,66 Os gerentes querem testar a hipótese de que a média das notas de exame é a mesma para todas as três fábricas. Consideremos as médias: \\(\\small _1\\):média das notas de exame da população 1 \\(\\small _2\\):média das notas de exame da população 2 \\(\\small _3\\):média das notas de exame da população 3 Embora jamais saibamos os valores reais de \\(\\small _1,_2\\) e \\(\\small _3\\), queremos usar os resultados amostrais para testar as seguintes hipóteses: \\[\\small H_0: _1= _2= _3\\] \\[\\small H_a:\\textrm{Nem todas as médias populacionais são iguais}\\] A ANOVA é um procedimento estatístico que pode ser usado para determinar se as diferenças observadas nas três médias amostrais são suficientemente grandes para rejeitarmos a \\(\\small H_0\\). A ANOVA analisa experimentos que envolvem variáveis de resposta, fator e tratamento. No exemplo as variáveis envolvidas são: localização das fábricas notas obtidas no exame de conhecimento sobre qualidade Dado que o objetivo é determinar se a média das notas do exame é a mesma para todas as três linhas de produção , as notas do exame são chamadas de variável dependente ou variável de resposta e o local da fábrica como variável independente ou fator. Em geral os valores de um fator selecionado para serem submetidos a uma investigação denominam-se níveis do fator ou tratamentos. 10.10.1 Hipótese sobre a análise de Variância Três hipóteses são necessárias para a análise de variância: Para cada população, a variável de resposta está normalmente distribuída. Implicação: As notas dos exames (variável resposta) devem estar normalmente distribuídas A variância da variável de resposta, denotada por \\(\\small ^2\\), é idêntica para todas as populações. Implicação: A variância das notas obtidas no exame deve ser idêntica para todas as três linhas de produção. As observações devem ser independentes. Implicação: A nota de cada funcionário obteve no exame deve ser independente da nota obtida por qualquer outro funcionário. 10.10.2 Visão Conceitual Se as médias correspondentes às três populações forem iguais é esperado que as três médias amostrais estejam bem próximas entre si. Quanto mais próximas as médias amostrais estiverem, mais forte é a evidência que as médias populacionais são iguais. Por outro lado, quanto mais as médias amostrais forem distantes uma das outras mais forte é a evidência de que as médias populacionais não são iguais. Portanto: Variabilidade pequena entre as médias amostrais: evidência favorável a \\(\\small H_0\\) Variabilidade grande entre as médias amostrais: evidência favorável a \\(\\small H_0\\) Sendo \\(\\small H_a\\) verdadeira podemos usar a variabilidade entre as médias amostrais para desenvolver uma estimativa de \\(\\small ^2\\). A distribuição amostral da média \\(\\small \\bar{x}\\) da amostra correspondente a uma amostra aleatória simples de tamanho n extraída de uma população normal, estará normalmente distribuída e possui uma média  com uma variância de \\(\\small \\frac{^2}{n}\\) Como podemos observar na imagem abaixo: Por exemplo (Hipótese nula verdadeira): Sendo a hipótese nula verdadeira, as médias amostrais \\(\\small \\bar{x}_1= 79, \\bar{x}_2= 74, \\bar{x}_3= 66\\) seriam valores extraídos aleatoriamente da distribuição amostral da mesma população ( como por exemplo, a exibida na figura acima). Neste caso, a média e a variância dos três valores podem ser usados para estimar a média e a variância da distribuição amostral. A estimativa da média seria dada por: \\[\\small \\frac{79+74+66}{3}=73\\] E essa estimativa chama-se: média global da amostra. A estimativa da variância da distribuição amostral de \\(\\small \\bar{x}, _{\\bar{x}}^{2}\\) é fornecida pela variância das três médias amostrais. \\[s_{\\bar{x}}^{2} =\\frac{(79 - 73)^2 + ( 74 - 73)^2 + ( 66 - 73)^2}{3 - 1} = 43\\] Dado que que \\(\\small _{\\bar{x}}^{2} = ^2\\/n\\), a resolução de \\(\\small ^2\\) fornece: \\[^2 = n_{\\bar{x}}^{2}\\] Portanto, Estimativa de \\(\\small ^2=n ( \\textrm{Estimativa de }\\bar{x}^{2} ) =ns_{\\bar{x}}^{2} = 6 (43) = 258\\) A essa estimativa, denomina-se: estimativa de \\(\\small ^2\\) entre tratamentos sample = sort(rnorm(n = 100,mean = 73,sd = 43 )) a = dnorm(sample, mean = 73,sd = 43) plot(sample,a, type = &quot;l&quot;, col=&quot;blue&quot;,ylim=c(0,0.01)) lines(c(79, 79), c(0, 0.01), lwd = 2, col =&quot;red&quot;, lty = 2) lines(c(74, 74), c(0, 0.01), lwd = 2, col = &quot;yellow&quot;, lty = 2) lines(c(66, 66), c(0, 0.01), lwd = 2, lty = 2) Simulação de uma distribuição normal de média 73 e desvio padrão 43. Amarelo = média amostral de 74 Preto = média amostral de 66 Vermelho = média amostral de 79 Supondo a \\(\\small H_0\\) falsa , todas as médias de amostra iriam diferir. Seriam as amostras portanto, provenientes de populações normais com diferentes médias, elas resultarão em três diferentes distribuições amostrais, como pode ser observado na imagem abaixo: Dessa forma, \\(\\small s_{\\bar{x}}^{2}\\)será maior, fazendo que a estimativa de de \\(\\small ^2\\) entre tratamentos seja maior. 10.10.2.1 Estimativa da variância dentro dos tratamentos A variância que ocorre dentro da cada uma das amostras também tem um efeito sobre a conclusão a que chegamos ao realizar a análise da variância. Quando uma amostra aleatória simples é selecionada de cada população, cada uma das variâncias amostrais oferece uma estimativa sem viés de \\(^2\\). Portanto, podemos combinar ou agrupar as estimativas individuais de \\(\\small ^2\\) em uma estimativa global. A estimativa global de \\(^2\\) obtida dessa maneira é chamada de estimativa agrupada ou estimativa de \\(^2\\) dentro dos tratamentos . Uma vez que cada variância amostral fornece uma estimativa de \\(\\small ^2\\) baseada somente na variação existente dentro de cada amostra, a estimativa de \\(\\small ^2\\) dentro dos tratamentos não é afetada pelo fato de as médias populacionais serem ou não serem iguais. Quando o tamanho das amostras é igual, a estimativa de \\(\\small ^2\\) dentro dos tratamentos pode ser obtida calculando-se a média das variâncias individuais. Para o exemplo em questão temos: Estimativa de \\(\\small ^2\\) dentro dos tratamentos = \\(\\small \\frac{34 + 20 + 32}{3} = 28,67\\) No exemplo atual, a estimativa de \\(^2\\) entre tratamentos (258) é muito maior que a estimativa de \\(\\small ^2\\) dentro dos tratamentos (28,67). A razão das estimativas: \\(\\small \\frac{\\textrm{Estimativa de } \\sigma^2 \\textrm{ entre tratamentos}}{\\textrm{Estimativa de } \\sigma^2 \\textrm{ dentro dos tratamentos}} = \\frac{258}{28,67} = 9\\) A abordagem entre tratamentos produz uma boa estimativa de \\(\\small ^2\\) somente se a hipótese nula for verdadeira; se a hipótese nula for falsa, a abordagem entre tratamentos superestimará \\(\\small ^2\\). O critério dentro do tratamento fornece uma boa estima de \\(\\small ^2\\) em qualquer um dos casos. Desse modo, se a hipótese nula for verdadeira, as duas estimativas serão similares e suas razões serão próximas a 1. Se a hipótese nula for falsa, a estimativa entre tratamentos será maior que a estimativa dentro dos tratamentos e a razão entre elas será grande. 10.10.2.2 Resumo A lógica da ANOVA se baseia no desenvolvimento de duas estimativas independentes da variância populacional \\(^2\\) comum: Baseada na variabilidade existente entre as próprias médias amostrais Baseada na variabilidade existente dentro de cada amostra Ao comparar as essas duas estimativas de \\(\\small ^2\\), seremos capazes de determinar se as médias populacionais são iguais. 10.10.3 Observação Se os tamanhos das amostras forem iguais, a análise de variância não terá sensibilidade suficiente para detectar afastamentos da hipótese de que as populações estão normalmente distribuídas. 10.10.4 Fórmulas Matemáticas A análise de variância pode ser usada para testar a igualdade de k médias populacionais. A forma geral das hipóteses testadas é: \\[\\small H_0: _1= _2= ... = _k\\] \\[\\small H_a:\\textrm{Nem todas as médias populacionais são iguais}\\] em que: \\[\\small _k = \\textrm{média da k-ésima população}\\] Supomos que a amostra aleatória simples de tamanho \\(n_j\\) tenha sido selecionada de cada uma das k populações ou tratamentos. Em relação aos dados amostrais resultantes, admitimos que: \\(\\small x_{ij}\\) = valor da observação i para o tratamento j \\(\\small n_j\\) = número de observações para o tratamento j \\(\\small \\bar{x}_j\\) = média amostral para o tratamento j \\(\\small s_j^2\\) = variância amostral para o tratamento j \\(\\small s_j\\) = desvio padrão amostral para o tratamento j A fórmula correspondente à média amostral para o tratamento j é a seguinte: \\[\\small \\bar{x}_j= \\frac{\\sum_{i=1}^{n_j} x_{ij}}{n_j}\\] A fórmula correspondente à variância amostral para o tratamento j é a seguinte: \\[\\small s_j^2 = \\frac{ \\sum_{n_j}^{i = 1}(x_{ij} - \\bar{x}_j)^2}{n_j - 1}\\] A média global da amostra, denotada por \\(\\bar{x}\\), é a soma de todas as observações divididas pelo número total de observações. Ou seja: \\[ \\small \\bar{\\bar{x}}= \\frac{\\sum_{k}^{j = 1} \\sum{n_j}{i = 1}x_ {ij}}{n_T} \\] Em que: \\[\\small n_T= n_1+n_2+  + n_k\\] Se o tamanho de cada amostra for n, \\(\\small n_T = k_n\\). Nesse caso a equação se reduz a: \\[\\small \\bar{\\bar{x}}= \\frac{\\sum_{j = 1}^{k} \\sum_{i = 1}^{n_j}x_{ij}}{kn} = \\frac{\\sum_{j = 1}^{k} \\sum_{i = 1}^{n_j}x_{ij/n}}{k} = \\frac{\\sum_{j = 1}^{k}\\bar{x}_j}{k}\\] Em outras palavras, quando o tamanho das amostras forem iguais, a média global das amostras é simplesmente o valor médio das k médias amostrais. 10.10.4.1 Estimativa da Variância Populacional entre Tratamentos O conceito da estimativa de \\(\\small _2\\) entre tratamentos é chamado quadrado da média em razão do tratamento e é denotada por MSTR (mean square due to treatments). A fórmula geral para calcular a MSTR é: \\[\\small MSTR = \\frac{\\sum_{j = 1}^{k} n_j(\\bar{x}_j - \\bar{\\bar{x}})^2}{k - 1}\\] O numerador é chamado soma dos quadrados dos tratamentos e é denotado por SSTR ( sum of squares due to treatments) O denominador, k-1, representa os graus de liberdade associados à SSTR. Portanto, o quadrado médio dos tratamentos pode ser calculado pela seguinte fórmula. \\[\\small MSTR = \\frac{SSTR}{k - 1}\\] \\[\\small SSTR = \\sum_{j = 1}^{k}n_j\\bar{(x}_j- \\bar{\\bar{x}})^2\\] Se \\(\\small H_0\\) for verdadeira, a MSTR produzirá uma estimativa sem viés de \\(\\small ^2\\). Entretanto, se as médias de k populações não forem iguais, a MSTR não será um estimativa sem viés de \\(\\small ^2\\); realmente, nesse caso, a MSTR deve superestimar \\(\\small ^2\\). 10.10.4.2 Estimativa da Variância Populacional dentro de Tratamentos Uma estimativa de \\(\\small ^2\\) dentro de tratamentos é chamada quadrado médio dos erros, e é denotada por MSE ( mean square due to error). A fórmula geral para calcular o MSE é: \\[\\small MSE =\\frac{\\sum_{j = 1}^{k}(nj - 1)s_j^2}{n_T - k}\\] O numerador é denominado soma dos quadrados dos erros e é denotado SSE ( sum of square due to error). O denominador de MSE, \\(\\small n_T -k\\), é o grau de liberdade associado à SSE. Portanto, a fórmula para calcular MSE também pode ser definida da seguinte forma: \\[\\small MSE =\\frac{SSE}{n_T - k}\\] \\[\\small SSE =\\sum_{j = 1}^{k}(n_j - 1)s_j^2\\] O MSE baseia-se na variação dentro de cada um dos tratamentos; ele não é influenciado pelo fato de a hipótese nula ser ou não ser verdadeira. Portanto, o MSE sempre produz uma estimativa sem viés de \\(\\small ^2\\). 10.10.5 Comparando as Estimativas de Variância: o Teste F Se a hipótese nula for verdadeira, o MSTR (estimativa entre tratamentos) e o MSE ( estimativa dentro dos tratamentos ) produzem duas estimativas independentes da variância populacional \\(\\small ^2\\). Quando a hipótese nula é verdadeira e as pressuposições ANOVA são válidas, a distribuição amostral da razão MSTR/MSE tem uma distribuição F com k - 1 graus de liberdade no numerador e \\(n_T - 1\\) graus de liberdade no denominador. A forma geral dessa distribuição F é mostrada abaixo: Se a hipótese nula for verdadeira, o valor de MSTR/MSE parecerá que é proveniente dessa distribuição. Se a hipótese nula for falsa, o valor de MSTR/MSE sofrerá uma inflação, porque um MSTR grande produz uma estimativa em excesso de \\(^2\\). Os valores de MSTR/MSE, essa razão torna-se a estatística de teste do teste de hipóteses sobre a igualdade de k médias populacionais. A estatística de teste é a seguinte: \\[\\small F = \\frac{MSTR}{MSE}\\] A distribuição F tem k - 1 graus de liberdade no numerador e \\(\\small n_T - k\\) graus de liberdade no denominador. No exemplo, usando um nível de significância de  = 0,05 para realizar o teste de hipóteses. As hipóteses nula e alternativa são redefinidas da seguinte maneira: \\[\\small H_0: _1= _2= _3\\] \\[\\small H_a:\\textrm{Nem todas as médias populacionais são iguais}\\] Com MSTR = 258 e MSE = 28,67 calculados anteriormente, o valor da estatística de teste é: \\[\\small F = \\frac{MSTR}{MSE} = \\frac{258}{28,67} = 9\\] Os graus de liberdade do numerador são (k - 1)= (3 - 1) = 2 Os graus de liberdade do denominador são (\\(\\small n_T - k\\)) = (18 - 3) = 15 Uma vez que rejeitamos a hipótese nula para valores grandes da estatística de teste, calcularemos o valor p como a área da cauda superior da distribuição F à direita da estatística de teste F = 9. A regra de rejeição de \\(\\small H_0\\) dos testes de hipótese habituais se o valor p   aplica-se nesse caso. Um trecho da tabela F é exibido abaixo: Área da Cauda Superior 0,10 0,05 0,025 0,01 Valor F (\\(\\small gl_1 = 2, gl_2 = 15\\)) 2,70 3,68 4,77 6,36 Já que F = 9 é maior que 6,36, a área da cauda superior em F = 9 é menor que 0,01, portanto, o valor p é menor que 0,01. Com o valor de  = 0,05 a \\(\\small H_0\\)é rejeitada. O teste estão fornece suficientes evidências para concluirmos que as médias das três populações não são iguais, ou seja, a média populacional das notas de exame nas três fábricas não é igual. O critério do valor crítico também poderia ser utilizado, no caso ficaria da seguinte forma: \\[\\small \\textrm{Rejeitar }H_0\\textrm{ se F  }3,68\\] Com F = 9 rejeitamos a \\(\\small H_0\\) e concluímos que a média das três populações não são iguais. Em resumo, com o exemplo obtivemos os seguintes resultados: Fonte de Variação Soma dos Quadrados Graus de Liberdade Quadrado Médio F Tratamentos 516 2 258 9 Erro 430 15 28,67 Total 946 17 A soma do quadrados associada à fonte de variação que recebe o rótulo de Total denomina-se soma total dos quadrados - SST (total sum of squares). \\[\\small SST = SSTR + SSE\\] Os graus de liberdade associadas a essa soma total de quadrados é a soma dos graus de liberdade associados com a estimativa de \\(_2\\) entre tratamentos e com a estimativa de \\(_2\\) dentro dos tratamentos. A soma total dos quadrados (SST) dividida por seus graus de liberdade \\(n_T - 1\\) é a variância amostral global que seria obtida se tratássemos o conjunto inteiro de 18 observações como um conjunto de dados. Quando se tem o conjunto de dados inteiro como uma única amostra, a fórmula para calcular a soma total dos quadrados, SST, é: \\[\\small SST= \\sum_{j = 1}^{k}\\sum_ {i = 1}^{n_j}(x_{ij}- \\bar{\\bar{x}} )^2\\] Em outras palavras, a SST pode ser dividida em duas somas de quadrados: a soma dos quadrados dos tratamentos (SSTR) a soma dos quadrados dos erros (SSE) Os graus de liberdade correspondentes a SST ( \\(\\small n_T - 1\\)), podem ser divididos nos graus de liberdade correspondentes a SSTR (\\(\\small k - 1\\) ), e nos graus de liberdade correspondentes a MSE (\\(\\small n_T - k\\)). A análise de variância pode ser vista como um processo de partição da soma total dos quadrados e os graus de liberdade em suas fontes correspondentes: tratamento e erro. Dividir a soma dos quadrados pelos graus de liberdade apropriados produzirá as estimativas de variância e o valor F que são usadas para testar a hipótese de médias populacionais iguais. No caso do exemplo teremos: \\[\\small SST = SSTR + SSE\\] \\[\\small SST = 516+ 430 = 946\\] O Desvio Padrão Agrupado (estimativa de ) é dado por: \\[\\small s = \\sqrt{MSE}\\] \\[\\small s = \\sqrt{28,7} = 5,354\\] 10.10.6 Estimação por intervalo A forma geral de uma estimação por intervalo de uma média populacional é: \\[\\small \\bar{x}± t_{ / 2} \\frac{s}{\\sqrt{n}}\\] em que  é a estimativa do desvio padrão s da população. Na análise de variância, a melhor estimativa de  é fornecida pela raiz quadrada do MSE ou do Desvio Padrão Agrupado. No caso do exemplo temos (especificamente para fábrica de Atlanta): \\[\\small \\bar{x}± t_{ / 2} \\frac{s}{\\sqrt{n}}\\] \\[\\small 79± 2,131 \\frac{5,354}{\\sqrt{6}}\\] \\[\\small 79± 4,66\\] \\[\\small 74,34    83,66\\] Usamos o grau de liberdade associado à estimativa de \\(^2\\) dentro dos tratamentos e a média obtida na fábrica de Atlanta. 10.10.7 Resumo Teste da igualdade de k médias populacionais \\[\\small H_0: \\mu_1 = \\mu_2=...=\\mu_k\\] \\[\\small H_a: \\textrm{Nem todas as médias populacionais são iguais}\\] Estatística de Teste \\[\\small F = \\frac{MSTR}{MSE}\\] Estatística de Teste Critério do valor p: Rejeitar \\(\\small H_0\\) se o valor de \\(\\small p \\leq \\alpha\\) Critério do valor crítico: Rejeitar \\(\\small H_0\\) se o valor de \\(\\small F \\geq F_{\\alpha}\\) em que o valor de \\(\\small F_{\\alpha}\\) baseia-se em uma distribuição F com \\(\\small k-1\\) graus de liberdade no numerador e \\(\\small n_T - k\\) graus de liberdade no denominador. 10.10.7.1 Tabela de análise de variância Fonte de Variação Graus de Liberdade Soma dos quadrados Quadrado Médio Estatística F Tratamentos k - 1 SQ ( Tr ) QM ( Tr ) \\(\\frac{Qm ( Tr )}{QME}\\) Erro k (n - 1) SQE QME Total kn - 1 SQT \\[\\small SQ ( Tr) = s_{\\bar{x}}^{2} =\\frac{(\\bar{x}_i - \\bar{x})^2}{k - 1} =\\textrm{Soma dos quadrados entre tratamentos}\\] \\(\\small \\bar{x}\\) = média global \\(\\small \\bar{x}_i\\) = média do tratamento \\[\\small QM ( Tr ) = \\frac{SQ ( Tr)}{k - 1} = \\textrm{Quadrado Médio de Tratamento}\\] \\[\\small SQE = s_{\\bar{x}}^2 =\\frac{(\\bar{x}_{ij} - \\bar{x}_i)^2}{k (n - 1)} =\\textrm{Soma dos quadrados entre tratamentos}\\] \\(\\small \\bar{x}_{ij}\\)= elemento do tratamento \\(\\small \\bar{x}_i\\) = média do tratamento \\[\\small QME= \\frac{SQE}{k (n - 1)} = \\textrm{Quadrado Médio de Erro}\\] \\[\\small SQT = \\sum_ {i = 1}^{k} \\sum_{j =1}^n(x_{ij} - \\bar{x} )^2 \\] \\(\\small \\bar{x}_{ij}\\)= j-ésimo elemento do i-ésimo tratamento ou \\(\\small SQT =SQ ( Tr) + SQE\\) 10.10.8 Comparações Múltiplas Os testes de comparações múltiplas, ou teste de comparações de médias, servem como uma complemento ao teste F, para detectar diferenças de efeitos entes tratamentos. Ou seja, quando a ANOVA detectou que existe uma diferença significativa entre as médias o teste de comparações múltiplas permite ranquear tais diferenças. São utilizados para testar todo e qualquer contraste entre duas médias e não permite comparar grupos de médias entre si. E porque não simplesmente utilizar um teste t? Porque assim a possibilidade de cometer um erro de tipo I (atribuir diferenças significativas quando elas realmente não existem) aumentam exponencialmente ao número de pares. \\[\\small Erro = 1 - ()^n\\] n = número de pares possíveis A tabela abaixo auxílio na escolha do teste adequado de acordo com o coeficiente de variação da amostra e o número de tratamentos. Coeficiente de Variação Número de tratamentos &lt; 4 tratamentos &gt; 4 tratamentos Menor que 15% Tukey, SNK ou Sheffé Tukey ou SNK Entre 15% e 30% Teste t Duncan ou SNK Maior que 15% Teste t Teste t, Duncan O teste Scott-Knott é sempre recomendado. Exemplo: Os dados abaixo, informam o tempo em minutos que uma certa pessoa levou para dirigir para o local de trabalho em cinco duas, selecionadas ao acaso, ao longo de quatro trajetos diferentes: \\(\\small \\bar{x}\\) Trajeto 1 25 26 25 25 28 25,8 Trajeto 2 27 27 28 26 26 26,8 Trajeto 3 28 29 33 30 30 30,0 Trajeto 4 28 29 27 30 27 28,2 Iremos verificar por meio da ANOVA se são significantes as diferenças entre as quatro médias amostrais. Os resultados da análise são os seguintes (utilizando uma significância de 0,01): \\[\\small H_0: _1= _2= _3= _4\\] \\[\\small H_a:\\textrm{Nem todas as médias populacionais são iguais}\\] Fonte de Variação Graus de Liberdade Soma dos quadrados Quadrado Médio Estatística F Tratamentos 3 49.8 16.6 8.736842105 Erro 16 30.4 1.9 P-Value: .0011581109 Total 19 80.2 Sxp = 1.37840488 O p-value é menor que a significância (0.001 &lt; 0.01), portanto o hipótese nula deve ser rejeitada. Ou seja, nem todas as médias são iguais. Mas então qual seria a ordem dessas médias? Quais são maiores ou menores? Se fossemos fazer um teste t de duas amostras teríamos um total de \\(\\small \\binom{4}{2} =6\\) pares possíveis. Se os testes t forem feitos ao nível 0,05 de significância a probabilidade é de \\(\\small 1 - (0,95)^6 0,26\\) de cometer pelo menos um erro de tipo I. Para responder essa questão controlando a probabilidade de erros de tipo I utilizamos as comparações múltiplas. O método a seguir é chamado de intervalo studentizado. Intervalo studentizado - Teste Tukey ( HSD - honestly significant difference ) O intervalo studentizado, também chamado teste post-hoc foi projetado para controlar a probabilidade global de cometermos pelo menos um erro tipo I quando comparamos os diferentes pares de médias. Ele é baseado no argumento que a diferença entre as médias de dois tratamentos (digamos, os tratamentos i e j) é significante se: \\[\\small | \\bar{x}_i - \\bar{x}_j |  \\frac{q_}{\\sqrt{n}} s\\] s = raiz quadrado de do erro quadrático médio ( QME)  = nível geral se significância \\(\\small q_\\) = valor calculado a partir do número de tratamentos, significância e graus de liberdade para o erro Tabela Q - Tukey Portanto, a distância mínima significativa é: \\[\\small | \\bar{x}_i - \\bar{x}_j |  \\frac{\\bar{q_}}{{\\sqrt{n}}} s\\] \\[\\small \\frac{4,05}{\\sqrt{5}} 1,38=2,50\\] Em R o \\(\\small q_\\) pode ser dado por: qtukey(p = 0.95, df = 16, nmeans = 4) ## [1] 4.046093 Quando utilizamos as comparações múltiplas devemos organizar os tratamentos de acordo com o tamanho de suas médias e realizar o cálculo das diferenças das médias de todos os pares de trajetos possíveis, portanto: Trajeto 1 Trajeto 2 Trajeto 3 Trajeto 4 25,8 26,8 28,2 30 Trajeto 1 Trajeto 2 Trajeto 3 Trajeto 4 Trajeto 1 * 1 2,4 4,2 Trajeto 2 ** * 1,4 3,2 Trajeto 3 ** ** * 1,8 Trajeto 4 *** ** ** * Como podemos observar, somente os trajetos 1 e 4 e 2 e 4 apresentaram diferenças significativas. Ou seja, os trajetos 1,2 e 3 não são muito diferentes entre si e os trajetos 3 e 4 também não são muito diferentes entre si. É como se formassem dois grupos, onde os mais indicados seriam o grupo 1,2,3 ao invés do grupo dos trajetos 3 e 4. Em R teríamos: a &lt;- read.csv(&quot;data/trajetos.csv&quot;) trajeto &lt;- c(rep(&quot;Trajeto1&quot;,5),rep(&quot;Trajeto2&quot;,5),rep(&quot;Trajeto3&quot;,5),rep(&quot;Trajeto4&quot;,5)) tempo = c(a$Trajeto.1, a$Trajeto.2, a$Trajeto.3, a$Trajeto.4) data &lt;- data.frame(trajeto, tempo) TukeyHSD(aov(lm(tempo ~ trajeto, data = data))) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = lm(tempo ~ trajeto, data = data)) ## ## $trajeto ## diff lwr upr p adj ## Trajeto2-Trajeto1 1.0 -1.49417926 3.4941793 0.6669778 ## Trajeto3-Trajeto1 4.2 1.70582074 6.6941793 0.0009798 ## Trajeto4-Trajeto1 2.4 -0.09417926 4.8941793 0.0614131 ## Trajeto3-Trajeto2 3.2 0.70582074 5.6941793 0.0100117 ## Trajeto4-Trajeto2 1.4 -1.09417926 3.8941793 0.4031260 ## Trajeto4-Trajeto3 -1.8 -4.29417926 0.6941793 0.2065277 10.10.9 Princípios básicos da experimentação Os princípios básicos da experimentação: repetição casualização controle local Repetição: Corresponde ao número de parcelas que receberão um mesmo tratamento. Quanto maior a variabilidade do meio em que se realiza o experimento, e (ou) quando se deseja que os tratamentos apresentem poucas diferenças, maior o número de repetições, isso possibilita que o experimento tenha uma menor probabilidade de erro. Contudo, alguns fatores podem limitar o número de repetições como: o número de tratamentos que serão comparados, pela disponibilidade de material e de área experimental, entre outros. Além de permitir a estimativa do erro experimental, a repetição também aumentar a precisão das estimativas e o poder dos testes estatísticos Casualização: consiste em se distribuir, aleatoriamente, os tratamentos nas parcelas, de modo que cada um tenha a mesma chance de ocupar qualquer parcela na área experimental. Com isso, a casualização evita que determinado tratamento seja favorecido e garanta que os erros sejam independentes. Controle Local: serve para evitar as influências externas, que seriam responsáveis pela diferenciação dentro e entre tratamentos, fato que mascararia os resultados da pesquisa. 10.10.9.0.1 Como definir o número de repetições de um experimento? O número ótimo de repetições deve levar em conta os recursos disponíveis e em geral seguem as seguintes regras: Obter no mínimo vinte parcelas Graus de liberdade dos resíduos deve ser maior que 10 Ou ainda se basear pela revisão de literatura, verificando a quantidade de repetições geralmente utilizadas para aquele tipo de experimento. As repetições também podem ser definidas por meio de métodologias estatísticas como: análise do coeficiente de variação da característica, observado a diferença mínima significativa 10.10.9.1 Pressupostos do modelo estatístico Os pressupostos do modelo estatístico são que os erros são independentes, homocedásticos e normais. Erros independentes: Se o experimento é independentes, os dados coletados serão independentes e assim também seus erros. Homocedasticidade da variância: Constância da variância ao longo do eixo X. A variância em questão trata da distância entre o ponto predito pelo modelo e o ponto observado(resíduo), a homocedasticidade se refere a variância entre predito x observado não aumentar ao longo do eixo x, ou seja, a variância é constante no modelo. Caso a variância aumente/diminua com o tempo o dado é dito heterocedástico. Normalidade da distribuição: Os dados devem estar normalmente distribuídos, ou seja, seguir uma distribuição normal. O teste de normalidade pode ser efetuado por meio do Teste de Shapiro Wilk O pressuposto do erro é expresso pela seguinte equação: \\(\\small   N ( 0, I ^2)\\) 10.10.9.1.1 Consequências da não-validação de pressupostos A violação do pressuposto de normalidade é crítica se os grupos forem pequenos (abaixo de 30 observações) e não tão importante se forem grandes. A violação do pressuposto de homogeneidade pode levar a detecção das diferenças entre os grupos, que de fato existem. Seja como for, a ANOVA é um teste bastante robusto. Regra geral é apenas quando o resultado está na zona cinzenta, i.e. de p-value 1-10%, que não se deve tirar conclusões se houver pressupostos não validados. 10.10.9.1.2 Testes não paramétricos No caso de múltiplas violações grosseiras dos pressupostos será necessário recorrer a um método não paramétrico para analisar o planejamento experimental elaborado. 10.10.9.1.2.1 Um fator - Teste de Krustal-Wallis Um teste alternativo quando não estão validados os pressupostos da ANOVA é o teste de Kruskal-Wallis. Este é um teste não-paramétrico, as suas hipóteses H0 e Ha . não se referem a parâmetros da distribuição das variáveis estatísticas, como a média  , mas sim a características gerais dessas distribuições: \\[\\small H_0: \\textrm{os grupos têm a mesma distribuição}\\] \\[\\small H_a: \\textrm{Há pelo menos um grupo com distribuição diferente dos restantes}\\] O teste de Kruskal-Wallis pode ser executado independentemente do tipo de dados, mas tem mais dificuldades em identificar diferenças entre grupos, no geral devolve p-values mais elevados. O teste funciona transformando as observações em postos (ranks), após o que calcula um valor, H, e com ele obtém um p-value. Esta transformação de valores em postos chama-se rank transform e é uma das formas principais de relacionar a estatística paramétrica com a não-paramétrica. Compare o p-value obtido pelo teste anova e abaixo pelo krustal.test: prod = c(8.7, 8.3, 7.6, 6.0, 7.9, 5.7, 8.0, 7.0, 8.7, 8.7, 4.7, 4.0, 6.7, 6.3, 5.0) vinha = c(rep(&quot;SGab&quot;,5),rep(&quot;SMig&quot;,5),rep(&quot;SRaf&quot;,5)) dados = data.frame(prod,vinha) anova(lm(prod ~ vinha, data = dados)) ## Analysis of Variance Table ## ## Response: prod ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## vinha 2 17.957 8.9787 6.7593 0.01081 * ## Residuals 12 15.940 1.3283 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 kruskal.test(prod ~ vinha, data = dados) ## ## Kruskal-Wallis rank sum test ## ## data: prod by vinha ## Kruskal-Wallis chi-squared = 6.6676, df = 2, p-value = 0.03566 Como vemos, o teste de Kruskal-Wallis devolve um p-value maior do que a ANOVA, mas também próximo de 1%, confirmando mais uma vez que (pelo menos) um dos grupos é diferente dos restantes. 10.10.9.1.2.2 Dois fatores - Teste de rank ANOVA Para realização do teste ANOVA de dois fatores, no caso de múltiplas violações grosseiras, é preciso realizar um teste não paramétrico. Para ANOVA de um fator, o teste de Kruskal-Wallis é útil, porém no caso de dois fatores. De acordo com Conover e Iman podemos substituir as observações das variáveis em estudo pelos seus postos (ranks) e realizar a ANOVA tradicional sobre eles. A transformação de posto ( rank transformation ) pode ser feito em R com o comando rank(): grau = c(14, 11, 11, 11, 8, 10, 11, 11, 10, 17, 16, 14, 10, 10, 7, 5, 8, 8, 8, 7, 4, 6, 7, 8, 17, 21, 17, 15, 19, 16, 15, 21, 18, 16, 17, 19) tipoVinho = c(rep(&quot;bairrada&quot;,12),rep(&quot;verde&quot;,12),rep(&quot;porto&quot;,12)) tipoCasco = c(rep(c(rep(&quot;carvalho&quot;,6),rep(&quot;pinho&quot;,6)),3)) grauVinho = data.frame(grau,tipoVinho,tipoCasco) anova(lm(rank(grau)~tipoVinho*tipoCasco,data=grauVinho)) ## Analysis of Variance Table ## ## Response: rank(grau) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## tipoVinho 2 3117.54 1558.77 74.2370 2.417e-12 *** ## tipoCasco 1 3.36 3.36 0.1601 0.6919 ## tipoVinho:tipoCasco 2 98.18 49.09 2.3379 0.1139 ## Residuals 30 629.92 21.00 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 A ANOVA sobre os postos pode depois ser complementada pelos testes post-hoc usuais, bastando para isso ter novamente o cuidado de usar sempre rank(nome) como variável de resposta. A interpretação destes testes não é em termos de médias da variável de resposta, mas sim, naturalmente, em termos do rank médio das observações dos grupos, ou seja, grupo A tem rank médio maior que grupo B ou algo de semelhante. A ANOVA sobre os postos também pode ser usada como uma alternativa ao teste de Kruskal-Wallis para o caso de um fator, com a vantagem de poder ser seguida de um banal teste de Tukey sobre os postos. 10.10.9.1.3 Problemas do teste anova por ranks Como para todo teste paramétrico de ANOVA existe um teste não paramétrico pode parecer uma boa ideia ignorar os pressupostos e sempre partir para um teste não paramétrico. Porém existem algumas observações a serem feitas: Para testes de um fator p-value dos ranks se diferem de um teste de Krustal-Wallis (que seria o teste exato) Não são grandes, mas existem - Conover e Iman Portanto, em caso de violação dos pressupostos só se deve recorrer ao ANOVA por ranks dado a inexistência do outro teste não paramétrico Para teste de dois ou mais fatores o p-value do teste de interação por ranks deflaciona ( cresce) artificialmente quando há rejeição da \\(H_0\\) nos fatores 1 e 2. Ou seja, caso ambos os fatores influenciem a variável de resposta é possível que o teste à interação fique enviesado no sentido de rejeição (detectando interação onde não existem). Portanto em caso de tripla rejeição ( influência de ambos os fatores e interação) deve ser observado o diagrama de interação para confirmação dos resultados. Dada a não evidência clara de interação a hipótese de interação deve ser rejeitada. Em alternativa, se se quiser mesmo um p-value exato ao teste de interação, há que correr uma ANOVA específica para o efeito, a ANOVA-ART (aligned rank transform ANOVA), disponível no pacote R ARTool 10.10.9.2 Delineamentos Os delineamentos mais comuns são os: DIC - Delineamento Inteiramente Casualizado DBC - Delineamento em Blocos Casualizados DBC - Blocos ao acaso Eles tem por objetivo remover parte do erro experimental do experimento, de modo que as diferenças que forem apontadas numa comparação entre médias, ou numa análise de variância sejam, de fato, em função de diferenças entre os dados e não em função da variância devido a um fator externo ao experimento (ou não medido)- que é chamado de variação ao acaso. 10.10.9.2.1 Delineamento Inteiramente Casualizado É o delineamento mais simples, onde a área do experimento é dividido em blocos e por meio de sorteio os tratamentos são destinados a cada área. T1 T2 T2 T1 T1 T1 T2 T2 Dessa forma, nenhum tratamento é favorecido por uma variabilidade (não aparente) e o experimento fica protegido pela aleatoriedade. Neste caso somente os princípios da aleatorização e da casualização são levados em conta, não existindo portanto o controle local. Devido a isso, o ambiente do experimento deve ser o mais uniforme possível Vantagens Qualquer número de tratamentos e repetições pode ser usado As repetições podem variar entre tratamentos É simples de ser implantado O número de graus de liberdade para o resíduo é o maior possível Desvantagens Exige homogeneidade total das condições experimentais Conduz estimativas elevadas do erro experimental Objetivo Permitir a estimativa do erro experimental Contribuir para aumentar a precisão dos experimentos Fornecer informações sobre o procedimento mais apropriado para proceder os testes de significância 10.10.9.2.2 Delineamento em Blocos Casualizados O delineamento em blocos casualizados é o delineamento mais utilizado nas pesquisas devidos sua simplicidade e alta precisão. Neste delineamento são levadas em consideração os princípios da repetição, casualização e do controle local. Quando existe uma variabilidade entre as áreas experimentais, como no exemplo abaixo, um terreno em declive, onde quanto mais embaixo no terreno, maior a fertilidade e maior a umidade. Dessa forma se os tratamentos fossem somente repetidos e aleatorizados algum tratamento poderia ser favorecido ao ter mais parcelas da área baixa do terreno. Para contornar esse problema de enviesamento de dados podemos criar conjuntos ambientais homogêneos chamados blocos, sendo esta a aplicação do princípio do controle local: Os blocos tem por objetivo homogeneizar as unidades experimentais dentro de cada bloco, de modo a minimizar a variabilidade dentros dos blocos e maximizar a variabilidade entre os blocos. Dentro desses blocos será realizada uma distribuição casualizada, que é a aplicação do princípio da repetição e casualização, podendo ter uma ou mais repetições dentro da cada bloco. Vantagens A perda de um ou mais blocos não dificulta a análise estatística Conduz estimativas com erro experimental menos elevado A análise é simples Permite, dentro de certos limites, utilizar qualquer número de tratamentos e repetições Controla homogeneidade do ambiente onde o experimento é conduzido Melhor estimativa da variância residual (QMR) Desvantagens Redução dos graus de liberdade dos resíduos Exige homogeneidade dentro do bloco Susceptível ao desbalanceamento Não permite um número muito grande de tratamentos 10.10.9.2.3 Delineamento em Quadrado Latino Quando existem heterogeneidade em dois sentidos como no exemplo abaixo onde a seta azul indica a umidade e a seta preta a fertilidade: A solução é dividir a área em blocos, horizontais e verticais na mesma quantidade que os tratamentos e os tratamentos deveriam ser distribuídos de forma a não haver o mesmo tratamento numa mesma linha ou coluna, sendo então o controle local aplicado em dois sentidos (linha e coluna). Assim todos os tratamentos estão bem representados nas duas condições de heterogeneidade Vantagens Ideal para condição de grande heterogeneidade na área experimental É mais informativo em situações em que se quer obter informações sobre as linhas e as colunas Desvantagens Baixa flexibilidade Número de tratamentos, repetições, linhas e colunas devem ser os mesmos Não possibilita a avaliação de muitos tratamentos Números de parcelas =( Número de tratamentos )² Perda severa de graus de liberdade do resíduo A perda de blocos/parcelas causa um grave desbalanceamento 10.10.10 ANOVA de dois critérios (sem interação) A formulação de hipóteses a serem testadas no caso de duas variáveis é representada da seguinte forma: \\[\\small _{ij}=  + _{i} + _{j}\\] \\(\\small _{ij}\\) = média populacional que corresponde ao i-ésimo tratamento e j-ésimo bloco  = média global - média de todas as médias populacionais \\(\\small _{ij}\\) \\(\\small _i\\) =efeitos do tratamento (cuja soma é zero) \\(\\small _j\\)= efeitos de bloco (cuja soma é zero) As duas hipóteses que serão testadas são escritas: \\[\\small H_0 : _1 = _2 = ... = _k = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do tratamento i são iguais a zero}\\] e \\[\\small H_0: _1 = _2 = ... = _n = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do bloco i são iguais a zero}\\] Para testar a segunda hipótese é necessária uma grandeza análoga à soma dos quadrados de tratamentos que meça a variação entre as médias de blocos. Para tanto temos a soma de quadrados de blocos: \\[\\small SQB = \\frac{1}{k} . \\sum_{j = 1}^{n}T_{. j}^{2} - \\frac{1}{kn^.} T_{..}^{2}\\] \\(\\small T . j\\) = total de todos os valores de j-ésimo bloco \\(\\small x_{ij}\\) = valor da observação i para o tratamento j \\(\\small n_j\\) = número de observações para o tratamento j \\[\\small STQ =\\sum_{i = 1}^{k} \\sum_{j = 1}^{n}x_{ij}^{2}- \\frac{1}{kn} . T_{..}^{2}\\] \\[\\small SQ (Tr) =\\frac{1}{n^.} \\sum_{i = 1}^{k}T_{i.}^{2}- \\frac{1}{kn} . T_{..}^{2}\\] \\[\\small STQ = SQ (Tr) + SQB + SQE\\] \\[\\small SQE = STQ -[ SQ (Tr) + SQB]\\] Fonte de Variação Graus de Liberdade Soma dos quadrados Quadrado Médio Estatística F Tratamentos k - 1 SQ ( Tr ) \\(\\small QM ( Tr ) = \\frac{SQ (Tr )}{k -1}\\) \\(\\small \\frac{Qm ( Tr )}{QME}\\) Blocos n - 1 SQB \\(\\small QMB = \\frac{SQB}{n -1}\\) \\(\\small \\frac{QMB}{QME}\\) Erro (k - 1) (n - 1) SQE \\(\\small QME = \\frac{SQE}{(k - 1(n - 1))}\\) Total kn - 1 SQT Exemplo: Suponhamos que seja aplicado um teste de compreensão de leitura a amostras aleatórias de alunos da oitava série de quatro escolas com os resultados seguintes: Média Variância Amplitude Escola A 87 70 92 83 133 22 Escola B 43 75 56 58 259 32 Escola C 70 66 50 62 112 20 Escola D 67 85 79 77 84 18 Como as médias são bem diferentes podemos imaginar que haja algumas diferenças reais entre os graus de compreensão de leitura dos alunos. Não é o que decorre entretanto, de uma análise de variância de um critério: \\[\\small H_0: _1= _2= _3 = _4\\] \\[\\small Ha:\\textrm{Nem todas as médias populacionais são iguais}\\] Fonte de Variação Graus de Liberdade Soma dos quadrados Quadrado Médio Estatística F Tratamentos 3 1278 426 2.90 Erro 8 1176 147 Total 11 2454 O F crítico para 3 e 8 graus de liberdade e 0,05 para significância é de 4,07. Portanto, a hipótese nula não pode ser rejeitada ao nível de 0,05 de significância. A razão disso é que não há somente grandes diferenças entre as médias, mas também grandes diferenças entre os valores dentro das amostras que pode ser observada na amplitude dos dados. Analisando a questão podemos supor que as diferenças possam ser causadas por diferenças de capacidade (um fator irrelevante que poderíamos considerar um fator de incomodação) que foi aleatorizado ao tomarmos uma amostra aleatória de alunos de cada escola. Assim as variações causadas por diferenças de capacidade foram incluídas no erro experimental; isso inflacionou a soma de quadrados de erros, o denominador da estatística F e devido a isso os resultados não foram significantes. Para evitar essa situação poderíamos: manter fixo o fator irrelevante mas isso raramente nos dará a informação desejada limitar os estudos a alunos de nota média maior que 90 mas isso limitaria o estudo a alunos de nota maior que 90 fazer o fator de variabilidade (o fator irrelevante) variar deliberadamente variar deliberadamente sobre um intervalo tão amplo quanto necessário, de forma que a variabilidade causada possa ser medida e assim eliminada do erro experimental Ao escolher a terceira opção podemos planejar o experimento de forma a realizar uma análise de variância de dois critérios, onde a variabilidade total dos dados seja dividida em três componentes atribuídos aos tratamentos, ao fator irrelevante, e ao erro experimental. No exemplo podemos dividir os alunos em três grupos de acordo com as notas médias. Dessa forma, seriam selecionados aleatoriamente, em cada escola, alunos que se encaixassem em cada grupo. O resultado dessa divisão seria o seguinte: Nota média Baixa Nota média Típica Nota média Alta Escola A 71 92 89 Escola B 44 51 85 Escola C 50 64 72 Escola D 67 81 86 Essa divisão é denominada Delineamento em Blocos Casualizados. e cada bloco são os níveis que mantemos fixo um fator irrelevante, de modo que possamos medir sua contribuição para a variabilidade total dos dados por meio de uma análise de variância de dois critérios. As hipóteses seriam as seguintes: \\[\\small H_0 : _1 = _2 = ... = _k = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do tratamento } _i \\textrm{ são iguais a zero}\\] e \\[\\small H_0: _1 = _2 = ... = _n = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do bloco } _i \\textrm{ são iguais a zero}\\] Onde: \\(\\small _i\\) equivale à hipótese de que o grau médio de compreensão de leitura dos alunos da oitava série é o mesmo nas quatro escolas. \\(\\small _i\\) equivale à hipótese de que a compreensão média de leitura dos alunos da oitava série é a mesma para todos os três níveis de nota média. \\[\\small SQB = \\frac{1}{k} . \\sum_{j = 1}^{n}T_{. j}^{2} - \\frac{1}{kn^.} T_{..}^{2}\\] \\(\\small T . j\\) = total de todos os valores de j-ésimo bloco \\(\\small x_{ij}\\) = valor da observação i para o tratamento j \\(\\small n_j\\) = número de observações para o tratamento j \\(\\small k\\) = número de blocos Nota média Baixa Nota média Típica Nota média Alta Total Tratamentos Escola A 71 92 89 252 Escola B 44 51 85 180 Escola C 50 64 72 186 Escola D 67 81 86 234 Total Blocos 232 288 332 T.. = 232 + 288 + 332 = 852 k = 4 (tratamentos) n = 3 (blocos) j = 4 ( tratamentos) i = 3 (observação do tratamento j) \\[\\small SQB = \\frac{1}{k} . \\sum_{j = 1}^{n}T_{. j}^{2} - \\frac{1}{kn^.} T_{..}^{2}\\] \\[\\small SQB = \\frac{1}{4} . (232^2 + 288^2+ 332^2) - \\frac{1}{12}. (852)^2\\] \\[\\small SQB = \\frac{1}{4} . (53824 + 82944+ 110224) - \\frac{1}{12}. (725904)\\] \\[\\small SQB = \\frac{1}{4} . (246992) - 60492\\] \\[\\small SQB =1256\\] \\[\\small \\sum_{i=1}^{k}\\sum_{j=1}^{n}x_{ij}^{2}\\] Nota média Baixa Nota média Típica Nota média Alta Total Tratamentos Escola A \\(\\small (71)^2 = 5041\\) \\(\\small (92)^2 =8464\\) \\(\\small (89)^2 = 7921\\) 21426 Escola B \\(\\small (44)^2=1936\\) \\(\\small (51)^2 =2601\\) \\(\\small (85)^2=7225\\) 11762 Escola C \\(\\small (50)^2=2500\\) \\(\\small (64)^2 =4096\\) \\(\\small (72)^2 = 5184\\) 11780 Escola D \\(\\small (67)^2=4489\\) \\(\\small (81)^2=6561\\) \\(\\small (86)^2=7396\\) 18446 Total Blocos 63.414 \\[\\small STQ =\\sum_{i = 1}^{k} \\sum_{j = 1}^{n}x_{ij}^{2}- \\frac{1}{kn} . T_{..}^{2}\\] \\[\\small STQ =63414 - \\frac{1}{12} (852)^2\\] \\[\\small STQ =63414 - 60492 = 2922\\] \\[\\small SQ (Tr) =\\frac{1}{n^.} \\sum_{i = 1}^{k}T_{i.}^{2}- \\frac{1}{kn} . T_{..}^{2}\\] \\[\\small SQ (Tr) =\\frac{1}{3} (252^2 + 180^2+ 186^2+ 234^2) - \\frac{1}{12} (852)^2\\] \\[\\small SQ (Tr) =\\frac{1}{3} (63504 + 32400+ 34596+ 54756) - \\frac{1}{12} (725904)^2\\] \\[\\small SQ (Tr) =\\frac{1}{3} . (185256) - 60492\\] \\[\\small SQ (Tr) =61752 - 60492 =1260\\] \\[\\small STQ = SQ (Tr) + SQB + SQE\\] \\[\\small SQE = STQ -[ SQ (Tr) + SQB]\\] \\[\\small SQE = 2922-[ 1260 + 1256] = 406\\] Fonte de Variação Graus de Liberdade Soma dos quadrados Quadrado Médio Estatística F Tratamentos \\(\\small k - 1\\) \\(\\small 4 - 1 = 3\\) \\(\\small SQ ( Tr )=1260\\) \\(\\small QM ( Tr ) = \\frac{SQ (Tr )}{k-1}\\)\\(12603=420\\) \\(\\small \\frac{Qm ( Tr )}{QME}\\)\\(\\small \\frac{420}{67,67} =6,21\\) Blocos \\(\\small n - 1\\)\\(\\small 3 - 1 = 2\\) \\(\\small SQB=1256\\) \\(\\small QMB = \\frac{SQB}{n -1}\\)\\(\\small \\frac{1256}{2}=628\\) \\(\\small \\frac{QMB}{QME}\\)\\(\\small \\frac{628}{67.67}=9,28\\) Erro \\(\\small (k - 1) (n - 1)\\) \\(\\small (4 - 1) (3 - 1) = 6\\) \\(\\small SQE=406\\) \\(\\small QME = \\frac{SQE}{(k - 1)(n - 1)}\\)\\(\\small \\frac{406}{6} \\approx 67,67\\) Total \\(\\small kn - 1\\)\\(\\small 4 \\times 3 - 1 = 11\\) \\(\\small STQ=2922\\) F crítico para os tratamentos:  4,76 qf(p = 0.95, df1 = 3, df2 = 6) ## [1] 4.757063 F crítico para os blocos  5,14 qf(p = 0.95, df1 = 2, df2 = 6) ## [1] 5.143253 Portanto, como o F observado nos tratamentos foi de 6,21 e o F crítico foi de 4,76 a hipótese nula relacionada aos tratamentos deve ser rejeitada). O F observado nos blocos foi de 9,28 e o F crítico foi de 5,14 , então a hipótese nula relacionada aos blocos deve ser rejeitada. Ou seja, concluímos que o grau médio de compreensão de leitura de alunos da oitava série não é o mesmos para as quatro escolas e o grau médio de compreensão de leitura de alunos da oitava série não é o mesmo para os três níveis de média de notas. pf(q = 6.21, df1 = 3 , df2 = 6, lower.tail = F) ## [1] 0.02857731 pf(q = 9.28, df1 = 2 , df2 = 6, lower.tail = F) ## [1] 0.01458037 Ambos os p-values são menores que a significância de 0.05 , confirmando novamente a rejeição de ambas as hipóteses nulas. Como pode ser observado, obtivemos diferenças significativas entre os graus médios de compreensão de leitura com o uso de bloqueamento, o que não ocorreu com o uso da ANOVA de um fator (sem bloqueamento). 10.10.11 ANOVA de dois critérios (com interação) A formulação de hipóteses a serem testadas no caso de duas variáveis é representada da seguinte forma: \\[\\small _{ij}=  + _i + _j + _{ij}\\] \\(\\small _{ij}\\) = média populacional que corresponde ao i-ésimo tratamento e j-ésimo bloco \\(\\small \\) = média global - média de todas as médias populacionais \\(\\small _{ij}\\) \\(\\small _i\\) =efeitos do fator A(cuja soma é zero) \\(\\small _j\\)= efeitos do fator B(cuja soma é zero) \\(\\small _{ij}\\) = efeitos do fator A e B combinados As duas hipóteses que serão testadas são escritas: Teste ao fator 1: \\[\\small H_0 : _1 = _2 = ... = _k = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do fator i são iguais a zero}\\] e Teste ao fator 2: \\[\\small H_0: _1 = _2 = ... = _n = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do fator i são iguais a zero}\\] e Teste à interação dos fatores: \\[\\small H_0: _{ij} _{ij} = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos das combinações dos fatores são iguais a zero}\\] Exemplo: Um experimento projetado para testar se o alcance de vôo de um míssil (em quilômetros) é afetado pelas diferenças entre os lançadores e também pelas diferenças entre os tipos de combustível: Combustível 1 Combustível 2 Combustível 3 Combustível 4 Lançador X 45,9 57,6 52,2 41,7 Lançador Y 46,0 51,0 50,1 38,8 Lançador Z 45,7 56,9 55,3 48,1 As duas variáveis serão chamadas de Fator A e Fator B. Para que ser possível analisar as interações entre os dois fatores (Fator AB) é necessário que cada grupo tenha mais de um elemento representativo (para que a variância dentro do grupo não seja 0). Portanto, iremos aplicar o princípio da repetição e repetir o experimento. A repetição rendeu as seguintes observações: Combustível 1 Combustível 2 Combustível 3 Combustível 4 Lançador X 46,1 55,9 52,6 44,3 Lançador Y 46,3 52,1 51,4 39,6 Lançador Z 45,8 57,9 56,2 47,6 A primeira análise será baseada na hipótese: \\[\\small H_0 : _1 = _2 = ... = _k = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do tratamento i são iguais a zero}\\] e \\[\\small H_0: _1 = _2 = ... = _n = 0\\] \\[\\small Ha:\\textrm{Nem todas os efeitos do bloco } _i \\textrm{ são iguais a zero}\\] Sendo  o lançador e  o combustível. O resultado da análise ANOVA para as hipóteses acima é a seguinte: Df Sum Sq Mean Sq F value Pr(&gt;F) &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; lancador 2 91.50333 45.751667 14.02668 2.128629e-04 combustivel 3 570.82458 190.274861 58.33504 1.800197e-09 Residuals 18 58.71167 3.261759 NA NA O p-value para  e  são menores que a significância de 0,05, então ambas as hipótese nulas devem ser rejeitadas. Ou seja, existe diferença significativa entre as distâncias de arremesso dos diferentes lançadores e combustíveis. Agora vamos realizar a análise considerando a hipótese de haver uma interação entre os fatores combustível e lançador. As hipóteses a serem analisadas são as seguintes: \\[\\small H_0 : _1 = _2 = ... = _k = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do tratamento } _k \\textrm{ são iguais a zero}\\] e \\[\\small H_0: _1 = _2 = ... = _n = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do bloco } _n \\textrm{ são iguais a zero}\\] e \\[\\small H_0: _1 _1 = _2 _2 = ... = _k_n = 0\\] \\[\\small H_a:\\textrm{Nem todas os efeitos do bloco } _k _n \\textrm{ são iguais a zero}\\] Sendo  o lançador e  o combustível e  a interação entre os fatores . O resultado da análise ANOVA para as hipóteses acima é a seguinte: Df Sum Sq Mean Sq F value Pr(&gt;F) &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; combustivel 3 570.82458 190.2748611 293.67181 1.716617e-11 lancador 2 91.50333 45.7516667 70.61350 2.307148e-07 combustivel:lancador 6 50.93667 8.4894444 13.10268 1.187165e-04 Residuals 12 7.77500 0.6479167 NA NA O p-value para  ,  ,  são menores que a significância de 0,05, então todas as hipótese nulas devem ser rejeitadas. Ou seja, existe diferença significativa entre as distâncias de arremesso dos diferentes lançadores e combustíveis. O gráfico de interação pode ser obtido pelo comando: L_X&lt;- c(45.9,57.6,52.2,41.7) L_Y&lt;- c(46,51,50.1,38.8) L_Z&lt;- c(45.7,56.9,55.3,48.1) alcance1 &lt;- c(L_X,L_Y,L_Z) #replicação L_X&lt;- c(46.1,55.9,52.6,44.3) L_Y&lt;- c(46.3,52.1,51.4,39.6) L_Z&lt;- c(45.8,57.9,56.2,47.6) alcance2 &lt;- c(L_X,L_Y,L_Z) alcance &lt;- c(alcance1, alcance2) lancador &lt;- rep(c(&quot;Lançador X&quot;,&quot;Lançador Y&quot;,&quot;Lançador Z&quot;),each=4, times = 2) combustivel &lt;- rep(c(&quot;Combustível 1&quot;,&quot;Combustível 2&quot;, &quot;Combustível 3&quot;, &quot;Combustível 4&quot;),each=1,times = 6) data = data.frame(alcance, lancador, combustivel) interaction.plot(data$combustivel, data$lancador, data$alcance) A partir do gráfico podemos perceber que os lançadores fazem uma grande diferença no alcance, porém a maior diferença é vista nos diferentes combustíveis. 10.10.12 Resumo : Anova dois critérios O que é? Essencialmente, a ANOVA de dois fatores é um modelo de regressão múltipla com duas variáveis categóricas (fatores ) como variáveis explanatórias. Usado quando? Avaliação inicial do modelo Teste de interação Teste de fatores individuais Condições Variável resposta é independente, homogênea dentro dos grupos e normalmente distribuída. Caso as observações sejam desequilibradas (diferente números de observações (n) para cada combinação de tratamentos (ab)). Modelo saturado - não aditivo No modelo não aditivo, os efeitos de um fator são possivelmente diferentes em todos os níveis do outro fator  há interação. Essencialmente, o modelo de linhas separadas em regressão múltipla. \\[\\small ( Y | A,B) = _0 + A + B + AB\\] Modelo aditivo Em um modelo aditivo, os efeitos de um fator são todos iguais em todos os níveis do outro fator  não há interação. Essencialmente, o modelo de linhas paralelas na regressão múltipla.. \\[\\small ( Y | A,B) = _0 + A + B\\] 10.11 Transformação de dados A transformação de dados nada mais é do que modificar cada ponto de um dataset por meio da aplicação de uma função matemática. Isso geralmente é realizado com o objetivo de tornar os dados apropriados para serem utilizados num teste ou método estatístico, como por exemplo: Utilizar o inverso : \\(\\small \\frac{1}{x}\\) para reduzir efeito aparente dos outliers A função log: para estabilizar a variância Ocorre quando os dados cobrem diferentes ordens de magnitude Elevar a potência: para induzir a normalidade ou simetria dos dados Melhorar a exibição gráfica dos dados, como reduzir o domínio de outliers em dados fortemente agrupados 10.11.1 Rank A transformação de dados em rank trata de substituir o valor do dado pela sua posição ordenada em relação ao demais dados: Original: s = {4.001 , 1, -10, 4 , 76328632586325 } Rank: s = {4 , 2 , 1 , 3 , 5} Percebe-se: que o valor dos dados foram substituídos pela posição relativa dos valores ordenados trata-se uma transformação não linear dos dados visto que: 4.001 e 4 são próximos, mas estão separados por um index, assim como o maior valor do grupo em relação a 4.001 é uma transformação que perde informação: (não invertível) depois de feita a transformação não é possível retornar ao valor original 10.11.1.1 Tipos RT = Ranking transformation 10.11.1.1.1 RT - 1 O conjunto inteiro de observações é rankeado do menor para o maior. Em caso de valores iguais, o rank é dado pela média entre as posições. 10.11.1.1.2 RT - 2 As observações são divididas em subgrupos, onde cada subgrupo tem um rank próprio, independente. 10.11.1.1.3 RT - 3 O RT - 1 é aplicado depois da transformação dos dados ( log, raiz quadrada, etc.). 10.11.1.1.4 RT - 4 O RT - 2 é aplicado depois da transformação dos dados ( log, raiz quadrada, etc.). 10.11.2 Raiz Quadrada A transformação raiz quadrada é utilizada quando se tratam: dados de contagem ex: número de carrapatos em uma determinada área do corpo de um animal, número de vezes que o animal vai ao cocho, a distribuição é de poisson (média igual à variância) Seja Y uma variável aleatória mensurada na unidade de observação: \\(\\small Y&#39; = \\sqrt{Y}\\) Caso hajam zeros na distribuição basta adicionar meio ou 1 (a todos os elementos): \\(\\small Y&#39; = \\sqrt{Y + 0,5}\\) Graficamente teríamos os seguintes resultados: 10.11.3 Logarítmica A transformação logarítmica é usada quando: Os dados são contínuos e mesmo assim não aderem a distribuição normal Quando há proporcionalidade entre as médias e os desvios padrões dos tratamentos Não há diferença da base logarítmica ser 10 ou neperiana () Portanto, seja Y uma variável aleatória mensurada na unidade de observação, tem-se a seguinte transformação: \\[\\small Y&#39; =log(Y) \\textrm{ ou } Y&#39; =ln(Y)\\] Caso hajam zeros na distribuição basta adicionar meio ou 1 (a todos os elementos): \\[\\small Y&#39; = log(Y&#39; + 0,5) \\textrm{ ou } ln(Y&#39; + 0,5)\\] Graficamente teríamos os seguintes resultados: 10.11.4 Arcoseno Raiz Quadrada (Angular) A transformação arcoseno raiz qadrada é usada quando: dados binomiais proporções ou percentagens se os dados variam entre 30-70% (15- 85% )- dispensável A função arcoseno é a inversa da função seno com domínio no intervalo[- 2 , 2] e domínio no intervalo [-1, 1 ]. Portanto, seja Y uma variável aleatória mensurada na unidade de observação, tem-se a seguinte transformação para decimais: \\[\\small Y&#39; = arcsin \\sqrt{Y}\\] E a seguinte transformação para percentagens: \\[\\small Y&#39; = arcsin \\sqrt{\\frac{ Y}{100}}\\] Graficamente temos: 10.11.5 Transformação BoxCox A transformação BoxCox é a mais recentes das transformações e é aplicável a qualquer tipo de variável e geralmente resolve a grande maioria dos casos (principalmente nos casos em que as transformações usuais não funcionam). Dado Y, que é uma variável aleatória discreta ou contínua, a transformação é realizada da seguinte forma: \\[\\small Y&#39; = \\frac{Y^ - 1}{} \\textrm{ se }   0\\] \\[\\small Y&#39; = log(Y) \\textrm{ se }  = 0\\] Sendo o parâmetro  o que queremos encontrar, pois ele é o que maximiza a função de verossimilhança para uma distribuição normal. Ao utilizar a função no R teremos como retorno o MLE ( Maximum-likelihood ) e este valor deverá ser utilizado para elevar à potência a variável resposta. Como o método trabalha com o logaritmo da função de verossimilhança, caso tenha zeros nos dados, também podemos acrescentar 0,5 aos dados para que seja possível a transformação. Graficamente temos: 10.12 Comparações Envolvendo Proporções e Teste de Independência "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
